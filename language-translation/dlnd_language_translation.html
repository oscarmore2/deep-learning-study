<!DOCTYPE html>
<!-- saved from url=(0083)http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>dlnd_language_translation</title><script src="./dlnd_language_translation_files/require.min.js.下载"></script>
<script src="./dlnd_language_translation_files/jquery.min.js.下载"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="./dlnd_language_translation_files/custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="./dlnd_language_translation_files/MathJax.js.下载" id=""></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config;executed=true">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>
<body style=""><div id="MathJax_Message" style="display: none;"></div>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Language-Translation">¶</a></h1><p>In this project, you’re going to take a peek into the realm of neural network machine translation.  You’ll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Get-the-Data">¶</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">'data/small_vocab_en'</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">'data/small_vocab_fr'</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Explore-the-Data">¶</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Dataset Stats'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of sentences: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Average number of words in a sentence: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'English sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'French sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 227
Roughly the number of unique words: 355
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l' automne , et il est neigeux en avril .
les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .
california est généralement calme en mars , et il est généralement chaud en juin .
les états-unis est parfois légère en juin , et il fait froid en septembre .
votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .
son fruit préféré est l'orange , mais mon préféré est le raisin .
paris est relaxant en décembre , mais il est généralement froid en juillet .
new jersey est occupé au printemps , et il est jamais chaude en mars .
notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .
les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Implement-Preprocessing-Function">¶</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Text-to-Word-Ids">¶</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    """</span>
    
    <span class="c1">#sentences2 = target_text.split('n')</span>
    <span class="c1">#wordList1 = source_text.split(' ')</span>
    <span class="n">mat_in</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">mat_tar</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1">#print(source_vocab_to_int)</span>
    <span class="c1">#target_text = temp.replace(".", "&lt;EOS&gt;")</span>
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">):</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="n">mat_in</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
        
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">):</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="n">arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">])</span>
        <span class="c1">#print(np.array(arr).shape)</span>
        <span class="n">mat_tar</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
        
    <span class="c1">#print (mat_tar[1])</span>
    
    <span class="c1">#for count, word in enumerate(target_text)</span>
    <span class="k">return</span> <span class="n">mat_in</span><span class="p">,</span> <span class="n">mat_tar</span>

<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">"""</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Preprocess-all-the-data-and-save-it">¶</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Check-Point">¶</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Check-the-Version-of-TensorFlow-and-Access-to-GPU">¶</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers.core</span> <span class="k">import</span> <span class="n">Dense</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">'1.1'</span><span class="p">),</span> <span class="s1">'Please use TensorFlow version 1.1 or newer'</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'TensorFlow Version: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">'No GPU found. Please use a GPU to train your neural network.'</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Default GPU Device: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.1.0
Default GPU Device: /gpu:0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Build-the-Neural-Network">¶</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoder_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Input">¶</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
<li>Target sequence length placeholder named "target_sequence_length" with rank 1</li>
<li>Max target sequence length tensor named "max_target_len" getting its value from applying tf.reduce_max on the target_sequence_length placeholder. Rank 0.</li>
<li>Source sequence length placeholder named "source_sequence_length" with rank 1</li>
</ul>
<p>Return the placeholders in the following the tuple (input, targets, learning rate, keep probability, target sequence length, max target sequence length, source sequence length)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">"""</span>
<span class="sd">    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,</span>
<span class="sd">    max target sequence length, source sequence length)</span>
<span class="sd">    """</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">'input'</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">'target'</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'learning_rate'</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>  <span class="n">name</span><span class="o">=</span><span class="s1">'keep_prob'</span><span class="p">)</span>
    <span class="n">target_seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">'target_sequence_length'</span><span class="p">)</span>
    <span class="n">max_target_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_seq_len</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'max_target_len'</span><span class="p">)</span>
    <span class="n">source_seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">'source_sequence_length'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_seq_len</span><span class="p">,</span> <span class="n">max_target_len</span><span class="p">,</span> <span class="n">source_seq_len</span>


<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">"""</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoder-Input">Process Decoder Input<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Process-Decoder-Input">¶</a></h3><p>Implement <code>process_decoder_input</code> by removing the last word id from each batch in <code>target_data</code> and concat the GO ID to the begining of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Preprocess target data for encoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    """</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">target_data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">200</span><span class="p">])</span>
    <span class="n">go</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">'&lt;GO&gt;'</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">new_target</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">go</span><span class="p">,</span><span class="n">target_data</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_target</span>

<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">"""</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_encoding_input</span><span class="p">(</span><span class="n">process_decoder_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tensor("strided_slice:0", shape=(2, 3), dtype=int32)
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Encoding">¶</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer:</p>
<ul>
<li>Embed the encoder input using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence"><code>tf.contrib.layers.embed_sequence</code></a></li>
<li>Construct a <a href="https://github.com/tensorflow/tensorflow/blob/6947f65a374ebf29e74bb71e36fd82760056d82c/tensorflow/docs_src/tutorials/recurrent.md#stacking-multiple-lstms">stacked</a> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"><code>tf.contrib.rnn.LSTMCell</code></a> wrapped in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"><code>tf.contrib.rnn.DropoutWrapper</code></a></li>
<li>Pass cell and embedded input to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">imp</span> <span class="k">import</span> <span class="n">reload</span>
<span class="n">reload</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">encoding_embedding_size</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param source_sequence_length: a list of the lengths of each sequence in the batch</span>
<span class="sd">    :param source_vocab_size: vocabulary size of source data</span>
<span class="sd">    :param encoding_embedding_size: embedding size of source data</span>
<span class="sd">    :return: tuple (RNN output, RNN state)</span>
<span class="sd">    """</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">cell_stack</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
        <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
        <span class="n">drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
        <span class="n">cell_stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">drop</span><span class="p">)</span>
    <span class="n">lstms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">(</span><span class="n">cell_stack</span><span class="p">)</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">encoding_embedding_size</span><span class="p">)</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">lstms</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>

<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">"""</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Decoding---Training">¶</a></h3><p>Create a training decoding layer:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper"><code>tf.contrib.seq2seq.TrainingHelper</code></a> </li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                         <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_summary_length</span><span class="p">,</span> 
                         <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_summary_length: The length of the longest sequence in the batch</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing training logits and sample_id</span>
<span class="sd">    """</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1">#print("seq length")</span>
    <span class="c1">#print(target_sequence_length)</span>
    <span class="n">train_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span><span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">)</span>
    <span class="n">basic_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">train_helper</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">)</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">basic_decoder</span><span class="p">,</span><span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_summary_length</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>



<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">"""</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Decoding---Inference">¶</a></h3><p>Create inference decoder:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper"><code>tf.contrib.seq2seq.GreedyEmbeddingHelper</code></a></li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                         <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                         <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param start_of_sequence_id: GO ID</span>
<span class="sd">    :param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param vocab_size: Size of decoder/target vocabulary</span>
<span class="sd">    :param decoding_scope: TenorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param batch_size: Batch size</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing inference logits and sample_id</span>
<span class="sd">    """</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">([</span><span class="n">start_of_sequence_id</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">])</span>
    <span class="c1"># Create the embedding helper.</span>
    <span class="n">embedding_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span>
        <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">ids</span><span class="p">,</span> <span class="n">end_of_sequence_id</span><span class="p">)</span>
    <span class="n">basic_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span>
        <span class="n">dec_cell</span><span class="p">,</span> <span class="n">embedding_helper</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">)</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span>
        <span class="n">basic_decoder</span><span class="p">,</span><span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>



<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">"""</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Build-the-Decoding-Layer">¶</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Embed the target sequences</li>
<li>Construct the decoder LSTM cell (just like you constructed the encoder cell above)</li>
<li>Create an output layer to map the outputs of the decoder to the elements of our vocabulary</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, max_target_sequence_length, vocab_size, output_layer, batch_size, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_input: Decoder input</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param target_vocab_size: Size of target vocabulary</span>
<span class="sd">    :param batch_size: The size of the batch</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param decoding_embedding_size: Decoding embedding size</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    """</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">cells</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
        <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
        <span class="n">drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
        <span class="n">cells</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">drop</span><span class="p">)</span>
    <span class="n">lstms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">(</span><span class="n">cells</span><span class="p">)</span>
    <span class="n">dec_embeds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">]))</span>
    <span class="n">dec_embed_in</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">dec_embeds</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>
    
    <span class="n">dense_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">"decode"</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
        <span class="n">train_decoder_outputs</span> <span class="o">=</span> <span class="n">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">lstms</span><span class="p">,</span> <span class="n">dec_embed_in</span><span class="p">,</span> 
            <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dense_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
        <span class="n">scope</span><span class="o">.</span><span class="n">reuse_variables</span><span class="p">()</span>
        <span class="n">infer_decoder_outputs</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">lstms</span><span class="p">,</span> <span class="n">dec_embeds</span><span class="p">,</span> 
            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">'&lt;GO&gt;'</span><span class="p">],</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">],</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> 
            <span class="n">dense_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">train_decoder_outputs</span> <span class="p">,</span> <span class="n">infer_decoder_outputs</span>



<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">"""</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Build-the-Neural-Network">¶</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob,  source_sequence_length, source_vocab_size, encoding_embedding_size)</code>.</li>
<li>Process target data using your <code>process_decoder_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)</code> function.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                  <span class="n">max_target_sentence_length</span><span class="p">,</span>
                  <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span>
                  <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param source_sequence_length: Sequence Lengths of source sequences in the batch</span>
<span class="sd">    :param target_sequence_length: Sequence Lengths of target sequences in the batch</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    """</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">enc_embedding_size</span><span class="p">)</span>
    
    <span class="n">processed_input</span> <span class="o">=</span> <span class="n">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="n">train_decoder_output</span><span class="p">,</span> <span class="n">interface_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span><span class="n">processed_input</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sentence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_decoder_output</span><span class="p">,</span> <span class="n">interface_decoder_output</span>


<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">"""</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tensor("strided_slice:0", shape=(64, 22), dtype=int32)
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Neural-Network-Training">¶</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Hyperparameters">¶</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
<li>Set <code>display_step</code> to state how many steps between each debug output statement</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0009</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Build-the-Graph">¶</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">'checkpoints/dev'</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_target_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>

    <span class="c1">#sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name='sequence_length')</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                                   <span class="n">targets</span><span class="p">,</span>
                                                   <span class="n">keep_prob</span><span class="p">,</span>
                                                   <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">source_sequence_length</span><span class="p">,</span>
                                                   <span class="n">target_sequence_length</span><span class="p">,</span>
                                                   <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
                                                   <span class="n">encoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">decoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">rnn_size</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">target_vocab_to_int</span><span class="p">)</span>


    <span class="n">training_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">train_logits</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'logits'</span><span class="p">)</span>
    <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="o">.</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'predictions'</span><span class="p">)</span>

    <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'masks'</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">"optimization"</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">training_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tensor("strided_slice:0", shape=(?, ?), dtype=int32)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch and pad the source and target sequences</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="k">def</span> <span class="nf">pad_sentence_batch</span><span class="p">(</span><span class="n">sentence_batch</span><span class="p">,</span> <span class="n">pad_int</span><span class="p">):</span>
    <span class="sd">"""Pad sentences with &lt;PAD&gt; so that each sentence of a batch has the same length"""</span>
    <span class="n">max_sentence</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_int</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sentence</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">):</span>
    <span class="sd">"""Batch targets, sources, and the lengths of their sentences together"""</span>
    <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="n">batch_i</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="c1"># Slice the right amount for the batch</span>
        <span class="n">sources_batch</span> <span class="o">=</span> <span class="n">sources</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">targets_batch</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="c1"># Pad</span>
        <span class="n">pad_sources_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">sources_batch</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">))</span>
        <span class="n">pad_targets_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">targets_batch</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">))</span>

        <span class="c1"># Need the lengths for the _lengths parameters</span>
        <span class="n">pad_targets_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pad_targets_batch</span><span class="p">:</span>
            <span class="n">pad_targets_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>

        <span class="n">pad_source_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">pad_sources_batch</span><span class="p">:</span>
            <span class="n">pad_source_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>

        <span class="k">yield</span> <span class="n">pad_sources_batch</span><span class="p">,</span> <span class="n">pad_targets_batch</span><span class="p">,</span> <span class="n">pad_source_lengths</span><span class="p">,</span> <span class="n">pad_targets_lengths</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Train">¶</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    """</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">'constant'</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">'constant'</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>

<span class="c1"># Split data to training and validation sets</span>
<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">valid_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">(</span><span class="n">valid_sources_batch</span><span class="p">,</span> <span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">valid_sources_lengths</span><span class="p">,</span> <span class="n">valid_targets_lengths</span> <span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">get_batches</span><span class="p">(</span><span class="n">valid_source</span><span class="p">,</span>
                                                                                                             <span class="n">valid_target</span><span class="p">,</span>
                                                                                                             <span class="n">batch_size</span><span class="p">,</span>
                                                                                                             <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">],</span>
                                                                                                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">]))</span>                                                                                                  
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">sources_lengths</span><span class="p">,</span> <span class="n">targets_lengths</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">get_batches</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">],</span>
                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">])):</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                 <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>


            <span class="k">if</span> <span class="n">batch_i</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>


                <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>


                <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_sources_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">valid_sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">valid_targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>

                <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>

                <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">batch_valid_logits</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.4f}</span><span class="s1">'</span>
                      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Model Trained and Saved'</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch    1/269 - Train Accuracy: 0.2329, Validation Accuracy: 0.3096, Loss: 5.7262
Epoch   0 Batch    2/269 - Train Accuracy: 0.2655, Validation Accuracy: 0.3096, Loss: 5.5192
Epoch   0 Batch    3/269 - Train Accuracy: 0.2444, Validation Accuracy: 0.3096, Loss: 5.3796
Epoch   0 Batch    4/269 - Train Accuracy: 0.2317, Validation Accuracy: 0.3096, Loss: 5.2292
Epoch   0 Batch    5/269 - Train Accuracy: 0.2325, Validation Accuracy: 0.3096, Loss: 5.0729
Epoch   0 Batch    6/269 - Train Accuracy: 0.2787, Validation Accuracy: 0.3099, Loss: 4.7808
Epoch   0 Batch    7/269 - Train Accuracy: 0.2840, Validation Accuracy: 0.3177, Loss: 4.6387
Epoch   0 Batch    8/269 - Train Accuracy: 0.2535, Validation Accuracy: 0.3223, Loss: 4.6668
Epoch   0 Batch    9/269 - Train Accuracy: 0.2866, Validation Accuracy: 0.3283, Loss: 4.4565
Epoch   0 Batch   10/269 - Train Accuracy: 0.2659, Validation Accuracy: 0.3399, Loss: 4.5089
Epoch   0 Batch   11/269 - Train Accuracy: 0.3055, Validation Accuracy: 0.3411, Loss: 4.2574
Epoch   0 Batch   12/269 - Train Accuracy: 0.2791, Validation Accuracy: 0.3421, Loss: 4.3017
Epoch   0 Batch   13/269 - Train Accuracy: 0.3443, Validation Accuracy: 0.3427, Loss: 3.9052
Epoch   0 Batch   14/269 - Train Accuracy: 0.3053, Validation Accuracy: 0.3426, Loss: 4.0173
Epoch   0 Batch   15/269 - Train Accuracy: 0.2960, Validation Accuracy: 0.3426, Loss: 3.9817
Epoch   0 Batch   16/269 - Train Accuracy: 0.3116, Validation Accuracy: 0.3426, Loss: 3.8692
Epoch   0 Batch   17/269 - Train Accuracy: 0.3022, Validation Accuracy: 0.3427, Loss: 3.8145
Epoch   0 Batch   18/269 - Train Accuracy: 0.2711, Validation Accuracy: 0.3427, Loss: 3.8973
Epoch   0 Batch   19/269 - Train Accuracy: 0.3412, Validation Accuracy: 0.3427, Loss: 3.5360
Epoch   0 Batch   20/269 - Train Accuracy: 0.2751, Validation Accuracy: 0.3428, Loss: 3.7738
Epoch   0 Batch   21/269 - Train Accuracy: 0.2934, Validation Accuracy: 0.3593, Loss: 3.7429
Epoch   0 Batch   22/269 - Train Accuracy: 0.3449, Validation Accuracy: 0.3709, Loss: 3.5209
Epoch   0 Batch   23/269 - Train Accuracy: 0.3613, Validation Accuracy: 0.3775, Loss: 3.4517
Epoch   0 Batch   24/269 - Train Accuracy: 0.2949, Validation Accuracy: 0.3622, Loss: 3.5959
Epoch   0 Batch   25/269 - Train Accuracy: 0.2918, Validation Accuracy: 0.3548, Loss: 3.5642
Epoch   0 Batch   26/269 - Train Accuracy: 0.3580, Validation Accuracy: 0.3565, Loss: 3.2350
Epoch   0 Batch   27/269 - Train Accuracy: 0.3185, Validation Accuracy: 0.3538, Loss: 3.3540
Epoch   0 Batch   28/269 - Train Accuracy: 0.3000, Validation Accuracy: 0.3770, Loss: 3.5321
Epoch   0 Batch   29/269 - Train Accuracy: 0.3071, Validation Accuracy: 0.3738, Loss: 3.4388
Epoch   0 Batch   30/269 - Train Accuracy: 0.3344, Validation Accuracy: 0.3734, Loss: 3.2954
Epoch   0 Batch   31/269 - Train Accuracy: 0.3444, Validation Accuracy: 0.3722, Loss: 3.2377
Epoch   0 Batch   32/269 - Train Accuracy: 0.3340, Validation Accuracy: 0.3736, Loss: 3.2550
Epoch   0 Batch   33/269 - Train Accuracy: 0.3449, Validation Accuracy: 0.3738, Loss: 3.1640
Epoch   0 Batch   34/269 - Train Accuracy: 0.3429, Validation Accuracy: 0.3755, Loss: 3.1753
Epoch   0 Batch   35/269 - Train Accuracy: 0.3545, Validation Accuracy: 0.3840, Loss: 3.1487
Epoch   0 Batch   36/269 - Train Accuracy: 0.3724, Validation Accuracy: 0.4056, Loss: 3.1315
Epoch   0 Batch   37/269 - Train Accuracy: 0.4041, Validation Accuracy: 0.4326, Loss: 3.1066
Epoch   0 Batch   38/269 - Train Accuracy: 0.3997, Validation Accuracy: 0.4314, Loss: 3.1051
Epoch   0 Batch   39/269 - Train Accuracy: 0.3948, Validation Accuracy: 0.4229, Loss: 3.0761
Epoch   0 Batch   40/269 - Train Accuracy: 0.3735, Validation Accuracy: 0.4267, Loss: 3.2056
Epoch   0 Batch   41/269 - Train Accuracy: 0.4106, Validation Accuracy: 0.4411, Loss: 3.0601
Epoch   0 Batch   42/269 - Train Accuracy: 0.4292, Validation Accuracy: 0.4330, Loss: 2.9160
Epoch   0 Batch   43/269 - Train Accuracy: 0.3710, Validation Accuracy: 0.4228, Loss: 3.1254
Epoch   0 Batch   44/269 - Train Accuracy: 0.4107, Validation Accuracy: 0.4302, Loss: 2.9973
Epoch   0 Batch   45/269 - Train Accuracy: 0.3903, Validation Accuracy: 0.4442, Loss: 3.1261
Epoch   0 Batch   46/269 - Train Accuracy: 0.3740, Validation Accuracy: 0.4356, Loss: 3.1623
Epoch   0 Batch   47/269 - Train Accuracy: 0.4342, Validation Accuracy: 0.4339, Loss: 2.8194
Epoch   0 Batch   48/269 - Train Accuracy: 0.4222, Validation Accuracy: 0.4490, Loss: 2.9217
Epoch   0 Batch   49/269 - Train Accuracy: 0.3937, Validation Accuracy: 0.4498, Loss: 3.0640
Epoch   0 Batch   50/269 - Train Accuracy: 0.3934, Validation Accuracy: 0.4453, Loss: 3.0595
Epoch   0 Batch   51/269 - Train Accuracy: 0.4178, Validation Accuracy: 0.4533, Loss: 2.9510
Epoch   0 Batch   52/269 - Train Accuracy: 0.4314, Validation Accuracy: 0.4569, Loss: 2.8921
Epoch   0 Batch   53/269 - Train Accuracy: 0.4024, Validation Accuracy: 0.4561, Loss: 3.0218
Epoch   0 Batch   54/269 - Train Accuracy: 0.4037, Validation Accuracy: 0.4557, Loss: 2.9993
Epoch   0 Batch   55/269 - Train Accuracy: 0.4223, Validation Accuracy: 0.4498, Loss: 2.8690
Epoch   0 Batch   56/269 - Train Accuracy: 0.4288, Validation Accuracy: 0.4538, Loss: 2.8517
Epoch   0 Batch   57/269 - Train Accuracy: 0.4171, Validation Accuracy: 0.4425, Loss: 2.8327
Epoch   0 Batch   58/269 - Train Accuracy: 0.4304, Validation Accuracy: 0.4507, Loss: 2.8354
Epoch   0 Batch   59/269 - Train Accuracy: 0.4275, Validation Accuracy: 0.4535, Loss: 2.8191
Epoch   0 Batch   60/269 - Train Accuracy: 0.4328, Validation Accuracy: 0.4500, Loss: 2.7428
Epoch   0 Batch   61/269 - Train Accuracy: 0.4536, Validation Accuracy: 0.4561, Loss: 2.6664
Epoch   0 Batch   62/269 - Train Accuracy: 0.4573, Validation Accuracy: 0.4528, Loss: 2.6864
Epoch   0 Batch   63/269 - Train Accuracy: 0.4329, Validation Accuracy: 0.4609, Loss: 2.7687
Epoch   0 Batch   64/269 - Train Accuracy: 0.4169, Validation Accuracy: 0.4482, Loss: 2.7705
Epoch   0 Batch   65/269 - Train Accuracy: 0.4316, Validation Accuracy: 0.4555, Loss: 2.7464
Epoch   0 Batch   66/269 - Train Accuracy: 0.4489, Validation Accuracy: 0.4585, Loss: 2.6635
Epoch   0 Batch   67/269 - Train Accuracy: 0.4314, Validation Accuracy: 0.4636, Loss: 2.7536
Epoch   0 Batch   68/269 - Train Accuracy: 0.4356, Validation Accuracy: 0.4662, Loss: 2.7344
Epoch   0 Batch   69/269 - Train Accuracy: 0.4077, Validation Accuracy: 0.4640, Loss: 2.8731
Epoch   0 Batch   70/269 - Train Accuracy: 0.4488, Validation Accuracy: 0.4681, Loss: 2.6961
Epoch   0 Batch   71/269 - Train Accuracy: 0.4192, Validation Accuracy: 0.4690, Loss: 2.8332
Epoch   0 Batch   72/269 - Train Accuracy: 0.4567, Validation Accuracy: 0.4640, Loss: 2.5873
Epoch   0 Batch   73/269 - Train Accuracy: 0.4391, Validation Accuracy: 0.4645, Loss: 2.6788
Epoch   0 Batch   74/269 - Train Accuracy: 0.4229, Validation Accuracy: 0.4635, Loss: 2.7760
Epoch   0 Batch   75/269 - Train Accuracy: 0.4439, Validation Accuracy: 0.4691, Loss: 2.6535
Epoch   0 Batch   76/269 - Train Accuracy: 0.4336, Validation Accuracy: 0.4685, Loss: 2.7044
Epoch   0 Batch   77/269 - Train Accuracy: 0.4525, Validation Accuracy: 0.4665, Loss: 2.6265
Epoch   0 Batch   78/269 - Train Accuracy: 0.4408, Validation Accuracy: 0.4702, Loss: 2.6579
Epoch   0 Batch   79/269 - Train Accuracy: 0.4395, Validation Accuracy: 0.4674, Loss: 2.6439
Epoch   0 Batch   80/269 - Train Accuracy: 0.4524, Validation Accuracy: 0.4719, Loss: 2.5661
Epoch   0 Batch   81/269 - Train Accuracy: 0.4426, Validation Accuracy: 0.4677, Loss: 2.6215
Epoch   0 Batch   82/269 - Train Accuracy: 0.4592, Validation Accuracy: 0.4749, Loss: 2.5633
Epoch   0 Batch   83/269 - Train Accuracy: 0.4453, Validation Accuracy: 0.4672, Loss: 2.5624
Epoch   0 Batch   84/269 - Train Accuracy: 0.4560, Validation Accuracy: 0.4769, Loss: 2.5879
Epoch   0 Batch   85/269 - Train Accuracy: 0.4442, Validation Accuracy: 0.4767, Loss: 2.5916
Epoch   0 Batch   86/269 - Train Accuracy: 0.4494, Validation Accuracy: 0.4728, Loss: 2.5792
Epoch   0 Batch   87/269 - Train Accuracy: 0.3909, Validation Accuracy: 0.4667, Loss: 2.7354
Epoch   0 Batch   88/269 - Train Accuracy: 0.4483, Validation Accuracy: 0.4648, Loss: 2.5689
Epoch   0 Batch   89/269 - Train Accuracy: 0.4643, Validation Accuracy: 0.4801, Loss: 2.5399
Epoch   0 Batch   90/269 - Train Accuracy: 0.4162, Validation Accuracy: 0.4808, Loss: 2.6791
Epoch   0 Batch   91/269 - Train Accuracy: 0.4518, Validation Accuracy: 0.4752, Loss: 2.5248
Epoch   0 Batch   92/269 - Train Accuracy: 0.4525, Validation Accuracy: 0.4775, Loss: 2.5198
Epoch   0 Batch   93/269 - Train Accuracy: 0.4743, Validation Accuracy: 0.4825, Loss: 2.4282
Epoch   0 Batch   94/269 - Train Accuracy: 0.4644, Validation Accuracy: 0.4833, Loss: 2.4931
Epoch   0 Batch   95/269 - Train Accuracy: 0.4535, Validation Accuracy: 0.4785, Loss: 2.4889
Epoch   0 Batch   96/269 - Train Accuracy: 0.4553, Validation Accuracy: 0.4794, Loss: 2.4823
Epoch   0 Batch   97/269 - Train Accuracy: 0.4594, Validation Accuracy: 0.4795, Loss: 2.4660
Epoch   0 Batch   98/269 - Train Accuracy: 0.4634, Validation Accuracy: 0.4787, Loss: 2.4319
Epoch   0 Batch   99/269 - Train Accuracy: 0.4300, Validation Accuracy: 0.4834, Loss: 2.5870
Epoch   0 Batch  100/269 - Train Accuracy: 0.4832, Validation Accuracy: 0.4861, Loss: 2.3901
Epoch   0 Batch  101/269 - Train Accuracy: 0.4228, Validation Accuracy: 0.4767, Loss: 2.5665
Epoch   0 Batch  102/269 - Train Accuracy: 0.4592, Validation Accuracy: 0.4829, Loss: 2.4401
Epoch   0 Batch  103/269 - Train Accuracy: 0.4626, Validation Accuracy: 0.4808, Loss: 2.4231
Epoch   0 Batch  104/269 - Train Accuracy: 0.4488, Validation Accuracy: 0.4812, Loss: 2.4278
Epoch   0 Batch  105/269 - Train Accuracy: 0.4529, Validation Accuracy: 0.4859, Loss: 2.4338
Epoch   0 Batch  106/269 - Train Accuracy: 0.4544, Validation Accuracy: 0.4901, Loss: 2.4218
Epoch   0 Batch  107/269 - Train Accuracy: 0.4151, Validation Accuracy: 0.4820, Loss: 2.5388
Epoch   0 Batch  108/269 - Train Accuracy: 0.4593, Validation Accuracy: 0.4867, Loss: 2.4064
Epoch   0 Batch  109/269 - Train Accuracy: 0.4541, Validation Accuracy: 0.4866, Loss: 2.3880
Epoch   0 Batch  110/269 - Train Accuracy: 0.4488, Validation Accuracy: 0.4838, Loss: 2.3783
Epoch   0 Batch  111/269 - Train Accuracy: 0.4302, Validation Accuracy: 0.4843, Loss: 2.5120
Epoch   0 Batch  112/269 - Train Accuracy: 0.4636, Validation Accuracy: 0.4878, Loss: 2.3477
Epoch   0 Batch  113/269 - Train Accuracy: 0.4832, Validation Accuracy: 0.4885, Loss: 2.2506
Epoch   0 Batch  114/269 - Train Accuracy: 0.4625, Validation Accuracy: 0.4943, Loss: 2.3329
Epoch   0 Batch  115/269 - Train Accuracy: 0.4273, Validation Accuracy: 0.4869, Loss: 2.4452
Epoch   0 Batch  116/269 - Train Accuracy: 0.4769, Validation Accuracy: 0.4956, Loss: 2.3395
Epoch   0 Batch  117/269 - Train Accuracy: 0.4539, Validation Accuracy: 0.4890, Loss: 2.3327
Epoch   0 Batch  118/269 - Train Accuracy: 0.4812, Validation Accuracy: 0.4893, Loss: 2.2513
Epoch   0 Batch  119/269 - Train Accuracy: 0.4500, Validation Accuracy: 0.4916, Loss: 2.4051
Epoch   0 Batch  120/269 - Train Accuracy: 0.4330, Validation Accuracy: 0.4873, Loss: 2.4097
Epoch   0 Batch  121/269 - Train Accuracy: 0.4660, Validation Accuracy: 0.4933, Loss: 2.2843
Epoch   0 Batch  122/269 - Train Accuracy: 0.4748, Validation Accuracy: 0.4905, Loss: 2.2582
Epoch   0 Batch  123/269 - Train Accuracy: 0.4249, Validation Accuracy: 0.4903, Loss: 2.3993
Epoch   0 Batch  124/269 - Train Accuracy: 0.4733, Validation Accuracy: 0.4988, Loss: 2.2576
Epoch   0 Batch  125/269 - Train Accuracy: 0.4540, Validation Accuracy: 0.4867, Loss: 2.2461
Epoch   0 Batch  126/269 - Train Accuracy: 0.4740, Validation Accuracy: 0.4874, Loss: 2.2198
Epoch   0 Batch  127/269 - Train Accuracy: 0.4385, Validation Accuracy: 0.4877, Loss: 2.3597
Epoch   0 Batch  128/269 - Train Accuracy: 0.4765, Validation Accuracy: 0.4909, Loss: 2.2107
Epoch   0 Batch  129/269 - Train Accuracy: 0.4647, Validation Accuracy: 0.4967, Loss: 2.2413
Epoch   0 Batch  130/269 - Train Accuracy: 0.4225, Validation Accuracy: 0.4880, Loss: 2.3685
Epoch   0 Batch  131/269 - Train Accuracy: 0.4521, Validation Accuracy: 0.4938, Loss: 2.3164
Epoch   0 Batch  132/269 - Train Accuracy: 0.4542, Validation Accuracy: 0.4887, Loss: 2.2225
Epoch   0 Batch  133/269 - Train Accuracy: 0.4643, Validation Accuracy: 0.4893, Loss: 2.2018
Epoch   0 Batch  134/269 - Train Accuracy: 0.4339, Validation Accuracy: 0.4901, Loss: 2.2850
Epoch   0 Batch  135/269 - Train Accuracy: 0.4334, Validation Accuracy: 0.4943, Loss: 2.3274
Epoch   0 Batch  136/269 - Train Accuracy: 0.4357, Validation Accuracy: 0.4969, Loss: 2.3018
Epoch   0 Batch  137/269 - Train Accuracy: 0.4520, Validation Accuracy: 0.4996, Loss: 2.2673
Epoch   0 Batch  138/269 - Train Accuracy: 0.4590, Validation Accuracy: 0.4990, Loss: 2.2216
Epoch   0 Batch  139/269 - Train Accuracy: 0.4639, Validation Accuracy: 0.4846, Loss: 2.1255
Epoch   0 Batch  140/269 - Train Accuracy: 0.4696, Validation Accuracy: 0.4887, Loss: 2.1456
Epoch   0 Batch  141/269 - Train Accuracy: 0.4524, Validation Accuracy: 0.4873, Loss: 2.1877
Epoch   0 Batch  142/269 - Train Accuracy: 0.4639, Validation Accuracy: 0.4901, Loss: 2.1138
Epoch   0 Batch  143/269 - Train Accuracy: 0.4764, Validation Accuracy: 0.5041, Loss: 2.1328
Epoch   0 Batch  144/269 - Train Accuracy: 0.4688, Validation Accuracy: 0.4956, Loss: 2.1164
Epoch   0 Batch  145/269 - Train Accuracy: 0.4659, Validation Accuracy: 0.4980, Loss: 2.1204
Epoch   0 Batch  146/269 - Train Accuracy: 0.4694, Validation Accuracy: 0.4957, Loss: 2.0783
Epoch   0 Batch  147/269 - Train Accuracy: 0.4866, Validation Accuracy: 0.4907, Loss: 1.9982
Epoch   0 Batch  148/269 - Train Accuracy: 0.4584, Validation Accuracy: 0.4897, Loss: 2.1440
Epoch   0 Batch  149/269 - Train Accuracy: 0.4584, Validation Accuracy: 0.4837, Loss: 2.0843
Epoch   0 Batch  150/269 - Train Accuracy: 0.4765, Validation Accuracy: 0.5033, Loss: 2.0900
Epoch   0 Batch  151/269 - Train Accuracy: 0.5154, Validation Accuracy: 0.5090, Loss: 1.9720
Epoch   0 Batch  152/269 - Train Accuracy: 0.4475, Validation Accuracy: 0.4810, Loss: 2.0803
Epoch   0 Batch  153/269 - Train Accuracy: 0.4792, Validation Accuracy: 0.5021, Loss: 2.0697
Epoch   0 Batch  154/269 - Train Accuracy: 0.4464, Validation Accuracy: 0.5036, Loss: 2.1562
Epoch   0 Batch  155/269 - Train Accuracy: 0.4896, Validation Accuracy: 0.4917, Loss: 1.9451
Epoch   0 Batch  156/269 - Train Accuracy: 0.4604, Validation Accuracy: 0.5016, Loss: 2.1030
Epoch   0 Batch  157/269 - Train Accuracy: 0.4789, Validation Accuracy: 0.5053, Loss: 2.0173
Epoch   0 Batch  158/269 - Train Accuracy: 0.4639, Validation Accuracy: 0.4947, Loss: 2.0127
Epoch   0 Batch  159/269 - Train Accuracy: 0.4868, Validation Accuracy: 0.5114, Loss: 2.0261
Epoch   0 Batch  160/269 - Train Accuracy: 0.4826, Validation Accuracy: 0.5043, Loss: 2.0013
Epoch   0 Batch  161/269 - Train Accuracy: 0.4679, Validation Accuracy: 0.5061, Loss: 2.0274
Epoch   0 Batch  162/269 - Train Accuracy: 0.4789, Validation Accuracy: 0.5065, Loss: 1.9795
Epoch   0 Batch  163/269 - Train Accuracy: 0.4825, Validation Accuracy: 0.4974, Loss: 1.9755
Epoch   0 Batch  164/269 - Train Accuracy: 0.4781, Validation Accuracy: 0.5002, Loss: 1.9787
Epoch   0 Batch  165/269 - Train Accuracy: 0.4405, Validation Accuracy: 0.5030, Loss: 2.0453
Epoch   0 Batch  166/269 - Train Accuracy: 0.5074, Validation Accuracy: 0.5052, Loss: 1.8504
Epoch   0 Batch  167/269 - Train Accuracy: 0.4816, Validation Accuracy: 0.5042, Loss: 1.9344
Epoch   0 Batch  168/269 - Train Accuracy: 0.4781, Validation Accuracy: 0.5061, Loss: 1.9711
Epoch   0 Batch  169/269 - Train Accuracy: 0.4710, Validation Accuracy: 0.5055, Loss: 1.9376
Epoch   0 Batch  170/269 - Train Accuracy: 0.4810, Validation Accuracy: 0.5049, Loss: 1.9275
Epoch   0 Batch  171/269 - Train Accuracy: 0.4613, Validation Accuracy: 0.5061, Loss: 1.9937
Epoch   0 Batch  172/269 - Train Accuracy: 0.4725, Validation Accuracy: 0.5044, Loss: 1.9269
Epoch   0 Batch  173/269 - Train Accuracy: 0.4841, Validation Accuracy: 0.5056, Loss: 1.9184
Epoch   0 Batch  174/269 - Train Accuracy: 0.4772, Validation Accuracy: 0.5059, Loss: 1.9011
Epoch   0 Batch  175/269 - Train Accuracy: 0.4803, Validation Accuracy: 0.5057, Loss: 1.9028
Epoch   0 Batch  176/269 - Train Accuracy: 0.4554, Validation Accuracy: 0.5078, Loss: 1.9795
Epoch   0 Batch  177/269 - Train Accuracy: 0.4978, Validation Accuracy: 0.5082, Loss: 1.8110
Epoch   0 Batch  178/269 - Train Accuracy: 0.4521, Validation Accuracy: 0.5022, Loss: 1.9472
Epoch   0 Batch  179/269 - Train Accuracy: 0.4807, Validation Accuracy: 0.5054, Loss: 1.8743
Epoch   0 Batch  180/269 - Train Accuracy: 0.4795, Validation Accuracy: 0.5079, Loss: 1.8519
Epoch   0 Batch  181/269 - Train Accuracy: 0.4735, Validation Accuracy: 0.5038, Loss: 1.8517
Epoch   0 Batch  182/269 - Train Accuracy: 0.4714, Validation Accuracy: 0.4980, Loss: 1.8445
Epoch   0 Batch  183/269 - Train Accuracy: 0.5439, Validation Accuracy: 0.5050, Loss: 1.6045
Epoch   0 Batch  184/269 - Train Accuracy: 0.4519, Validation Accuracy: 0.5032, Loss: 1.9131
Epoch   0 Batch  185/269 - Train Accuracy: 0.4784, Validation Accuracy: 0.4946, Loss: 1.7946
Epoch   0 Batch  186/269 - Train Accuracy: 0.4418, Validation Accuracy: 0.5004, Loss: 1.8988
Epoch   0 Batch  187/269 - Train Accuracy: 0.4807, Validation Accuracy: 0.5076, Loss: 1.7731
Epoch   0 Batch  188/269 - Train Accuracy: 0.4772, Validation Accuracy: 0.4932, Loss: 1.7594
Epoch   0 Batch  189/269 - Train Accuracy: 0.4789, Validation Accuracy: 0.4894, Loss: 1.7817
Epoch   0 Batch  190/269 - Train Accuracy: 0.4726, Validation Accuracy: 0.4995, Loss: 1.7856
Epoch   0 Batch  191/269 - Train Accuracy: 0.4691, Validation Accuracy: 0.4947, Loss: 1.8049
Epoch   0 Batch  192/269 - Train Accuracy: 0.4657, Validation Accuracy: 0.4936, Loss: 1.7889
Epoch   0 Batch  193/269 - Train Accuracy: 0.4679, Validation Accuracy: 0.4997, Loss: 1.7817
Epoch   0 Batch  194/269 - Train Accuracy: 0.4764, Validation Accuracy: 0.5016, Loss: 1.7762
Epoch   0 Batch  195/269 - Train Accuracy: 0.4463, Validation Accuracy: 0.4935, Loss: 1.7943
Epoch   0 Batch  196/269 - Train Accuracy: 0.4695, Validation Accuracy: 0.5046, Loss: 1.7555
Epoch   0 Batch  197/269 - Train Accuracy: 0.4510, Validation Accuracy: 0.5016, Loss: 1.8267
Epoch   0 Batch  198/269 - Train Accuracy: 0.4416, Validation Accuracy: 0.5028, Loss: 1.8514
Epoch   0 Batch  199/269 - Train Accuracy: 0.4674, Validation Accuracy: 0.5017, Loss: 1.7778
Epoch   0 Batch  200/269 - Train Accuracy: 0.4525, Validation Accuracy: 0.4963, Loss: 1.7987
Epoch   0 Batch  201/269 - Train Accuracy: 0.4713, Validation Accuracy: 0.4920, Loss: 1.7334
Epoch   0 Batch  202/269 - Train Accuracy: 0.4627, Validation Accuracy: 0.4964, Loss: 1.7393
Epoch   0 Batch  203/269 - Train Accuracy: 0.4546, Validation Accuracy: 0.5059, Loss: 1.7906
Epoch   0 Batch  204/269 - Train Accuracy: 0.4386, Validation Accuracy: 0.5001, Loss: 1.7837
Epoch   0 Batch  205/269 - Train Accuracy: 0.4622, Validation Accuracy: 0.4988, Loss: 1.7089
Epoch   0 Batch  206/269 - Train Accuracy: 0.4458, Validation Accuracy: 0.4969, Loss: 1.8048
Epoch   0 Batch  207/269 - Train Accuracy: 0.4854, Validation Accuracy: 0.4987, Loss: 1.6408
Epoch   0 Batch  208/269 - Train Accuracy: 0.4493, Validation Accuracy: 0.5012, Loss: 1.8011
Epoch   0 Batch  209/269 - Train Accuracy: 0.4514, Validation Accuracy: 0.5012, Loss: 1.7525
Epoch   0 Batch  210/269 - Train Accuracy: 0.4753, Validation Accuracy: 0.4995, Loss: 1.6736
Epoch   0 Batch  211/269 - Train Accuracy: 0.4617, Validation Accuracy: 0.4920, Loss: 1.6723
Epoch   0 Batch  212/269 - Train Accuracy: 0.4848, Validation Accuracy: 0.4926, Loss: 1.6403
Epoch   0 Batch  213/269 - Train Accuracy: 0.4710, Validation Accuracy: 0.4933, Loss: 1.6537
Epoch   0 Batch  214/269 - Train Accuracy: 0.4769, Validation Accuracy: 0.4975, Loss: 1.6544
Epoch   0 Batch  215/269 - Train Accuracy: 0.5044, Validation Accuracy: 0.5008, Loss: 1.5673
Epoch   0 Batch  216/269 - Train Accuracy: 0.4540, Validation Accuracy: 0.5098, Loss: 1.7664
Epoch   0 Batch  217/269 - Train Accuracy: 0.4437, Validation Accuracy: 0.5000, Loss: 1.7360
Epoch   0 Batch  218/269 - Train Accuracy: 0.4557, Validation Accuracy: 0.5020, Loss: 1.7402
Epoch   0 Batch  219/269 - Train Accuracy: 0.4651, Validation Accuracy: 0.5099, Loss: 1.6977
Epoch   0 Batch  220/269 - Train Accuracy: 0.4873, Validation Accuracy: 0.5036, Loss: 1.5883
Epoch   0 Batch  221/269 - Train Accuracy: 0.4807, Validation Accuracy: 0.5026, Loss: 1.6270
Epoch   0 Batch  222/269 - Train Accuracy: 0.4880, Validation Accuracy: 0.5114, Loss: 1.5873
Epoch   0 Batch  223/269 - Train Accuracy: 0.4909, Validation Accuracy: 0.5107, Loss: 1.5858
Epoch   0 Batch  224/269 - Train Accuracy: 0.4877, Validation Accuracy: 0.5091, Loss: 1.6209
Epoch   0 Batch  225/269 - Train Accuracy: 0.4697, Validation Accuracy: 0.5173, Loss: 1.6816
Epoch   0 Batch  226/269 - Train Accuracy: 0.4868, Validation Accuracy: 0.5190, Loss: 1.6094
Epoch   0 Batch  227/269 - Train Accuracy: 0.5532, Validation Accuracy: 0.5041, Loss: 1.4092
Epoch   0 Batch  228/269 - Train Accuracy: 0.4762, Validation Accuracy: 0.5044, Loss: 1.6186
Epoch   0 Batch  229/269 - Train Accuracy: 0.4874, Validation Accuracy: 0.5075, Loss: 1.5995
Epoch   0 Batch  230/269 - Train Accuracy: 0.4752, Validation Accuracy: 0.5102, Loss: 1.6093
Epoch   0 Batch  231/269 - Train Accuracy: 0.4511, Validation Accuracy: 0.5074, Loss: 1.6736
Epoch   0 Batch  232/269 - Train Accuracy: 0.4497, Validation Accuracy: 0.5153, Loss: 1.6503
Epoch   0 Batch  233/269 - Train Accuracy: 0.4920, Validation Accuracy: 0.5131, Loss: 1.5962
Epoch   0 Batch  234/269 - Train Accuracy: 0.4693, Validation Accuracy: 0.4998, Loss: 1.5909
Epoch   0 Batch  235/269 - Train Accuracy: 0.4865, Validation Accuracy: 0.5063, Loss: 1.5873
Epoch   0 Batch  236/269 - Train Accuracy: 0.4829, Validation Accuracy: 0.5138, Loss: 1.5768
Epoch   0 Batch  237/269 - Train Accuracy: 0.4703, Validation Accuracy: 0.4983, Loss: 1.5737
Epoch   0 Batch  238/269 - Train Accuracy: 0.4821, Validation Accuracy: 0.5080, Loss: 1.5841
Epoch   0 Batch  239/269 - Train Accuracy: 0.5036, Validation Accuracy: 0.5198, Loss: 1.5568
Epoch   0 Batch  240/269 - Train Accuracy: 0.5234, Validation Accuracy: 0.5187, Loss: 1.4530
Epoch   0 Batch  241/269 - Train Accuracy: 0.4871, Validation Accuracy: 0.5055, Loss: 1.5444
Epoch   0 Batch  242/269 - Train Accuracy: 0.4754, Validation Accuracy: 0.5078, Loss: 1.5449
Epoch   0 Batch  243/269 - Train Accuracy: 0.4949, Validation Accuracy: 0.5028, Loss: 1.5163
Epoch   0 Batch  244/269 - Train Accuracy: 0.4731, Validation Accuracy: 0.5044, Loss: 1.5339
Epoch   0 Batch  245/269 - Train Accuracy: 0.4757, Validation Accuracy: 0.5177, Loss: 1.6176
Epoch   0 Batch  246/269 - Train Accuracy: 0.4906, Validation Accuracy: 0.5224, Loss: 1.5399
Epoch   0 Batch  247/269 - Train Accuracy: 0.4662, Validation Accuracy: 0.5143, Loss: 1.5879
Epoch   0 Batch  248/269 - Train Accuracy: 0.4799, Validation Accuracy: 0.5177, Loss: 1.5336
Epoch   0 Batch  249/269 - Train Accuracy: 0.5236, Validation Accuracy: 0.5187, Loss: 1.4682
Epoch   0 Batch  250/269 - Train Accuracy: 0.4615, Validation Accuracy: 0.5037, Loss: 1.5743
Epoch   0 Batch  251/269 - Train Accuracy: 0.4787, Validation Accuracy: 0.4991, Loss: 1.5016
Epoch   0 Batch  252/269 - Train Accuracy: 0.4759, Validation Accuracy: 0.5089, Loss: 1.5430
Epoch   0 Batch  253/269 - Train Accuracy: 0.4688, Validation Accuracy: 0.5004, Loss: 1.5157
Epoch   0 Batch  254/269 - Train Accuracy: 0.4678, Validation Accuracy: 0.5006, Loss: 1.4929
Epoch   0 Batch  255/269 - Train Accuracy: 0.5247, Validation Accuracy: 0.5201, Loss: 1.4474
Epoch   0 Batch  256/269 - Train Accuracy: 0.4750, Validation Accuracy: 0.5207, Loss: 1.5282
Epoch   0 Batch  257/269 - Train Accuracy: 0.4726, Validation Accuracy: 0.5086, Loss: 1.5025
Epoch   0 Batch  258/269 - Train Accuracy: 0.4764, Validation Accuracy: 0.5196, Loss: 1.5079
Epoch   0 Batch  259/269 - Train Accuracy: 0.4998, Validation Accuracy: 0.5186, Loss: 1.4843
Epoch   0 Batch  260/269 - Train Accuracy: 0.4678, Validation Accuracy: 0.5131, Loss: 1.5561
Epoch   0 Batch  261/269 - Train Accuracy: 0.4491, Validation Accuracy: 0.5167, Loss: 1.5744
Epoch   0 Batch  262/269 - Train Accuracy: 0.5025, Validation Accuracy: 0.5246, Loss: 1.4893
Epoch   0 Batch  263/269 - Train Accuracy: 0.4700, Validation Accuracy: 0.5151, Loss: 1.5379
Epoch   0 Batch  264/269 - Train Accuracy: 0.4733, Validation Accuracy: 0.5154, Loss: 1.5540
Epoch   0 Batch  265/269 - Train Accuracy: 0.4671, Validation Accuracy: 0.5162, Loss: 1.5159
Epoch   0 Batch  266/269 - Train Accuracy: 0.4850, Validation Accuracy: 0.5132, Loss: 1.4385
Epoch   0 Batch  267/269 - Train Accuracy: 0.4870, Validation Accuracy: 0.5152, Loss: 1.4830
Epoch   1 Batch    1/269 - Train Accuracy: 0.4578, Validation Accuracy: 0.5124, Loss: 1.5173
Epoch   1 Batch    2/269 - Train Accuracy: 0.4770, Validation Accuracy: 0.5179, Loss: 1.4861
Epoch   1 Batch    3/269 - Train Accuracy: 0.4776, Validation Accuracy: 0.5239, Loss: 1.5178
Epoch   1 Batch    4/269 - Train Accuracy: 0.4629, Validation Accuracy: 0.5182, Loss: 1.4998
Epoch   1 Batch    5/269 - Train Accuracy: 0.4606, Validation Accuracy: 0.5154, Loss: 1.5138
Epoch   1 Batch    6/269 - Train Accuracy: 0.5093, Validation Accuracy: 0.5224, Loss: 1.3856
Epoch   1 Batch    7/269 - Train Accuracy: 0.5007, Validation Accuracy: 0.5173, Loss: 1.4242
Epoch   1 Batch    8/269 - Train Accuracy: 0.4653, Validation Accuracy: 0.5142, Loss: 1.4902
Epoch   1 Batch    9/269 - Train Accuracy: 0.4914, Validation Accuracy: 0.5274, Loss: 1.4322
Epoch   1 Batch   10/269 - Train Accuracy: 0.4769, Validation Accuracy: 0.5248, Loss: 1.4527
Epoch   1 Batch   11/269 - Train Accuracy: 0.4871, Validation Accuracy: 0.5171, Loss: 1.4371
Epoch   1 Batch   12/269 - Train Accuracy: 0.4708, Validation Accuracy: 0.5233, Loss: 1.4897
Epoch   1 Batch   13/269 - Train Accuracy: 0.5309, Validation Accuracy: 0.5229, Loss: 1.3260
Epoch   1 Batch   14/269 - Train Accuracy: 0.4819, Validation Accuracy: 0.5201, Loss: 1.4111
Epoch   1 Batch   15/269 - Train Accuracy: 0.4868, Validation Accuracy: 0.5208, Loss: 1.4087
Epoch   1 Batch   16/269 - Train Accuracy: 0.5103, Validation Accuracy: 0.5225, Loss: 1.4071
Epoch   1 Batch   17/269 - Train Accuracy: 0.4881, Validation Accuracy: 0.5168, Loss: 1.3855
Epoch   1 Batch   18/269 - Train Accuracy: 0.4731, Validation Accuracy: 0.5265, Loss: 1.4501
Epoch   1 Batch   19/269 - Train Accuracy: 0.5173, Validation Accuracy: 0.5218, Loss: 1.3269
Epoch   1 Batch   20/269 - Train Accuracy: 0.4727, Validation Accuracy: 0.5167, Loss: 1.4447
Epoch   1 Batch   21/269 - Train Accuracy: 0.4713, Validation Accuracy: 0.5188, Loss: 1.4829
Epoch   1 Batch   22/269 - Train Accuracy: 0.5033, Validation Accuracy: 0.5286, Loss: 1.3776
Epoch   1 Batch   23/269 - Train Accuracy: 0.5086, Validation Accuracy: 0.5264, Loss: 1.3966
Epoch   1 Batch   24/269 - Train Accuracy: 0.4823, Validation Accuracy: 0.5302, Loss: 1.4430
Epoch   1 Batch   25/269 - Train Accuracy: 0.4813, Validation Accuracy: 0.5289, Loss: 1.4339
Epoch   1 Batch   26/269 - Train Accuracy: 0.5320, Validation Accuracy: 0.5278, Loss: 1.2937
Epoch   1 Batch   27/269 - Train Accuracy: 0.5010, Validation Accuracy: 0.5270, Loss: 1.3879
Epoch   1 Batch   28/269 - Train Accuracy: 0.4641, Validation Accuracy: 0.5305, Loss: 1.4522
Epoch   1 Batch   29/269 - Train Accuracy: 0.4846, Validation Accuracy: 0.5266, Loss: 1.4151
Epoch   1 Batch   30/269 - Train Accuracy: 0.5170, Validation Accuracy: 0.5293, Loss: 1.3502
Epoch   1 Batch   31/269 - Train Accuracy: 0.5190, Validation Accuracy: 0.5298, Loss: 1.3540
Epoch   1 Batch   32/269 - Train Accuracy: 0.5052, Validation Accuracy: 0.5289, Loss: 1.3668
Epoch   1 Batch   33/269 - Train Accuracy: 0.5156, Validation Accuracy: 0.5265, Loss: 1.3221
Epoch   1 Batch   34/269 - Train Accuracy: 0.5068, Validation Accuracy: 0.5234, Loss: 1.3394
Epoch   1 Batch   35/269 - Train Accuracy: 0.5145, Validation Accuracy: 0.5264, Loss: 1.3366
Epoch   1 Batch   36/269 - Train Accuracy: 0.5091, Validation Accuracy: 0.5294, Loss: 1.3483
Epoch   1 Batch   37/269 - Train Accuracy: 0.5099, Validation Accuracy: 0.5272, Loss: 1.3561
Epoch   1 Batch   38/269 - Train Accuracy: 0.5026, Validation Accuracy: 0.5334, Loss: 1.3389
Epoch   1 Batch   39/269 - Train Accuracy: 0.5118, Validation Accuracy: 0.5359, Loss: 1.3292
Epoch   1 Batch   40/269 - Train Accuracy: 0.4847, Validation Accuracy: 0.5328, Loss: 1.3791
Epoch   1 Batch   41/269 - Train Accuracy: 0.5032, Validation Accuracy: 0.5368, Loss: 1.3396
Epoch   1 Batch   42/269 - Train Accuracy: 0.5240, Validation Accuracy: 0.5301, Loss: 1.2667
Epoch   1 Batch   43/269 - Train Accuracy: 0.4943, Validation Accuracy: 0.5312, Loss: 1.3673
Epoch   1 Batch   44/269 - Train Accuracy: 0.5183, Validation Accuracy: 0.5295, Loss: 1.3219
Epoch   1 Batch   45/269 - Train Accuracy: 0.4843, Validation Accuracy: 0.5310, Loss: 1.3685
Epoch   1 Batch   46/269 - Train Accuracy: 0.4847, Validation Accuracy: 0.5297, Loss: 1.3813
Epoch   1 Batch   47/269 - Train Accuracy: 0.5286, Validation Accuracy: 0.5237, Loss: 1.2289
Epoch   1 Batch   48/269 - Train Accuracy: 0.5096, Validation Accuracy: 0.5287, Loss: 1.2803
Epoch   1 Batch   49/269 - Train Accuracy: 0.4905, Validation Accuracy: 0.5281, Loss: 1.3439
Epoch   1 Batch   50/269 - Train Accuracy: 0.4937, Validation Accuracy: 0.5319, Loss: 1.3615
Epoch   1 Batch   51/269 - Train Accuracy: 0.5028, Validation Accuracy: 0.5324, Loss: 1.3248
Epoch   1 Batch   52/269 - Train Accuracy: 0.5133, Validation Accuracy: 0.5352, Loss: 1.2844
Epoch   1 Batch   53/269 - Train Accuracy: 0.4928, Validation Accuracy: 0.5340, Loss: 1.3577
Epoch   1 Batch   54/269 - Train Accuracy: 0.5051, Validation Accuracy: 0.5365, Loss: 1.3459
Epoch   1 Batch   55/269 - Train Accuracy: 0.5168, Validation Accuracy: 0.5279, Loss: 1.2844
Epoch   1 Batch   56/269 - Train Accuracy: 0.5224, Validation Accuracy: 0.5268, Loss: 1.2918
Epoch   1 Batch   57/269 - Train Accuracy: 0.5224, Validation Accuracy: 0.5327, Loss: 1.2972
Epoch   1 Batch   58/269 - Train Accuracy: 0.5199, Validation Accuracy: 0.5373, Loss: 1.2715
Epoch   1 Batch   59/269 - Train Accuracy: 0.5233, Validation Accuracy: 0.5286, Loss: 1.2571
Epoch   1 Batch   60/269 - Train Accuracy: 0.5265, Validation Accuracy: 0.5347, Loss: 1.2262
Epoch   1 Batch   61/269 - Train Accuracy: 0.5361, Validation Accuracy: 0.5281, Loss: 1.2051
Epoch   1 Batch   62/269 - Train Accuracy: 0.5272, Validation Accuracy: 0.5298, Loss: 1.2338
Epoch   1 Batch   63/269 - Train Accuracy: 0.5114, Validation Accuracy: 0.5367, Loss: 1.2770
Epoch   1 Batch   64/269 - Train Accuracy: 0.5127, Validation Accuracy: 0.5349, Loss: 1.2611
Epoch   1 Batch   65/269 - Train Accuracy: 0.5127, Validation Accuracy: 0.5249, Loss: 1.2410
Epoch   1 Batch   66/269 - Train Accuracy: 0.5204, Validation Accuracy: 0.5251, Loss: 1.2163
Epoch   1 Batch   67/269 - Train Accuracy: 0.5053, Validation Accuracy: 0.5330, Loss: 1.2713
Epoch   1 Batch   68/269 - Train Accuracy: 0.5068, Validation Accuracy: 0.5275, Loss: 1.2711
Epoch   1 Batch   69/269 - Train Accuracy: 0.4868, Validation Accuracy: 0.5239, Loss: 1.3526
Epoch   1 Batch   70/269 - Train Accuracy: 0.5206, Validation Accuracy: 0.5303, Loss: 1.2386
Epoch   1 Batch   71/269 - Train Accuracy: 0.5042, Validation Accuracy: 0.5400, Loss: 1.3001
Epoch   1 Batch   72/269 - Train Accuracy: 0.5389, Validation Accuracy: 0.5385, Loss: 1.2084
Epoch   1 Batch   73/269 - Train Accuracy: 0.5192, Validation Accuracy: 0.5384, Loss: 1.2706
Epoch   1 Batch   74/269 - Train Accuracy: 0.5048, Validation Accuracy: 0.5321, Loss: 1.2664
Epoch   1 Batch   75/269 - Train Accuracy: 0.5126, Validation Accuracy: 0.5297, Loss: 1.2339
Epoch   1 Batch   76/269 - Train Accuracy: 0.5047, Validation Accuracy: 0.5330, Loss: 1.2541
Epoch   1 Batch   77/269 - Train Accuracy: 0.5293, Validation Accuracy: 0.5373, Loss: 1.2328
Epoch   1 Batch   78/269 - Train Accuracy: 0.5172, Validation Accuracy: 0.5392, Loss: 1.2384
Epoch   1 Batch   79/269 - Train Accuracy: 0.5327, Validation Accuracy: 0.5433, Loss: 1.2188
Epoch   1 Batch   80/269 - Train Accuracy: 0.5446, Validation Accuracy: 0.5426, Loss: 1.2055
Epoch   1 Batch   81/269 - Train Accuracy: 0.5202, Validation Accuracy: 0.5396, Loss: 1.2422
Epoch   1 Batch   82/269 - Train Accuracy: 0.5255, Validation Accuracy: 0.5356, Loss: 1.1858
Epoch   1 Batch   83/269 - Train Accuracy: 0.5405, Validation Accuracy: 0.5405, Loss: 1.1962
Epoch   1 Batch   84/269 - Train Accuracy: 0.5362, Validation Accuracy: 0.5450, Loss: 1.1919
Epoch   1 Batch   85/269 - Train Accuracy: 0.5156, Validation Accuracy: 0.5373, Loss: 1.2125
Epoch   1 Batch   86/269 - Train Accuracy: 0.5019, Validation Accuracy: 0.5384, Loss: 1.2269
Epoch   1 Batch   87/269 - Train Accuracy: 0.4930, Validation Accuracy: 0.5391, Loss: 1.2869
Epoch   1 Batch   88/269 - Train Accuracy: 0.5162, Validation Accuracy: 0.5389, Loss: 1.2094
Epoch   1 Batch   89/269 - Train Accuracy: 0.5236, Validation Accuracy: 0.5407, Loss: 1.1959
Epoch   1 Batch   90/269 - Train Accuracy: 0.4823, Validation Accuracy: 0.5463, Loss: 1.2748
Epoch   1 Batch   91/269 - Train Accuracy: 0.5193, Validation Accuracy: 0.5422, Loss: 1.1914
Epoch   1 Batch   92/269 - Train Accuracy: 0.5174, Validation Accuracy: 0.5405, Loss: 1.1907
Epoch   1 Batch   93/269 - Train Accuracy: 0.5455, Validation Accuracy: 0.5389, Loss: 1.1464
Epoch   1 Batch   94/269 - Train Accuracy: 0.5210, Validation Accuracy: 0.5391, Loss: 1.2105
Epoch   1 Batch   95/269 - Train Accuracy: 0.5254, Validation Accuracy: 0.5440, Loss: 1.1873
Epoch   1 Batch   96/269 - Train Accuracy: 0.5238, Validation Accuracy: 0.5435, Loss: 1.1711
Epoch   1 Batch   97/269 - Train Accuracy: 0.5278, Validation Accuracy: 0.5484, Loss: 1.1873
Epoch   1 Batch   98/269 - Train Accuracy: 0.5403, Validation Accuracy: 0.5395, Loss: 1.1517
Epoch   1 Batch   99/269 - Train Accuracy: 0.5115, Validation Accuracy: 0.5468, Loss: 1.2289
Epoch   1 Batch  100/269 - Train Accuracy: 0.5341, Validation Accuracy: 0.5474, Loss: 1.1421
Epoch   1 Batch  101/269 - Train Accuracy: 0.5041, Validation Accuracy: 0.5434, Loss: 1.2313
Epoch   1 Batch  102/269 - Train Accuracy: 0.5322, Validation Accuracy: 0.5446, Loss: 1.1567
Epoch   1 Batch  103/269 - Train Accuracy: 0.5288, Validation Accuracy: 0.5493, Loss: 1.1628
Epoch   1 Batch  104/269 - Train Accuracy: 0.5183, Validation Accuracy: 0.5488, Loss: 1.1714
Epoch   1 Batch  105/269 - Train Accuracy: 0.5177, Validation Accuracy: 0.5410, Loss: 1.1737
Epoch   1 Batch  106/269 - Train Accuracy: 0.5115, Validation Accuracy: 0.5361, Loss: 1.1566
Epoch   1 Batch  107/269 - Train Accuracy: 0.4899, Validation Accuracy: 0.5410, Loss: 1.2103
Epoch   1 Batch  108/269 - Train Accuracy: 0.5280, Validation Accuracy: 0.5468, Loss: 1.1464
Epoch   1 Batch  109/269 - Train Accuracy: 0.5089, Validation Accuracy: 0.5400, Loss: 1.1637
Epoch   1 Batch  110/269 - Train Accuracy: 0.5281, Validation Accuracy: 0.5470, Loss: 1.1414
Epoch   1 Batch  111/269 - Train Accuracy: 0.5038, Validation Accuracy: 0.5520, Loss: 1.2321
Epoch   1 Batch  112/269 - Train Accuracy: 0.5406, Validation Accuracy: 0.5542, Loss: 1.1404
Epoch   1 Batch  113/269 - Train Accuracy: 0.5471, Validation Accuracy: 0.5484, Loss: 1.0933
Epoch   1 Batch  114/269 - Train Accuracy: 0.5290, Validation Accuracy: 0.5513, Loss: 1.1349
Epoch   1 Batch  115/269 - Train Accuracy: 0.5157, Validation Accuracy: 0.5532, Loss: 1.1670
Epoch   1 Batch  116/269 - Train Accuracy: 0.5325, Validation Accuracy: 0.5490, Loss: 1.1376
Epoch   1 Batch  117/269 - Train Accuracy: 0.5307, Validation Accuracy: 0.5476, Loss: 1.1233
Epoch   1 Batch  118/269 - Train Accuracy: 0.5481, Validation Accuracy: 0.5445, Loss: 1.0962
Epoch   1 Batch  119/269 - Train Accuracy: 0.5219, Validation Accuracy: 0.5491, Loss: 1.1848
Epoch   1 Batch  120/269 - Train Accuracy: 0.5135, Validation Accuracy: 0.5429, Loss: 1.1698
Epoch   1 Batch  121/269 - Train Accuracy: 0.5230, Validation Accuracy: 0.5437, Loss: 1.1113
Epoch   1 Batch  122/269 - Train Accuracy: 0.5407, Validation Accuracy: 0.5507, Loss: 1.1070
Epoch   1 Batch  123/269 - Train Accuracy: 0.5110, Validation Accuracy: 0.5519, Loss: 1.1692
Epoch   1 Batch  124/269 - Train Accuracy: 0.5365, Validation Accuracy: 0.5513, Loss: 1.0877
Epoch   1 Batch  125/269 - Train Accuracy: 0.5352, Validation Accuracy: 0.5500, Loss: 1.0886
Epoch   1 Batch  126/269 - Train Accuracy: 0.5379, Validation Accuracy: 0.5483, Loss: 1.0868
Epoch   1 Batch  127/269 - Train Accuracy: 0.5059, Validation Accuracy: 0.5532, Loss: 1.1649
Epoch   1 Batch  128/269 - Train Accuracy: 0.5553, Validation Accuracy: 0.5557, Loss: 1.0968
Epoch   1 Batch  129/269 - Train Accuracy: 0.5322, Validation Accuracy: 0.5566, Loss: 1.1141
Epoch   1 Batch  130/269 - Train Accuracy: 0.5118, Validation Accuracy: 0.5536, Loss: 1.1695
Epoch   1 Batch  131/269 - Train Accuracy: 0.5255, Validation Accuracy: 0.5554, Loss: 1.1379
Epoch   1 Batch  132/269 - Train Accuracy: 0.5402, Validation Accuracy: 0.5562, Loss: 1.0957
Epoch   1 Batch  133/269 - Train Accuracy: 0.5346, Validation Accuracy: 0.5562, Loss: 1.0787
Epoch   1 Batch  134/269 - Train Accuracy: 0.5075, Validation Accuracy: 0.5586, Loss: 1.1410
Epoch   1 Batch  135/269 - Train Accuracy: 0.5038, Validation Accuracy: 0.5588, Loss: 1.1655
Epoch   1 Batch  136/269 - Train Accuracy: 0.5054, Validation Accuracy: 0.5555, Loss: 1.1622
Epoch   1 Batch  137/269 - Train Accuracy: 0.5239, Validation Accuracy: 0.5510, Loss: 1.1416
Epoch   1 Batch  138/269 - Train Accuracy: 0.5265, Validation Accuracy: 0.5529, Loss: 1.1155
Epoch   1 Batch  139/269 - Train Accuracy: 0.5494, Validation Accuracy: 0.5547, Loss: 1.0586
Epoch   1 Batch  140/269 - Train Accuracy: 0.5415, Validation Accuracy: 0.5519, Loss: 1.0887
Epoch   1 Batch  141/269 - Train Accuracy: 0.5302, Validation Accuracy: 0.5517, Loss: 1.0956
Epoch   1 Batch  142/269 - Train Accuracy: 0.5418, Validation Accuracy: 0.5531, Loss: 1.0588
Epoch   1 Batch  143/269 - Train Accuracy: 0.5309, Validation Accuracy: 0.5478, Loss: 1.0717
Epoch   1 Batch  144/269 - Train Accuracy: 0.5303, Validation Accuracy: 0.5425, Loss: 1.0552
Epoch   1 Batch  145/269 - Train Accuracy: 0.5318, Validation Accuracy: 0.5489, Loss: 1.0685
Epoch   1 Batch  146/269 - Train Accuracy: 0.5253, Validation Accuracy: 0.5488, Loss: 1.0495
Epoch   1 Batch  147/269 - Train Accuracy: 0.5534, Validation Accuracy: 0.5498, Loss: 1.0186
Epoch   1 Batch  148/269 - Train Accuracy: 0.5218, Validation Accuracy: 0.5534, Loss: 1.0933
Epoch   1 Batch  149/269 - Train Accuracy: 0.5379, Validation Accuracy: 0.5515, Loss: 1.0729
Epoch   1 Batch  150/269 - Train Accuracy: 0.5388, Validation Accuracy: 0.5525, Loss: 1.0704
Epoch   1 Batch  151/269 - Train Accuracy: 0.5676, Validation Accuracy: 0.5549, Loss: 1.0256
Epoch   1 Batch  152/269 - Train Accuracy: 0.5373, Validation Accuracy: 0.5526, Loss: 1.0552
Epoch   1 Batch  153/269 - Train Accuracy: 0.5429, Validation Accuracy: 0.5517, Loss: 1.0532
Epoch   1 Batch  154/269 - Train Accuracy: 0.5155, Validation Accuracy: 0.5524, Loss: 1.0900
Epoch   1 Batch  155/269 - Train Accuracy: 0.5643, Validation Accuracy: 0.5528, Loss: 0.9941
Epoch   1 Batch  156/269 - Train Accuracy: 0.5262, Validation Accuracy: 0.5570, Loss: 1.0889
Epoch   1 Batch  157/269 - Train Accuracy: 0.5375, Validation Accuracy: 0.5607, Loss: 1.0442
Epoch   1 Batch  158/269 - Train Accuracy: 0.5394, Validation Accuracy: 0.5615, Loss: 1.0360
Epoch   1 Batch  159/269 - Train Accuracy: 0.5390, Validation Accuracy: 0.5542, Loss: 1.0551
Epoch   1 Batch  160/269 - Train Accuracy: 0.5397, Validation Accuracy: 0.5516, Loss: 1.0474
Epoch   1 Batch  161/269 - Train Accuracy: 0.5275, Validation Accuracy: 0.5468, Loss: 1.0460
Epoch   1 Batch  162/269 - Train Accuracy: 0.5286, Validation Accuracy: 0.5475, Loss: 1.0358
Epoch   1 Batch  163/269 - Train Accuracy: 0.5454, Validation Accuracy: 0.5553, Loss: 1.0306
Epoch   1 Batch  164/269 - Train Accuracy: 0.5504, Validation Accuracy: 0.5577, Loss: 1.0326
Epoch   1 Batch  165/269 - Train Accuracy: 0.5178, Validation Accuracy: 0.5581, Loss: 1.0664
Epoch   1 Batch  166/269 - Train Accuracy: 0.5635, Validation Accuracy: 0.5561, Loss: 0.9799
Epoch   1 Batch  167/269 - Train Accuracy: 0.5469, Validation Accuracy: 0.5592, Loss: 1.0362
Epoch   1 Batch  168/269 - Train Accuracy: 0.5286, Validation Accuracy: 0.5538, Loss: 1.0477
Epoch   1 Batch  169/269 - Train Accuracy: 0.5366, Validation Accuracy: 0.5573, Loss: 1.0301
Epoch   1 Batch  170/269 - Train Accuracy: 0.5427, Validation Accuracy: 0.5570, Loss: 1.0240
Epoch   1 Batch  171/269 - Train Accuracy: 0.5340, Validation Accuracy: 0.5586, Loss: 1.0649
Epoch   1 Batch  172/269 - Train Accuracy: 0.5369, Validation Accuracy: 0.5559, Loss: 1.0308
Epoch   1 Batch  173/269 - Train Accuracy: 0.5313, Validation Accuracy: 0.5528, Loss: 1.0101
Epoch   1 Batch  174/269 - Train Accuracy: 0.5305, Validation Accuracy: 0.5528, Loss: 1.0237
Epoch   1 Batch  175/269 - Train Accuracy: 0.5312, Validation Accuracy: 0.5546, Loss: 1.0267
Epoch   1 Batch  176/269 - Train Accuracy: 0.5229, Validation Accuracy: 0.5483, Loss: 1.0613
Epoch   1 Batch  177/269 - Train Accuracy: 0.5404, Validation Accuracy: 0.5475, Loss: 0.9771
Epoch   1 Batch  178/269 - Train Accuracy: 0.5209, Validation Accuracy: 0.5493, Loss: 1.0413
Epoch   1 Batch  179/269 - Train Accuracy: 0.5328, Validation Accuracy: 0.5499, Loss: 1.0135
Epoch   1 Batch  180/269 - Train Accuracy: 0.5328, Validation Accuracy: 0.5549, Loss: 0.9946
Epoch   1 Batch  181/269 - Train Accuracy: 0.5217, Validation Accuracy: 0.5532, Loss: 1.0111
Epoch   1 Batch  182/269 - Train Accuracy: 0.5286, Validation Accuracy: 0.5532, Loss: 1.0149
Epoch   1 Batch  183/269 - Train Accuracy: 0.6023, Validation Accuracy: 0.5530, Loss: 0.8692
Epoch   1 Batch  184/269 - Train Accuracy: 0.5220, Validation Accuracy: 0.5588, Loss: 1.0455
Epoch   1 Batch  185/269 - Train Accuracy: 0.5488, Validation Accuracy: 0.5589, Loss: 0.9929
Epoch   1 Batch  186/269 - Train Accuracy: 0.5109, Validation Accuracy: 0.5597, Loss: 1.0324
Epoch   1 Batch  187/269 - Train Accuracy: 0.5428, Validation Accuracy: 0.5567, Loss: 0.9778
Epoch   1 Batch  188/269 - Train Accuracy: 0.5519, Validation Accuracy: 0.5616, Loss: 0.9666
Epoch   1 Batch  189/269 - Train Accuracy: 0.5543, Validation Accuracy: 0.5596, Loss: 0.9811
Epoch   1 Batch  190/269 - Train Accuracy: 0.5392, Validation Accuracy: 0.5602, Loss: 0.9785
Epoch   1 Batch  191/269 - Train Accuracy: 0.5395, Validation Accuracy: 0.5596, Loss: 0.9820
Epoch   1 Batch  192/269 - Train Accuracy: 0.5475, Validation Accuracy: 0.5612, Loss: 0.9957
Epoch   1 Batch  193/269 - Train Accuracy: 0.5469, Validation Accuracy: 0.5615, Loss: 0.9882
Epoch   1 Batch  194/269 - Train Accuracy: 0.5531, Validation Accuracy: 0.5608, Loss: 0.9954
Epoch   1 Batch  195/269 - Train Accuracy: 0.5245, Validation Accuracy: 0.5590, Loss: 0.9968
Epoch   1 Batch  196/269 - Train Accuracy: 0.5229, Validation Accuracy: 0.5561, Loss: 0.9753
Epoch   1 Batch  197/269 - Train Accuracy: 0.5169, Validation Accuracy: 0.5645, Loss: 1.0294
Epoch   1 Batch  198/269 - Train Accuracy: 0.5171, Validation Accuracy: 0.5661, Loss: 1.0417
Epoch   1 Batch  199/269 - Train Accuracy: 0.5436, Validation Accuracy: 0.5698, Loss: 0.9999
Epoch   1 Batch  200/269 - Train Accuracy: 0.5390, Validation Accuracy: 0.5726, Loss: 1.0068
Epoch   1 Batch  201/269 - Train Accuracy: 0.5419, Validation Accuracy: 0.5733, Loss: 0.9799
Epoch   1 Batch  202/269 - Train Accuracy: 0.5476, Validation Accuracy: 0.5699, Loss: 0.9778
Epoch   1 Batch  203/269 - Train Accuracy: 0.5246, Validation Accuracy: 0.5656, Loss: 1.0348
Epoch   1 Batch  204/269 - Train Accuracy: 0.5256, Validation Accuracy: 0.5669, Loss: 1.0091
Epoch   1 Batch  205/269 - Train Accuracy: 0.5332, Validation Accuracy: 0.5682, Loss: 0.9642
Epoch   1 Batch  206/269 - Train Accuracy: 0.5228, Validation Accuracy: 0.5699, Loss: 1.0271
Epoch   1 Batch  207/269 - Train Accuracy: 0.5755, Validation Accuracy: 0.5667, Loss: 0.9367
Epoch   1 Batch  208/269 - Train Accuracy: 0.5224, Validation Accuracy: 0.5695, Loss: 1.0268
Epoch   1 Batch  209/269 - Train Accuracy: 0.5234, Validation Accuracy: 0.5635, Loss: 0.9893
Epoch   1 Batch  210/269 - Train Accuracy: 0.5516, Validation Accuracy: 0.5614, Loss: 0.9579
Epoch   1 Batch  211/269 - Train Accuracy: 0.5438, Validation Accuracy: 0.5597, Loss: 0.9740
Epoch   1 Batch  212/269 - Train Accuracy: 0.5676, Validation Accuracy: 0.5604, Loss: 0.9500
Epoch   1 Batch  213/269 - Train Accuracy: 0.5488, Validation Accuracy: 0.5569, Loss: 0.9502
Epoch   1 Batch  214/269 - Train Accuracy: 0.5434, Validation Accuracy: 0.5547, Loss: 0.9500
Epoch   1 Batch  215/269 - Train Accuracy: 0.5651, Validation Accuracy: 0.5644, Loss: 0.9016
Epoch   1 Batch  216/269 - Train Accuracy: 0.5217, Validation Accuracy: 0.5726, Loss: 1.0311
Epoch   1 Batch  217/269 - Train Accuracy: 0.5233, Validation Accuracy: 0.5703, Loss: 0.9948
Epoch   1 Batch  218/269 - Train Accuracy: 0.5437, Validation Accuracy: 0.5700, Loss: 0.9941
Epoch   1 Batch  219/269 - Train Accuracy: 0.5481, Validation Accuracy: 0.5691, Loss: 0.9917
Epoch   1 Batch  220/269 - Train Accuracy: 0.5585, Validation Accuracy: 0.5690, Loss: 0.9058
Epoch   1 Batch  221/269 - Train Accuracy: 0.5685, Validation Accuracy: 0.5705, Loss: 0.9390
Epoch   1 Batch  222/269 - Train Accuracy: 0.5614, Validation Accuracy: 0.5656, Loss: 0.9151
Epoch   1 Batch  223/269 - Train Accuracy: 0.5530, Validation Accuracy: 0.5583, Loss: 0.9225
Epoch   1 Batch  224/269 - Train Accuracy: 0.5605, Validation Accuracy: 0.5657, Loss: 0.9652
Epoch   1 Batch  225/269 - Train Accuracy: 0.5379, Validation Accuracy: 0.5684, Loss: 0.9761
Epoch   1 Batch  226/269 - Train Accuracy: 0.5460, Validation Accuracy: 0.5697, Loss: 0.9473
Epoch   1 Batch  227/269 - Train Accuracy: 0.6117, Validation Accuracy: 0.5684, Loss: 0.8344
Epoch   1 Batch  228/269 - Train Accuracy: 0.5552, Validation Accuracy: 0.5696, Loss: 0.9400
Epoch   1 Batch  229/269 - Train Accuracy: 0.5511, Validation Accuracy: 0.5750, Loss: 0.9330
Epoch   1 Batch  230/269 - Train Accuracy: 0.5522, Validation Accuracy: 0.5690, Loss: 0.9394
Epoch   1 Batch  231/269 - Train Accuracy: 0.5186, Validation Accuracy: 0.5616, Loss: 0.9828
Epoch   1 Batch  232/269 - Train Accuracy: 0.5157, Validation Accuracy: 0.5703, Loss: 0.9741
Epoch   1 Batch  233/269 - Train Accuracy: 0.5536, Validation Accuracy: 0.5746, Loss: 0.9463
Epoch   1 Batch  234/269 - Train Accuracy: 0.5559, Validation Accuracy: 0.5731, Loss: 0.9366
Epoch   1 Batch  235/269 - Train Accuracy: 0.5499, Validation Accuracy: 0.5729, Loss: 0.9328
Epoch   1 Batch  236/269 - Train Accuracy: 0.5446, Validation Accuracy: 0.5685, Loss: 0.9220
Epoch   1 Batch  237/269 - Train Accuracy: 0.5402, Validation Accuracy: 0.5662, Loss: 0.9221
Epoch   1 Batch  238/269 - Train Accuracy: 0.5567, Validation Accuracy: 0.5691, Loss: 0.9221
Epoch   1 Batch  239/269 - Train Accuracy: 0.5657, Validation Accuracy: 0.5697, Loss: 0.9154
Epoch   1 Batch  240/269 - Train Accuracy: 0.5859, Validation Accuracy: 0.5697, Loss: 0.8565
Epoch   1 Batch  241/269 - Train Accuracy: 0.5537, Validation Accuracy: 0.5698, Loss: 0.9349
Epoch   1 Batch  242/269 - Train Accuracy: 0.5459, Validation Accuracy: 0.5716, Loss: 0.9287
Epoch   1 Batch  243/269 - Train Accuracy: 0.5751, Validation Accuracy: 0.5735, Loss: 0.8925
Epoch   1 Batch  244/269 - Train Accuracy: 0.5518, Validation Accuracy: 0.5724, Loss: 0.9131
Epoch   1 Batch  245/269 - Train Accuracy: 0.5491, Validation Accuracy: 0.5724, Loss: 0.9721
Epoch   1 Batch  246/269 - Train Accuracy: 0.5428, Validation Accuracy: 0.5695, Loss: 0.9277
Epoch   1 Batch  247/269 - Train Accuracy: 0.5509, Validation Accuracy: 0.5766, Loss: 0.9582
Epoch   1 Batch  248/269 - Train Accuracy: 0.5625, Validation Accuracy: 0.5789, Loss: 0.9106
Epoch   1 Batch  249/269 - Train Accuracy: 0.6048, Validation Accuracy: 0.5830, Loss: 0.8715
Epoch   1 Batch  250/269 - Train Accuracy: 0.5506, Validation Accuracy: 0.5823, Loss: 0.9373
Epoch   1 Batch  251/269 - Train Accuracy: 0.5714, Validation Accuracy: 0.5771, Loss: 0.8922
Epoch   1 Batch  252/269 - Train Accuracy: 0.5552, Validation Accuracy: 0.5760, Loss: 0.9135
Epoch   1 Batch  253/269 - Train Accuracy: 0.5676, Validation Accuracy: 0.5810, Loss: 0.9199
Epoch   1 Batch  254/269 - Train Accuracy: 0.5652, Validation Accuracy: 0.5809, Loss: 0.9017
Epoch   1 Batch  255/269 - Train Accuracy: 0.5899, Validation Accuracy: 0.5776, Loss: 0.8665
Epoch   1 Batch  256/269 - Train Accuracy: 0.5445, Validation Accuracy: 0.5771, Loss: 0.9147
Epoch   1 Batch  257/269 - Train Accuracy: 0.5497, Validation Accuracy: 0.5848, Loss: 0.9136
Epoch   1 Batch  258/269 - Train Accuracy: 0.5535, Validation Accuracy: 0.5804, Loss: 0.9047
Epoch   1 Batch  259/269 - Train Accuracy: 0.5789, Validation Accuracy: 0.5773, Loss: 0.9018
Epoch   1 Batch  260/269 - Train Accuracy: 0.5491, Validation Accuracy: 0.5781, Loss: 0.9501
Epoch   1 Batch  261/269 - Train Accuracy: 0.5256, Validation Accuracy: 0.5767, Loss: 0.9667
Epoch   1 Batch  262/269 - Train Accuracy: 0.5747, Validation Accuracy: 0.5803, Loss: 0.9134
Epoch   1 Batch  263/269 - Train Accuracy: 0.5775, Validation Accuracy: 0.5825, Loss: 0.9339
Epoch   1 Batch  264/269 - Train Accuracy: 0.5485, Validation Accuracy: 0.5894, Loss: 0.9451
Epoch   1 Batch  265/269 - Train Accuracy: 0.5539, Validation Accuracy: 0.5842, Loss: 0.9268
Epoch   1 Batch  266/269 - Train Accuracy: 0.5762, Validation Accuracy: 0.5764, Loss: 0.8808
Epoch   1 Batch  267/269 - Train Accuracy: 0.5557, Validation Accuracy: 0.5722, Loss: 0.9194
Epoch   2 Batch    1/269 - Train Accuracy: 0.5531, Validation Accuracy: 0.5802, Loss: 0.9217
Epoch   2 Batch    2/269 - Train Accuracy: 0.5552, Validation Accuracy: 0.5852, Loss: 0.9074
Epoch   2 Batch    3/269 - Train Accuracy: 0.5633, Validation Accuracy: 0.5836, Loss: 0.9206
Epoch   2 Batch    4/269 - Train Accuracy: 0.5484, Validation Accuracy: 0.5822, Loss: 0.9245
Epoch   2 Batch    5/269 - Train Accuracy: 0.5421, Validation Accuracy: 0.5808, Loss: 0.9260
Epoch   2 Batch    6/269 - Train Accuracy: 0.5725, Validation Accuracy: 0.5837, Loss: 0.8492
Epoch   2 Batch    7/269 - Train Accuracy: 0.5852, Validation Accuracy: 0.5839, Loss: 0.8746
Epoch   2 Batch    8/269 - Train Accuracy: 0.5510, Validation Accuracy: 0.5787, Loss: 0.9291
Epoch   2 Batch    9/269 - Train Accuracy: 0.5714, Validation Accuracy: 0.5819, Loss: 0.9048
Epoch   2 Batch   10/269 - Train Accuracy: 0.5542, Validation Accuracy: 0.5802, Loss: 0.9035
Epoch   2 Batch   11/269 - Train Accuracy: 0.5655, Validation Accuracy: 0.5806, Loss: 0.9052
Epoch   2 Batch   12/269 - Train Accuracy: 0.5456, Validation Accuracy: 0.5825, Loss: 0.9191
Epoch   2 Batch   13/269 - Train Accuracy: 0.5848, Validation Accuracy: 0.5678, Loss: 0.8226
Epoch   2 Batch   14/269 - Train Accuracy: 0.5470, Validation Accuracy: 0.5659, Loss: 0.8752
Epoch   2 Batch   15/269 - Train Accuracy: 0.5556, Validation Accuracy: 0.5680, Loss: 0.8702
Epoch   2 Batch   16/269 - Train Accuracy: 0.5817, Validation Accuracy: 0.5740, Loss: 0.8747
Epoch   2 Batch   17/269 - Train Accuracy: 0.5707, Validation Accuracy: 0.5788, Loss: 0.8594
Epoch   2 Batch   18/269 - Train Accuracy: 0.5543, Validation Accuracy: 0.5808, Loss: 0.9069
Epoch   2 Batch   19/269 - Train Accuracy: 0.5966, Validation Accuracy: 0.5769, Loss: 0.8292
Epoch   2 Batch   20/269 - Train Accuracy: 0.5524, Validation Accuracy: 0.5639, Loss: 0.9047
Epoch   2 Batch   21/269 - Train Accuracy: 0.5551, Validation Accuracy: 0.5677, Loss: 0.9330
Epoch   2 Batch   22/269 - Train Accuracy: 0.5675, Validation Accuracy: 0.5714, Loss: 0.8576
Epoch   2 Batch   23/269 - Train Accuracy: 0.5849, Validation Accuracy: 0.5767, Loss: 0.8717
Epoch   2 Batch   24/269 - Train Accuracy: 0.5602, Validation Accuracy: 0.5743, Loss: 0.9060
Epoch   2 Batch   25/269 - Train Accuracy: 0.5514, Validation Accuracy: 0.5693, Loss: 0.9122
Epoch   2 Batch   26/269 - Train Accuracy: 0.6055, Validation Accuracy: 0.5726, Loss: 0.8118
Epoch   2 Batch   27/269 - Train Accuracy: 0.5706, Validation Accuracy: 0.5846, Loss: 0.8667
Epoch   2 Batch   28/269 - Train Accuracy: 0.5483, Validation Accuracy: 0.5917, Loss: 0.9225
Epoch   2 Batch   29/269 - Train Accuracy: 0.5655, Validation Accuracy: 0.5909, Loss: 0.8878
Epoch   2 Batch   30/269 - Train Accuracy: 0.5786, Validation Accuracy: 0.5786, Loss: 0.8502
Epoch   2 Batch   31/269 - Train Accuracy: 0.5802, Validation Accuracy: 0.5778, Loss: 0.8504
Epoch   2 Batch   32/269 - Train Accuracy: 0.5749, Validation Accuracy: 0.5755, Loss: 0.8577
Epoch   2 Batch   33/269 - Train Accuracy: 0.5821, Validation Accuracy: 0.5758, Loss: 0.8287
Epoch   2 Batch   34/269 - Train Accuracy: 0.5768, Validation Accuracy: 0.5785, Loss: 0.8523
Epoch   2 Batch   35/269 - Train Accuracy: 0.5847, Validation Accuracy: 0.5787, Loss: 0.8637
Epoch   2 Batch   36/269 - Train Accuracy: 0.5696, Validation Accuracy: 0.5738, Loss: 0.8632
Epoch   2 Batch   37/269 - Train Accuracy: 0.5823, Validation Accuracy: 0.5771, Loss: 0.8643
Epoch   2 Batch   38/269 - Train Accuracy: 0.5812, Validation Accuracy: 0.5795, Loss: 0.8536
Epoch   2 Batch   39/269 - Train Accuracy: 0.5806, Validation Accuracy: 0.5753, Loss: 0.8498
Epoch   2 Batch   40/269 - Train Accuracy: 0.5645, Validation Accuracy: 0.5737, Loss: 0.8858
Epoch   2 Batch   41/269 - Train Accuracy: 0.5687, Validation Accuracy: 0.5708, Loss: 0.8674
Epoch   2 Batch   42/269 - Train Accuracy: 0.5897, Validation Accuracy: 0.5787, Loss: 0.8064
Epoch   2 Batch   43/269 - Train Accuracy: 0.5574, Validation Accuracy: 0.5826, Loss: 0.8846
Epoch   2 Batch   44/269 - Train Accuracy: 0.5884, Validation Accuracy: 0.5863, Loss: 0.8560
Epoch   2 Batch   45/269 - Train Accuracy: 0.5591, Validation Accuracy: 0.5854, Loss: 0.8866
Epoch   2 Batch   46/269 - Train Accuracy: 0.5604, Validation Accuracy: 0.5730, Loss: 0.8655
Epoch   2 Batch   47/269 - Train Accuracy: 0.6005, Validation Accuracy: 0.5719, Loss: 0.7930
Epoch   2 Batch   48/269 - Train Accuracy: 0.5837, Validation Accuracy: 0.5797, Loss: 0.8252
Epoch   2 Batch   49/269 - Train Accuracy: 0.5649, Validation Accuracy: 0.5862, Loss: 0.8690
Epoch   2 Batch   50/269 - Train Accuracy: 0.5613, Validation Accuracy: 0.5831, Loss: 0.8899
Epoch   2 Batch   51/269 - Train Accuracy: 0.5617, Validation Accuracy: 0.5788, Loss: 0.8612
Epoch   2 Batch   52/269 - Train Accuracy: 0.5667, Validation Accuracy: 0.5761, Loss: 0.8229
Epoch   2 Batch   53/269 - Train Accuracy: 0.5569, Validation Accuracy: 0.5748, Loss: 0.8858
Epoch   2 Batch   54/269 - Train Accuracy: 0.5827, Validation Accuracy: 0.5869, Loss: 0.8739
Epoch   2 Batch   55/269 - Train Accuracy: 0.5888, Validation Accuracy: 0.5801, Loss: 0.8366
Epoch   2 Batch   56/269 - Train Accuracy: 0.5902, Validation Accuracy: 0.5806, Loss: 0.8433
Epoch   2 Batch   57/269 - Train Accuracy: 0.5881, Validation Accuracy: 0.5798, Loss: 0.8572
Epoch   2 Batch   58/269 - Train Accuracy: 0.5849, Validation Accuracy: 0.5819, Loss: 0.8362
Epoch   2 Batch   59/269 - Train Accuracy: 0.5954, Validation Accuracy: 0.5914, Loss: 0.8074
Epoch   2 Batch   60/269 - Train Accuracy: 0.5943, Validation Accuracy: 0.5858, Loss: 0.7977
Epoch   2 Batch   61/269 - Train Accuracy: 0.5956, Validation Accuracy: 0.5788, Loss: 0.7870
Epoch   2 Batch   62/269 - Train Accuracy: 0.5912, Validation Accuracy: 0.5793, Loss: 0.8090
Epoch   2 Batch   63/269 - Train Accuracy: 0.5717, Validation Accuracy: 0.5864, Loss: 0.8465
Epoch   2 Batch   64/269 - Train Accuracy: 0.5763, Validation Accuracy: 0.5918, Loss: 0.8205
Epoch   2 Batch   65/269 - Train Accuracy: 0.5894, Validation Accuracy: 0.5904, Loss: 0.8190
Epoch   2 Batch   66/269 - Train Accuracy: 0.5929, Validation Accuracy: 0.5841, Loss: 0.8040
Epoch   2 Batch   67/269 - Train Accuracy: 0.5683, Validation Accuracy: 0.5834, Loss: 0.8380
Epoch   2 Batch   68/269 - Train Accuracy: 0.5760, Validation Accuracy: 0.5837, Loss: 0.8449
Epoch   2 Batch   69/269 - Train Accuracy: 0.5617, Validation Accuracy: 0.5970, Loss: 0.9064
Epoch   2 Batch   70/269 - Train Accuracy: 0.6110, Validation Accuracy: 0.5996, Loss: 0.8372
Epoch   2 Batch   71/269 - Train Accuracy: 0.5744, Validation Accuracy: 0.5993, Loss: 0.8639
Epoch   2 Batch   72/269 - Train Accuracy: 0.5979, Validation Accuracy: 0.5985, Loss: 0.8095
Epoch   2 Batch   73/269 - Train Accuracy: 0.5850, Validation Accuracy: 0.5902, Loss: 0.8480
Epoch   2 Batch   74/269 - Train Accuracy: 0.5760, Validation Accuracy: 0.5911, Loss: 0.8411
Epoch   2 Batch   75/269 - Train Accuracy: 0.5852, Validation Accuracy: 0.5939, Loss: 0.8214
Epoch   2 Batch   76/269 - Train Accuracy: 0.5753, Validation Accuracy: 0.5957, Loss: 0.8400
Epoch   2 Batch   77/269 - Train Accuracy: 0.6143, Validation Accuracy: 0.5941, Loss: 0.8214
Epoch   2 Batch   78/269 - Train Accuracy: 0.5891, Validation Accuracy: 0.5986, Loss: 0.8176
Epoch   2 Batch   79/269 - Train Accuracy: 0.5962, Validation Accuracy: 0.5994, Loss: 0.8109
Epoch   2 Batch   80/269 - Train Accuracy: 0.6016, Validation Accuracy: 0.6023, Loss: 0.8139
Epoch   2 Batch   81/269 - Train Accuracy: 0.5945, Validation Accuracy: 0.6041, Loss: 0.8387
Epoch   2 Batch   82/269 - Train Accuracy: 0.6049, Validation Accuracy: 0.6059, Loss: 0.7915
Epoch   2 Batch   83/269 - Train Accuracy: 0.5938, Validation Accuracy: 0.6026, Loss: 0.8144
Epoch   2 Batch   84/269 - Train Accuracy: 0.6017, Validation Accuracy: 0.6009, Loss: 0.8025
Epoch   2 Batch   85/269 - Train Accuracy: 0.5795, Validation Accuracy: 0.5958, Loss: 0.8190
Epoch   2 Batch   86/269 - Train Accuracy: 0.5553, Validation Accuracy: 0.5961, Loss: 0.8180
Epoch   2 Batch   87/269 - Train Accuracy: 0.5614, Validation Accuracy: 0.5945, Loss: 0.8768
Epoch   2 Batch   88/269 - Train Accuracy: 0.5831, Validation Accuracy: 0.5949, Loss: 0.8195
Epoch   2 Batch   89/269 - Train Accuracy: 0.6011, Validation Accuracy: 0.5974, Loss: 0.8176
Epoch   2 Batch   90/269 - Train Accuracy: 0.5557, Validation Accuracy: 0.5981, Loss: 0.8649
Epoch   2 Batch   91/269 - Train Accuracy: 0.5994, Validation Accuracy: 0.6048, Loss: 0.7986
Epoch   2 Batch   92/269 - Train Accuracy: 0.5927, Validation Accuracy: 0.6075, Loss: 0.8003
Epoch   2 Batch   93/269 - Train Accuracy: 0.6069, Validation Accuracy: 0.6050, Loss: 0.7763
Epoch   2 Batch   94/269 - Train Accuracy: 0.5943, Validation Accuracy: 0.6042, Loss: 0.8335
Epoch   2 Batch   95/269 - Train Accuracy: 0.5884, Validation Accuracy: 0.6037, Loss: 0.8139
Epoch   2 Batch   96/269 - Train Accuracy: 0.5964, Validation Accuracy: 0.6062, Loss: 0.8065
Epoch   2 Batch   97/269 - Train Accuracy: 0.5817, Validation Accuracy: 0.6096, Loss: 0.8117
Epoch   2 Batch   98/269 - Train Accuracy: 0.6045, Validation Accuracy: 0.6095, Loss: 0.8100
Epoch   2 Batch   99/269 - Train Accuracy: 0.5841, Validation Accuracy: 0.6036, Loss: 0.8446
Epoch   2 Batch  100/269 - Train Accuracy: 0.6082, Validation Accuracy: 0.5998, Loss: 0.7986
Epoch   2 Batch  101/269 - Train Accuracy: 0.5611, Validation Accuracy: 0.6016, Loss: 0.8509
Epoch   2 Batch  102/269 - Train Accuracy: 0.5884, Validation Accuracy: 0.5973, Loss: 0.8015
Epoch   2 Batch  103/269 - Train Accuracy: 0.5878, Validation Accuracy: 0.5985, Loss: 0.8000
Epoch   2 Batch  104/269 - Train Accuracy: 0.5804, Validation Accuracy: 0.6004, Loss: 0.8022
Epoch   2 Batch  105/269 - Train Accuracy: 0.5817, Validation Accuracy: 0.5992, Loss: 0.8205
Epoch   2 Batch  106/269 - Train Accuracy: 0.5887, Validation Accuracy: 0.6024, Loss: 0.7994
Epoch   2 Batch  107/269 - Train Accuracy: 0.5641, Validation Accuracy: 0.6047, Loss: 0.8405
Epoch   2 Batch  108/269 - Train Accuracy: 0.5945, Validation Accuracy: 0.6060, Loss: 0.7863
Epoch   2 Batch  109/269 - Train Accuracy: 0.5767, Validation Accuracy: 0.6067, Loss: 0.8146
Epoch   2 Batch  110/269 - Train Accuracy: 0.5901, Validation Accuracy: 0.6054, Loss: 0.7903
Epoch   2 Batch  111/269 - Train Accuracy: 0.5676, Validation Accuracy: 0.6029, Loss: 0.8573
Epoch   2 Batch  112/269 - Train Accuracy: 0.6028, Validation Accuracy: 0.6050, Loss: 0.8003
Epoch   2 Batch  113/269 - Train Accuracy: 0.6086, Validation Accuracy: 0.6043, Loss: 0.7568
Epoch   2 Batch  114/269 - Train Accuracy: 0.5885, Validation Accuracy: 0.6054, Loss: 0.7923
Epoch   2 Batch  115/269 - Train Accuracy: 0.5864, Validation Accuracy: 0.6069, Loss: 0.8223
Epoch   2 Batch  116/269 - Train Accuracy: 0.5939, Validation Accuracy: 0.6070, Loss: 0.7979
Epoch   2 Batch  117/269 - Train Accuracy: 0.5887, Validation Accuracy: 0.6058, Loss: 0.7935
Epoch   2 Batch  118/269 - Train Accuracy: 0.6143, Validation Accuracy: 0.6037, Loss: 0.7722
Epoch   2 Batch  119/269 - Train Accuracy: 0.5745, Validation Accuracy: 0.6057, Loss: 0.8391
Epoch   2 Batch  120/269 - Train Accuracy: 0.5800, Validation Accuracy: 0.6025, Loss: 0.8216
Epoch   2 Batch  121/269 - Train Accuracy: 0.5996, Validation Accuracy: 0.6040, Loss: 0.7772
Epoch   2 Batch  122/269 - Train Accuracy: 0.5948, Validation Accuracy: 0.6039, Loss: 0.7898
Epoch   2 Batch  123/269 - Train Accuracy: 0.5734, Validation Accuracy: 0.5993, Loss: 0.8170
Epoch   2 Batch  124/269 - Train Accuracy: 0.5821, Validation Accuracy: 0.5983, Loss: 0.7693
Epoch   2 Batch  125/269 - Train Accuracy: 0.5974, Validation Accuracy: 0.6029, Loss: 0.7708
Epoch   2 Batch  126/269 - Train Accuracy: 0.5949, Validation Accuracy: 0.6041, Loss: 0.7773
Epoch   2 Batch  127/269 - Train Accuracy: 0.5912, Validation Accuracy: 0.6060, Loss: 0.8239
Epoch   2 Batch  128/269 - Train Accuracy: 0.6109, Validation Accuracy: 0.6054, Loss: 0.7907
Epoch   2 Batch  129/269 - Train Accuracy: 0.5918, Validation Accuracy: 0.6032, Loss: 0.7989
Epoch   2 Batch  130/269 - Train Accuracy: 0.5715, Validation Accuracy: 0.5990, Loss: 0.8287
Epoch   2 Batch  131/269 - Train Accuracy: 0.5855, Validation Accuracy: 0.6014, Loss: 0.8132
Epoch   2 Batch  132/269 - Train Accuracy: 0.5973, Validation Accuracy: 0.6068, Loss: 0.7945
Epoch   2 Batch  133/269 - Train Accuracy: 0.6018, Validation Accuracy: 0.6074, Loss: 0.7667
Epoch   2 Batch  134/269 - Train Accuracy: 0.5780, Validation Accuracy: 0.6040, Loss: 0.8074
Epoch   2 Batch  135/269 - Train Accuracy: 0.5700, Validation Accuracy: 0.6011, Loss: 0.8380
Epoch   2 Batch  136/269 - Train Accuracy: 0.5690, Validation Accuracy: 0.6039, Loss: 0.8320
Epoch   2 Batch  137/269 - Train Accuracy: 0.5920, Validation Accuracy: 0.6100, Loss: 0.8163
Epoch   2 Batch  138/269 - Train Accuracy: 0.5895, Validation Accuracy: 0.6086, Loss: 0.8054
Epoch   2 Batch  139/269 - Train Accuracy: 0.6115, Validation Accuracy: 0.6075, Loss: 0.7557
Epoch   2 Batch  140/269 - Train Accuracy: 0.6097, Validation Accuracy: 0.6085, Loss: 0.7962
Epoch   2 Batch  141/269 - Train Accuracy: 0.6037, Validation Accuracy: 0.6104, Loss: 0.7930
Epoch   2 Batch  142/269 - Train Accuracy: 0.6050, Validation Accuracy: 0.6109, Loss: 0.7601
Epoch   2 Batch  143/269 - Train Accuracy: 0.6032, Validation Accuracy: 0.6098, Loss: 0.7787
Epoch   2 Batch  144/269 - Train Accuracy: 0.6071, Validation Accuracy: 0.6078, Loss: 0.7473
Epoch   2 Batch  145/269 - Train Accuracy: 0.6007, Validation Accuracy: 0.6068, Loss: 0.7743
Epoch   2 Batch  146/269 - Train Accuracy: 0.6017, Validation Accuracy: 0.6085, Loss: 0.7614
Epoch   2 Batch  147/269 - Train Accuracy: 0.6225, Validation Accuracy: 0.6114, Loss: 0.7419
Epoch   2 Batch  148/269 - Train Accuracy: 0.5952, Validation Accuracy: 0.6112, Loss: 0.7892
Epoch   2 Batch  149/269 - Train Accuracy: 0.6035, Validation Accuracy: 0.6090, Loss: 0.7863
Epoch   2 Batch  150/269 - Train Accuracy: 0.5981, Validation Accuracy: 0.6069, Loss: 0.7895
Epoch   2 Batch  151/269 - Train Accuracy: 0.6236, Validation Accuracy: 0.6025, Loss: 0.7451
Epoch   2 Batch  152/269 - Train Accuracy: 0.5978, Validation Accuracy: 0.6066, Loss: 0.7756
Epoch   2 Batch  153/269 - Train Accuracy: 0.6150, Validation Accuracy: 0.6111, Loss: 0.7580
Epoch   2 Batch  154/269 - Train Accuracy: 0.5906, Validation Accuracy: 0.6096, Loss: 0.7894
Epoch   2 Batch  155/269 - Train Accuracy: 0.6273, Validation Accuracy: 0.6048, Loss: 0.7374
Epoch   2 Batch  156/269 - Train Accuracy: 0.5804, Validation Accuracy: 0.6028, Loss: 0.8014
Epoch   2 Batch  157/269 - Train Accuracy: 0.5922, Validation Accuracy: 0.6055, Loss: 0.7752
Epoch   2 Batch  158/269 - Train Accuracy: 0.6047, Validation Accuracy: 0.6097, Loss: 0.7643
Epoch   2 Batch  159/269 - Train Accuracy: 0.6043, Validation Accuracy: 0.6128, Loss: 0.7733
Epoch   2 Batch  160/269 - Train Accuracy: 0.5992, Validation Accuracy: 0.6073, Loss: 0.7685
Epoch   2 Batch  161/269 - Train Accuracy: 0.5889, Validation Accuracy: 0.6032, Loss: 0.7757
Epoch   2 Batch  162/269 - Train Accuracy: 0.6010, Validation Accuracy: 0.6053, Loss: 0.7566
Epoch   2 Batch  163/269 - Train Accuracy: 0.6097, Validation Accuracy: 0.6103, Loss: 0.7622
Epoch   2 Batch  164/269 - Train Accuracy: 0.6110, Validation Accuracy: 0.6127, Loss: 0.7626
Epoch   2 Batch  165/269 - Train Accuracy: 0.5859, Validation Accuracy: 0.6142, Loss: 0.7770
Epoch   2 Batch  166/269 - Train Accuracy: 0.6248, Validation Accuracy: 0.6143, Loss: 0.7271
Epoch   2 Batch  167/269 - Train Accuracy: 0.6007, Validation Accuracy: 0.6092, Loss: 0.7665
Epoch   2 Batch  168/269 - Train Accuracy: 0.5941, Validation Accuracy: 0.6123, Loss: 0.7750
Epoch   2 Batch  169/269 - Train Accuracy: 0.6033, Validation Accuracy: 0.6150, Loss: 0.7600
Epoch   2 Batch  170/269 - Train Accuracy: 0.6093, Validation Accuracy: 0.6177, Loss: 0.7585
Epoch   2 Batch  171/269 - Train Accuracy: 0.5987, Validation Accuracy: 0.6151, Loss: 0.7933
Epoch   2 Batch  172/269 - Train Accuracy: 0.6049, Validation Accuracy: 0.6129, Loss: 0.7692
Epoch   2 Batch  173/269 - Train Accuracy: 0.6084, Validation Accuracy: 0.6103, Loss: 0.7435
Epoch   2 Batch  174/269 - Train Accuracy: 0.5923, Validation Accuracy: 0.6107, Loss: 0.7635
Epoch   2 Batch  175/269 - Train Accuracy: 0.6073, Validation Accuracy: 0.6116, Loss: 0.7725
Epoch   2 Batch  176/269 - Train Accuracy: 0.5883, Validation Accuracy: 0.6133, Loss: 0.7936
Epoch   2 Batch  177/269 - Train Accuracy: 0.6140, Validation Accuracy: 0.6113, Loss: 0.7309
Epoch   2 Batch  178/269 - Train Accuracy: 0.5980, Validation Accuracy: 0.6113, Loss: 0.7753
Epoch   2 Batch  179/269 - Train Accuracy: 0.6084, Validation Accuracy: 0.6106, Loss: 0.7598
Epoch   2 Batch  180/269 - Train Accuracy: 0.6006, Validation Accuracy: 0.6079, Loss: 0.7510
Epoch   2 Batch  181/269 - Train Accuracy: 0.5903, Validation Accuracy: 0.6082, Loss: 0.7635
Epoch   2 Batch  182/269 - Train Accuracy: 0.6059, Validation Accuracy: 0.6119, Loss: 0.7647
Epoch   2 Batch  183/269 - Train Accuracy: 0.6626, Validation Accuracy: 0.6107, Loss: 0.6581
Epoch   2 Batch  184/269 - Train Accuracy: 0.5851, Validation Accuracy: 0.6070, Loss: 0.7832
Epoch   2 Batch  185/269 - Train Accuracy: 0.6110, Validation Accuracy: 0.6080, Loss: 0.7520
Epoch   2 Batch  186/269 - Train Accuracy: 0.5822, Validation Accuracy: 0.6133, Loss: 0.7754
Epoch   2 Batch  187/269 - Train Accuracy: 0.6068, Validation Accuracy: 0.6128, Loss: 0.7363
Epoch   2 Batch  188/269 - Train Accuracy: 0.6115, Validation Accuracy: 0.6103, Loss: 0.7232
Epoch   2 Batch  189/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6099, Loss: 0.7298
Epoch   2 Batch  190/269 - Train Accuracy: 0.6039, Validation Accuracy: 0.6130, Loss: 0.7264
Epoch   2 Batch  191/269 - Train Accuracy: 0.6199, Validation Accuracy: 0.6127, Loss: 0.7380
Epoch   2 Batch  192/269 - Train Accuracy: 0.6137, Validation Accuracy: 0.6102, Loss: 0.7491
Epoch   2 Batch  193/269 - Train Accuracy: 0.6042, Validation Accuracy: 0.6104, Loss: 0.7451
Epoch   2 Batch  194/269 - Train Accuracy: 0.6118, Validation Accuracy: 0.6104, Loss: 0.7519
Epoch   2 Batch  195/269 - Train Accuracy: 0.6015, Validation Accuracy: 0.6130, Loss: 0.7497
Epoch   2 Batch  196/269 - Train Accuracy: 0.5890, Validation Accuracy: 0.6119, Loss: 0.7429
Epoch   2 Batch  197/269 - Train Accuracy: 0.5843, Validation Accuracy: 0.6105, Loss: 0.7743
Epoch   2 Batch  198/269 - Train Accuracy: 0.5936, Validation Accuracy: 0.6113, Loss: 0.7865
Epoch   2 Batch  199/269 - Train Accuracy: 0.5954, Validation Accuracy: 0.6105, Loss: 0.7599
Epoch   2 Batch  200/269 - Train Accuracy: 0.5946, Validation Accuracy: 0.6140, Loss: 0.7655
Epoch   2 Batch  201/269 - Train Accuracy: 0.6083, Validation Accuracy: 0.6160, Loss: 0.7387
Epoch   2 Batch  202/269 - Train Accuracy: 0.6091, Validation Accuracy: 0.6192, Loss: 0.7406
Epoch   2 Batch  203/269 - Train Accuracy: 0.5795, Validation Accuracy: 0.6143, Loss: 0.7887
Epoch   2 Batch  204/269 - Train Accuracy: 0.5834, Validation Accuracy: 0.6143, Loss: 0.7741
Epoch   2 Batch  205/269 - Train Accuracy: 0.5981, Validation Accuracy: 0.6150, Loss: 0.7277
Epoch   2 Batch  206/269 - Train Accuracy: 0.5948, Validation Accuracy: 0.6159, Loss: 0.7705
Epoch   2 Batch  207/269 - Train Accuracy: 0.6346, Validation Accuracy: 0.6160, Loss: 0.7237
Epoch   2 Batch  208/269 - Train Accuracy: 0.5820, Validation Accuracy: 0.6149, Loss: 0.7778
Epoch   2 Batch  209/269 - Train Accuracy: 0.6050, Validation Accuracy: 0.6160, Loss: 0.7493
Epoch   2 Batch  210/269 - Train Accuracy: 0.6118, Validation Accuracy: 0.6154, Loss: 0.7249
Epoch   2 Batch  211/269 - Train Accuracy: 0.6113, Validation Accuracy: 0.6129, Loss: 0.7420
Epoch   2 Batch  212/269 - Train Accuracy: 0.6177, Validation Accuracy: 0.6139, Loss: 0.7241
Epoch   2 Batch  213/269 - Train Accuracy: 0.6071, Validation Accuracy: 0.6133, Loss: 0.7331
Epoch   2 Batch  214/269 - Train Accuracy: 0.6123, Validation Accuracy: 0.6146, Loss: 0.7355
Epoch   2 Batch  215/269 - Train Accuracy: 0.6338, Validation Accuracy: 0.6150, Loss: 0.6933
Epoch   2 Batch  216/269 - Train Accuracy: 0.5841, Validation Accuracy: 0.6155, Loss: 0.7942
Epoch   2 Batch  217/269 - Train Accuracy: 0.5792, Validation Accuracy: 0.6169, Loss: 0.7603
Epoch   2 Batch  218/269 - Train Accuracy: 0.5983, Validation Accuracy: 0.6156, Loss: 0.7581
Epoch   2 Batch  219/269 - Train Accuracy: 0.6092, Validation Accuracy: 0.6183, Loss: 0.7682
Epoch   2 Batch  220/269 - Train Accuracy: 0.6152, Validation Accuracy: 0.6207, Loss: 0.7005
Epoch   2 Batch  221/269 - Train Accuracy: 0.6412, Validation Accuracy: 0.6221, Loss: 0.7219
Epoch   2 Batch  222/269 - Train Accuracy: 0.6300, Validation Accuracy: 0.6214, Loss: 0.7074
Epoch   2 Batch  223/269 - Train Accuracy: 0.5994, Validation Accuracy: 0.6152, Loss: 0.7123
Epoch   2 Batch  224/269 - Train Accuracy: 0.6064, Validation Accuracy: 0.6159, Loss: 0.7515
Epoch   2 Batch  225/269 - Train Accuracy: 0.5985, Validation Accuracy: 0.6221, Loss: 0.7447
Epoch   2 Batch  226/269 - Train Accuracy: 0.6100, Validation Accuracy: 0.6239, Loss: 0.7305
Epoch   2 Batch  227/269 - Train Accuracy: 0.6700, Validation Accuracy: 0.6246, Loss: 0.6474
Epoch   2 Batch  228/269 - Train Accuracy: 0.6098, Validation Accuracy: 0.6238, Loss: 0.7266
Epoch   2 Batch  229/269 - Train Accuracy: 0.6102, Validation Accuracy: 0.6198, Loss: 0.7130
Epoch   2 Batch  230/269 - Train Accuracy: 0.5988, Validation Accuracy: 0.6191, Loss: 0.7282
Epoch   2 Batch  231/269 - Train Accuracy: 0.5862, Validation Accuracy: 0.6200, Loss: 0.7654
Epoch   2 Batch  232/269 - Train Accuracy: 0.5849, Validation Accuracy: 0.6208, Loss: 0.7543
Epoch   2 Batch  233/269 - Train Accuracy: 0.6183, Validation Accuracy: 0.6214, Loss: 0.7364
Epoch   2 Batch  234/269 - Train Accuracy: 0.6198, Validation Accuracy: 0.6233, Loss: 0.7279
Epoch   2 Batch  235/269 - Train Accuracy: 0.6151, Validation Accuracy: 0.6193, Loss: 0.7171
Epoch   2 Batch  236/269 - Train Accuracy: 0.6016, Validation Accuracy: 0.6246, Loss: 0.7122
Epoch   2 Batch  237/269 - Train Accuracy: 0.6008, Validation Accuracy: 0.6246, Loss: 0.7173
Epoch   2 Batch  238/269 - Train Accuracy: 0.6308, Validation Accuracy: 0.6230, Loss: 0.7119
Epoch   2 Batch  239/269 - Train Accuracy: 0.6216, Validation Accuracy: 0.6183, Loss: 0.7202
Epoch   2 Batch  240/269 - Train Accuracy: 0.6359, Validation Accuracy: 0.6201, Loss: 0.6579
Epoch   2 Batch  241/269 - Train Accuracy: 0.6105, Validation Accuracy: 0.6209, Loss: 0.7309
Epoch   2 Batch  242/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6222, Loss: 0.7243
Epoch   2 Batch  243/269 - Train Accuracy: 0.6390, Validation Accuracy: 0.6222, Loss: 0.6953
Epoch   2 Batch  244/269 - Train Accuracy: 0.6074, Validation Accuracy: 0.6225, Loss: 0.7138
Epoch   2 Batch  245/269 - Train Accuracy: 0.6068, Validation Accuracy: 0.6226, Loss: 0.7621
Epoch   2 Batch  246/269 - Train Accuracy: 0.5983, Validation Accuracy: 0.6219, Loss: 0.7247
Epoch   2 Batch  247/269 - Train Accuracy: 0.6030, Validation Accuracy: 0.6206, Loss: 0.7430
Epoch   2 Batch  248/269 - Train Accuracy: 0.6131, Validation Accuracy: 0.6224, Loss: 0.7148
Epoch   2 Batch  249/269 - Train Accuracy: 0.6401, Validation Accuracy: 0.6206, Loss: 0.6800
Epoch   2 Batch  250/269 - Train Accuracy: 0.5994, Validation Accuracy: 0.6173, Loss: 0.7321
Epoch   2 Batch  251/269 - Train Accuracy: 0.6287, Validation Accuracy: 0.6167, Loss: 0.7013
Epoch   2 Batch  252/269 - Train Accuracy: 0.6241, Validation Accuracy: 0.6174, Loss: 0.7181
Epoch   2 Batch  253/269 - Train Accuracy: 0.6045, Validation Accuracy: 0.6191, Loss: 0.7235
Epoch   2 Batch  254/269 - Train Accuracy: 0.6098, Validation Accuracy: 0.6172, Loss: 0.7114
Epoch   2 Batch  255/269 - Train Accuracy: 0.6333, Validation Accuracy: 0.6127, Loss: 0.6829
Epoch   2 Batch  256/269 - Train Accuracy: 0.6000, Validation Accuracy: 0.6191, Loss: 0.7250
Epoch   2 Batch  257/269 - Train Accuracy: 0.5905, Validation Accuracy: 0.6203, Loss: 0.7237
Epoch   2 Batch  258/269 - Train Accuracy: 0.6093, Validation Accuracy: 0.6176, Loss: 0.7172
Epoch   2 Batch  259/269 - Train Accuracy: 0.6204, Validation Accuracy: 0.6135, Loss: 0.7058
Epoch   2 Batch  260/269 - Train Accuracy: 0.5897, Validation Accuracy: 0.6126, Loss: 0.7509
Epoch   2 Batch  261/269 - Train Accuracy: 0.5839, Validation Accuracy: 0.6188, Loss: 0.7628
Epoch   2 Batch  262/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6216, Loss: 0.7149
Epoch   2 Batch  263/269 - Train Accuracy: 0.6106, Validation Accuracy: 0.6174, Loss: 0.7344
Epoch   2 Batch  264/269 - Train Accuracy: 0.5856, Validation Accuracy: 0.6166, Loss: 0.7404
Epoch   2 Batch  265/269 - Train Accuracy: 0.5897, Validation Accuracy: 0.6159, Loss: 0.7318
Epoch   2 Batch  266/269 - Train Accuracy: 0.6230, Validation Accuracy: 0.6226, Loss: 0.7009
Epoch   2 Batch  267/269 - Train Accuracy: 0.6121, Validation Accuracy: 0.6225, Loss: 0.7194
Epoch   3 Batch    1/269 - Train Accuracy: 0.5923, Validation Accuracy: 0.6184, Loss: 0.7258
Epoch   3 Batch    2/269 - Train Accuracy: 0.5911, Validation Accuracy: 0.6189, Loss: 0.7145
Epoch   3 Batch    3/269 - Train Accuracy: 0.6160, Validation Accuracy: 0.6181, Loss: 0.7225
Epoch   3 Batch    4/269 - Train Accuracy: 0.5880, Validation Accuracy: 0.6210, Loss: 0.7392
Epoch   3 Batch    5/269 - Train Accuracy: 0.5914, Validation Accuracy: 0.6181, Loss: 0.7328
Epoch   3 Batch    6/269 - Train Accuracy: 0.6144, Validation Accuracy: 0.6143, Loss: 0.6755
Epoch   3 Batch    7/269 - Train Accuracy: 0.6189, Validation Accuracy: 0.6148, Loss: 0.6884
Epoch   3 Batch    8/269 - Train Accuracy: 0.5937, Validation Accuracy: 0.6190, Loss: 0.7413
Epoch   3 Batch    9/269 - Train Accuracy: 0.6071, Validation Accuracy: 0.6203, Loss: 0.7122
Epoch   3 Batch   10/269 - Train Accuracy: 0.6060, Validation Accuracy: 0.6195, Loss: 0.7235
Epoch   3 Batch   11/269 - Train Accuracy: 0.6017, Validation Accuracy: 0.6153, Loss: 0.7173
Epoch   3 Batch   12/269 - Train Accuracy: 0.5922, Validation Accuracy: 0.6183, Loss: 0.7321
Epoch   3 Batch   13/269 - Train Accuracy: 0.6342, Validation Accuracy: 0.6201, Loss: 0.6568
Epoch   3 Batch   14/269 - Train Accuracy: 0.6179, Validation Accuracy: 0.6206, Loss: 0.6941
Epoch   3 Batch   15/269 - Train Accuracy: 0.6061, Validation Accuracy: 0.6215, Loss: 0.6872
Epoch   3 Batch   16/269 - Train Accuracy: 0.6226, Validation Accuracy: 0.6167, Loss: 0.7003
Epoch   3 Batch   17/269 - Train Accuracy: 0.6186, Validation Accuracy: 0.6190, Loss: 0.6906
Epoch   3 Batch   18/269 - Train Accuracy: 0.5855, Validation Accuracy: 0.6214, Loss: 0.7194
Epoch   3 Batch   19/269 - Train Accuracy: 0.6402, Validation Accuracy: 0.6212, Loss: 0.6535
Epoch   3 Batch   20/269 - Train Accuracy: 0.6035, Validation Accuracy: 0.6216, Loss: 0.7217
Epoch   3 Batch   21/269 - Train Accuracy: 0.6032, Validation Accuracy: 0.6213, Loss: 0.7371
Epoch   3 Batch   22/269 - Train Accuracy: 0.6173, Validation Accuracy: 0.6240, Loss: 0.6765
Epoch   3 Batch   23/269 - Train Accuracy: 0.6201, Validation Accuracy: 0.6223, Loss: 0.6919
Epoch   3 Batch   24/269 - Train Accuracy: 0.6085, Validation Accuracy: 0.6230, Loss: 0.7253
Epoch   3 Batch   25/269 - Train Accuracy: 0.6008, Validation Accuracy: 0.6250, Loss: 0.7306
Epoch   3 Batch   26/269 - Train Accuracy: 0.6365, Validation Accuracy: 0.6198, Loss: 0.6478
Epoch   3 Batch   27/269 - Train Accuracy: 0.6062, Validation Accuracy: 0.6228, Loss: 0.6930
Epoch   3 Batch   28/269 - Train Accuracy: 0.5747, Validation Accuracy: 0.6207, Loss: 0.7444
Epoch   3 Batch   29/269 - Train Accuracy: 0.6054, Validation Accuracy: 0.6194, Loss: 0.7189
Epoch   3 Batch   30/269 - Train Accuracy: 0.6177, Validation Accuracy: 0.6242, Loss: 0.6792
Epoch   3 Batch   31/269 - Train Accuracy: 0.6307, Validation Accuracy: 0.6254, Loss: 0.6715
Epoch   3 Batch   32/269 - Train Accuracy: 0.6077, Validation Accuracy: 0.6233, Loss: 0.6871
Epoch   3 Batch   33/269 - Train Accuracy: 0.6317, Validation Accuracy: 0.6226, Loss: 0.6676
Epoch   3 Batch   34/269 - Train Accuracy: 0.6206, Validation Accuracy: 0.6222, Loss: 0.6837
Epoch   3 Batch   35/269 - Train Accuracy: 0.6230, Validation Accuracy: 0.6212, Loss: 0.6945
Epoch   3 Batch   36/269 - Train Accuracy: 0.6178, Validation Accuracy: 0.6237, Loss: 0.6853
Epoch   3 Batch   37/269 - Train Accuracy: 0.6306, Validation Accuracy: 0.6238, Loss: 0.6810
Epoch   3 Batch   38/269 - Train Accuracy: 0.6178, Validation Accuracy: 0.6272, Loss: 0.6869
Epoch   3 Batch   39/269 - Train Accuracy: 0.6184, Validation Accuracy: 0.6239, Loss: 0.6728
Epoch   3 Batch   40/269 - Train Accuracy: 0.6095, Validation Accuracy: 0.6230, Loss: 0.7140
Epoch   3 Batch   41/269 - Train Accuracy: 0.6151, Validation Accuracy: 0.6246, Loss: 0.6955
Epoch   3 Batch   42/269 - Train Accuracy: 0.6439, Validation Accuracy: 0.6254, Loss: 0.6549
Epoch   3 Batch   43/269 - Train Accuracy: 0.6122, Validation Accuracy: 0.6276, Loss: 0.7089
Epoch   3 Batch   44/269 - Train Accuracy: 0.6313, Validation Accuracy: 0.6270, Loss: 0.6892
Epoch   3 Batch   45/269 - Train Accuracy: 0.5957, Validation Accuracy: 0.6242, Loss: 0.7144
Epoch   3 Batch   46/269 - Train Accuracy: 0.6210, Validation Accuracy: 0.6256, Loss: 0.7014
Epoch   3 Batch   47/269 - Train Accuracy: 0.6508, Validation Accuracy: 0.6232, Loss: 0.6323
Epoch   3 Batch   48/269 - Train Accuracy: 0.6207, Validation Accuracy: 0.6230, Loss: 0.6654
Epoch   3 Batch   49/269 - Train Accuracy: 0.5883, Validation Accuracy: 0.6270, Loss: 0.7032
Epoch   3 Batch   50/269 - Train Accuracy: 0.6048, Validation Accuracy: 0.6271, Loss: 0.7111
Epoch   3 Batch   51/269 - Train Accuracy: 0.6119, Validation Accuracy: 0.6260, Loss: 0.6890
Epoch   3 Batch   52/269 - Train Accuracy: 0.6035, Validation Accuracy: 0.6273, Loss: 0.6585
Epoch   3 Batch   53/269 - Train Accuracy: 0.6065, Validation Accuracy: 0.6254, Loss: 0.7178
Epoch   3 Batch   54/269 - Train Accuracy: 0.6124, Validation Accuracy: 0.6274, Loss: 0.7028
Epoch   3 Batch   55/269 - Train Accuracy: 0.6307, Validation Accuracy: 0.6277, Loss: 0.6736
Epoch   3 Batch   56/269 - Train Accuracy: 0.6310, Validation Accuracy: 0.6293, Loss: 0.6821
Epoch   3 Batch   57/269 - Train Accuracy: 0.6222, Validation Accuracy: 0.6331, Loss: 0.6959
Epoch   3 Batch   58/269 - Train Accuracy: 0.6323, Validation Accuracy: 0.6252, Loss: 0.6661
Epoch   3 Batch   59/269 - Train Accuracy: 0.6316, Validation Accuracy: 0.6240, Loss: 0.6527
Epoch   3 Batch   60/269 - Train Accuracy: 0.6250, Validation Accuracy: 0.6241, Loss: 0.6429
Epoch   3 Batch   61/269 - Train Accuracy: 0.6315, Validation Accuracy: 0.6293, Loss: 0.6401
Epoch   3 Batch   62/269 - Train Accuracy: 0.6362, Validation Accuracy: 0.6296, Loss: 0.6559
Epoch   3 Batch   63/269 - Train Accuracy: 0.6147, Validation Accuracy: 0.6278, Loss: 0.6861
Epoch   3 Batch   64/269 - Train Accuracy: 0.6111, Validation Accuracy: 0.6276, Loss: 0.6584
Epoch   3 Batch   65/269 - Train Accuracy: 0.6230, Validation Accuracy: 0.6322, Loss: 0.6632
Epoch   3 Batch   66/269 - Train Accuracy: 0.6278, Validation Accuracy: 0.6294, Loss: 0.6524
Epoch   3 Batch   67/269 - Train Accuracy: 0.6207, Validation Accuracy: 0.6261, Loss: 0.6810
Epoch   3 Batch   68/269 - Train Accuracy: 0.6026, Validation Accuracy: 0.6244, Loss: 0.6768
Epoch   3 Batch   69/269 - Train Accuracy: 0.5936, Validation Accuracy: 0.6269, Loss: 0.7365
Epoch   3 Batch   70/269 - Train Accuracy: 0.6322, Validation Accuracy: 0.6244, Loss: 0.6782
Epoch   3 Batch   71/269 - Train Accuracy: 0.6055, Validation Accuracy: 0.6199, Loss: 0.7047
Epoch   3 Batch   72/269 - Train Accuracy: 0.6234, Validation Accuracy: 0.6207, Loss: 0.6622
Epoch   3 Batch   73/269 - Train Accuracy: 0.6290, Validation Accuracy: 0.6238, Loss: 0.6821
Epoch   3 Batch   74/269 - Train Accuracy: 0.6207, Validation Accuracy: 0.6215, Loss: 0.6784
Epoch   3 Batch   75/269 - Train Accuracy: 0.6143, Validation Accuracy: 0.6204, Loss: 0.6628
Epoch   3 Batch   76/269 - Train Accuracy: 0.6031, Validation Accuracy: 0.6195, Loss: 0.6841
Epoch   3 Batch   77/269 - Train Accuracy: 0.6385, Validation Accuracy: 0.6244, Loss: 0.6545
Epoch   3 Batch   78/269 - Train Accuracy: 0.6240, Validation Accuracy: 0.6279, Loss: 0.6655
Epoch   3 Batch   79/269 - Train Accuracy: 0.6206, Validation Accuracy: 0.6263, Loss: 0.6584
Epoch   3 Batch   80/269 - Train Accuracy: 0.6373, Validation Accuracy: 0.6278, Loss: 0.6632
Epoch   3 Batch   81/269 - Train Accuracy: 0.6179, Validation Accuracy: 0.6308, Loss: 0.6847
Epoch   3 Batch   82/269 - Train Accuracy: 0.6324, Validation Accuracy: 0.6307, Loss: 0.6418
Epoch   3 Batch   83/269 - Train Accuracy: 0.6258, Validation Accuracy: 0.6357, Loss: 0.6695
Epoch   3 Batch   84/269 - Train Accuracy: 0.6392, Validation Accuracy: 0.6309, Loss: 0.6537
Epoch   3 Batch   85/269 - Train Accuracy: 0.6189, Validation Accuracy: 0.6323, Loss: 0.6609
Epoch   3 Batch   86/269 - Train Accuracy: 0.6079, Validation Accuracy: 0.6315, Loss: 0.6539
Epoch   3 Batch   87/269 - Train Accuracy: 0.6043, Validation Accuracy: 0.6353, Loss: 0.7009
Epoch   3 Batch   88/269 - Train Accuracy: 0.6300, Validation Accuracy: 0.6330, Loss: 0.6620
Epoch   3 Batch   89/269 - Train Accuracy: 0.6335, Validation Accuracy: 0.6283, Loss: 0.6672
Epoch   3 Batch   90/269 - Train Accuracy: 0.5932, Validation Accuracy: 0.6265, Loss: 0.7035
Epoch   3 Batch   91/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6286, Loss: 0.6383
Epoch   3 Batch   92/269 - Train Accuracy: 0.6285, Validation Accuracy: 0.6262, Loss: 0.6507
Epoch   3 Batch   93/269 - Train Accuracy: 0.6345, Validation Accuracy: 0.6304, Loss: 0.6324
Epoch   3 Batch   94/269 - Train Accuracy: 0.6129, Validation Accuracy: 0.6265, Loss: 0.6698
Epoch   3 Batch   95/269 - Train Accuracy: 0.6230, Validation Accuracy: 0.6314, Loss: 0.6631
Epoch   3 Batch   96/269 - Train Accuracy: 0.6185, Validation Accuracy: 0.6308, Loss: 0.6594
Epoch   3 Batch   97/269 - Train Accuracy: 0.6375, Validation Accuracy: 0.6254, Loss: 0.6508
Epoch   3 Batch   98/269 - Train Accuracy: 0.6323, Validation Accuracy: 0.6290, Loss: 0.6552
Epoch   3 Batch   99/269 - Train Accuracy: 0.6088, Validation Accuracy: 0.6295, Loss: 0.6787
Epoch   3 Batch  100/269 - Train Accuracy: 0.6468, Validation Accuracy: 0.6235, Loss: 0.6496
Epoch   3 Batch  101/269 - Train Accuracy: 0.6006, Validation Accuracy: 0.6332, Loss: 0.6954
Epoch   3 Batch  102/269 - Train Accuracy: 0.6335, Validation Accuracy: 0.6393, Loss: 0.6575
Epoch   3 Batch  103/269 - Train Accuracy: 0.6234, Validation Accuracy: 0.6376, Loss: 0.6539
Epoch   3 Batch  104/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6321, Loss: 0.6509
Epoch   3 Batch  105/269 - Train Accuracy: 0.6244, Validation Accuracy: 0.6341, Loss: 0.6648
Epoch   3 Batch  106/269 - Train Accuracy: 0.6333, Validation Accuracy: 0.6406, Loss: 0.6496
Epoch   3 Batch  107/269 - Train Accuracy: 0.5965, Validation Accuracy: 0.6334, Loss: 0.6898
Epoch   3 Batch  108/269 - Train Accuracy: 0.6259, Validation Accuracy: 0.6243, Loss: 0.6516
Epoch   3 Batch  109/269 - Train Accuracy: 0.6099, Validation Accuracy: 0.6316, Loss: 0.6573
Epoch   3 Batch  110/269 - Train Accuracy: 0.6205, Validation Accuracy: 0.6306, Loss: 0.6407
Epoch   3 Batch  111/269 - Train Accuracy: 0.5906, Validation Accuracy: 0.6278, Loss: 0.7011
Epoch   3 Batch  112/269 - Train Accuracy: 0.6296, Validation Accuracy: 0.6329, Loss: 0.6506
Epoch   3 Batch  113/269 - Train Accuracy: 0.6232, Validation Accuracy: 0.6308, Loss: 0.6273
Epoch   3 Batch  114/269 - Train Accuracy: 0.6200, Validation Accuracy: 0.6277, Loss: 0.6468
Epoch   3 Batch  115/269 - Train Accuracy: 0.6115, Validation Accuracy: 0.6283, Loss: 0.6805
Epoch   3 Batch  116/269 - Train Accuracy: 0.6148, Validation Accuracy: 0.6281, Loss: 0.6607
Epoch   3 Batch  117/269 - Train Accuracy: 0.6015, Validation Accuracy: 0.6206, Loss: 0.6478
Epoch   3 Batch  118/269 - Train Accuracy: 0.6434, Validation Accuracy: 0.6308, Loss: 0.6276
Epoch   3 Batch  119/269 - Train Accuracy: 0.6074, Validation Accuracy: 0.6335, Loss: 0.6842
Epoch   3 Batch  120/269 - Train Accuracy: 0.6158, Validation Accuracy: 0.6326, Loss: 0.6709
Epoch   3 Batch  121/269 - Train Accuracy: 0.6123, Validation Accuracy: 0.6344, Loss: 0.6321
Epoch   3 Batch  122/269 - Train Accuracy: 0.6299, Validation Accuracy: 0.6373, Loss: 0.6328
Epoch   3 Batch  123/269 - Train Accuracy: 0.6146, Validation Accuracy: 0.6337, Loss: 0.6680
Epoch   3 Batch  124/269 - Train Accuracy: 0.6189, Validation Accuracy: 0.6369, Loss: 0.6314
Epoch   3 Batch  125/269 - Train Accuracy: 0.6371, Validation Accuracy: 0.6404, Loss: 0.6325
Epoch   3 Batch  126/269 - Train Accuracy: 0.6283, Validation Accuracy: 0.6290, Loss: 0.6325
Epoch   3 Batch  127/269 - Train Accuracy: 0.6234, Validation Accuracy: 0.6285, Loss: 0.6696
Epoch   3 Batch  128/269 - Train Accuracy: 0.6423, Validation Accuracy: 0.6427, Loss: 0.6490
Epoch   3 Batch  129/269 - Train Accuracy: 0.6209, Validation Accuracy: 0.6386, Loss: 0.6460
Epoch   3 Batch  130/269 - Train Accuracy: 0.6091, Validation Accuracy: 0.6373, Loss: 0.6732
Epoch   3 Batch  131/269 - Train Accuracy: 0.6176, Validation Accuracy: 0.6312, Loss: 0.6590
Epoch   3 Batch  132/269 - Train Accuracy: 0.6220, Validation Accuracy: 0.6348, Loss: 0.6557
Epoch   3 Batch  133/269 - Train Accuracy: 0.6316, Validation Accuracy: 0.6311, Loss: 0.6272
Epoch   3 Batch  134/269 - Train Accuracy: 0.6072, Validation Accuracy: 0.6306, Loss: 0.6577
Epoch   3 Batch  135/269 - Train Accuracy: 0.5987, Validation Accuracy: 0.6325, Loss: 0.6828
Epoch   3 Batch  136/269 - Train Accuracy: 0.6040, Validation Accuracy: 0.6308, Loss: 0.6812
Epoch   3 Batch  137/269 - Train Accuracy: 0.6195, Validation Accuracy: 0.6334, Loss: 0.6701
Epoch   3 Batch  138/269 - Train Accuracy: 0.6147, Validation Accuracy: 0.6283, Loss: 0.6672
Epoch   3 Batch  139/269 - Train Accuracy: 0.6344, Validation Accuracy: 0.6278, Loss: 0.6334
Epoch   3 Batch  140/269 - Train Accuracy: 0.6311, Validation Accuracy: 0.6391, Loss: 0.6574
Epoch   3 Batch  141/269 - Train Accuracy: 0.6217, Validation Accuracy: 0.6288, Loss: 0.6574
Epoch   3 Batch  142/269 - Train Accuracy: 0.6258, Validation Accuracy: 0.6355, Loss: 0.6306
Epoch   3 Batch  143/269 - Train Accuracy: 0.6311, Validation Accuracy: 0.6356, Loss: 0.6363
Epoch   3 Batch  144/269 - Train Accuracy: 0.6354, Validation Accuracy: 0.6328, Loss: 0.6162
Epoch   3 Batch  145/269 - Train Accuracy: 0.6360, Validation Accuracy: 0.6331, Loss: 0.6341
Epoch   3 Batch  146/269 - Train Accuracy: 0.6344, Validation Accuracy: 0.6404, Loss: 0.6242
Epoch   3 Batch  147/269 - Train Accuracy: 0.6526, Validation Accuracy: 0.6454, Loss: 0.6053
Epoch   3 Batch  148/269 - Train Accuracy: 0.6232, Validation Accuracy: 0.6428, Loss: 0.6475
Epoch   3 Batch  149/269 - Train Accuracy: 0.6179, Validation Accuracy: 0.6353, Loss: 0.6464
Epoch   3 Batch  150/269 - Train Accuracy: 0.6322, Validation Accuracy: 0.6372, Loss: 0.6441
Epoch   3 Batch  151/269 - Train Accuracy: 0.6486, Validation Accuracy: 0.6369, Loss: 0.6166
Epoch   3 Batch  152/269 - Train Accuracy: 0.6391, Validation Accuracy: 0.6310, Loss: 0.6350
Epoch   3 Batch  153/269 - Train Accuracy: 0.6271, Validation Accuracy: 0.6372, Loss: 0.6216
Epoch   3 Batch  154/269 - Train Accuracy: 0.6209, Validation Accuracy: 0.6342, Loss: 0.6423
Epoch   3 Batch  155/269 - Train Accuracy: 0.6523, Validation Accuracy: 0.6395, Loss: 0.5998
Epoch   3 Batch  156/269 - Train Accuracy: 0.6143, Validation Accuracy: 0.6358, Loss: 0.6588
Epoch   3 Batch  157/269 - Train Accuracy: 0.6235, Validation Accuracy: 0.6420, Loss: 0.6283
Epoch   3 Batch  158/269 - Train Accuracy: 0.6115, Validation Accuracy: 0.6395, Loss: 0.6283
Epoch   3 Batch  159/269 - Train Accuracy: 0.6246, Validation Accuracy: 0.6394, Loss: 0.6334
Epoch   3 Batch  160/269 - Train Accuracy: 0.6239, Validation Accuracy: 0.6429, Loss: 0.6284
Epoch   3 Batch  161/269 - Train Accuracy: 0.6213, Validation Accuracy: 0.6356, Loss: 0.6297
Epoch   3 Batch  162/269 - Train Accuracy: 0.6463, Validation Accuracy: 0.6364, Loss: 0.6242
Epoch   3 Batch  163/269 - Train Accuracy: 0.6408, Validation Accuracy: 0.6375, Loss: 0.6132
Epoch   3 Batch  164/269 - Train Accuracy: 0.6441, Validation Accuracy: 0.6431, Loss: 0.6200
Epoch   3 Batch  165/269 - Train Accuracy: 0.6086, Validation Accuracy: 0.6383, Loss: 0.6400
Epoch   3 Batch  166/269 - Train Accuracy: 0.6442, Validation Accuracy: 0.6400, Loss: 0.5935
Epoch   3 Batch  167/269 - Train Accuracy: 0.6312, Validation Accuracy: 0.6436, Loss: 0.6256
Epoch   3 Batch  168/269 - Train Accuracy: 0.6219, Validation Accuracy: 0.6429, Loss: 0.6283
Epoch   3 Batch  169/269 - Train Accuracy: 0.6336, Validation Accuracy: 0.6427, Loss: 0.6283
Epoch   3 Batch  170/269 - Train Accuracy: 0.6326, Validation Accuracy: 0.6397, Loss: 0.6114
Epoch   3 Batch  171/269 - Train Accuracy: 0.6447, Validation Accuracy: 0.6409, Loss: 0.6484
Epoch   3 Batch  172/269 - Train Accuracy: 0.6187, Validation Accuracy: 0.6413, Loss: 0.6312
Epoch   3 Batch  173/269 - Train Accuracy: 0.6414, Validation Accuracy: 0.6415, Loss: 0.6124
Epoch   3 Batch  174/269 - Train Accuracy: 0.6284, Validation Accuracy: 0.6381, Loss: 0.6198
Epoch   3 Batch  175/269 - Train Accuracy: 0.6248, Validation Accuracy: 0.6406, Loss: 0.6319
Epoch   3 Batch  176/269 - Train Accuracy: 0.6297, Validation Accuracy: 0.6452, Loss: 0.6644
Epoch   3 Batch  177/269 - Train Accuracy: 0.6435, Validation Accuracy: 0.6439, Loss: 0.5957
Epoch   3 Batch  178/269 - Train Accuracy: 0.6186, Validation Accuracy: 0.6403, Loss: 0.6350
Epoch   3 Batch  179/269 - Train Accuracy: 0.6218, Validation Accuracy: 0.6390, Loss: 0.6250
Epoch   3 Batch  180/269 - Train Accuracy: 0.6350, Validation Accuracy: 0.6356, Loss: 0.6074
Epoch   3 Batch  181/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6357, Loss: 0.6278
Epoch   3 Batch  182/269 - Train Accuracy: 0.6407, Validation Accuracy: 0.6345, Loss: 0.6184
Epoch   3 Batch  183/269 - Train Accuracy: 0.6880, Validation Accuracy: 0.6366, Loss: 0.5311
Epoch   3 Batch  184/269 - Train Accuracy: 0.6112, Validation Accuracy: 0.6381, Loss: 0.6410
Epoch   3 Batch  185/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6405, Loss: 0.6113
Epoch   3 Batch  186/269 - Train Accuracy: 0.6135, Validation Accuracy: 0.6367, Loss: 0.6387
Epoch   3 Batch  187/269 - Train Accuracy: 0.6374, Validation Accuracy: 0.6396, Loss: 0.6036
Epoch   3 Batch  188/269 - Train Accuracy: 0.6393, Validation Accuracy: 0.6403, Loss: 0.5998
Epoch   3 Batch  189/269 - Train Accuracy: 0.6401, Validation Accuracy: 0.6405, Loss: 0.5980
Epoch   3 Batch  190/269 - Train Accuracy: 0.6388, Validation Accuracy: 0.6400, Loss: 0.6013
Epoch   3 Batch  191/269 - Train Accuracy: 0.6542, Validation Accuracy: 0.6419, Loss: 0.6041
Epoch   3 Batch  192/269 - Train Accuracy: 0.6422, Validation Accuracy: 0.6373, Loss: 0.6133
Epoch   3 Batch  193/269 - Train Accuracy: 0.6475, Validation Accuracy: 0.6398, Loss: 0.6053
Epoch   3 Batch  194/269 - Train Accuracy: 0.6348, Validation Accuracy: 0.6398, Loss: 0.6140
Epoch   3 Batch  195/269 - Train Accuracy: 0.6389, Validation Accuracy: 0.6411, Loss: 0.6117
Epoch   3 Batch  196/269 - Train Accuracy: 0.6366, Validation Accuracy: 0.6389, Loss: 0.6122
Epoch   3 Batch  197/269 - Train Accuracy: 0.6127, Validation Accuracy: 0.6363, Loss: 0.6431
Epoch   3 Batch  198/269 - Train Accuracy: 0.6148, Validation Accuracy: 0.6371, Loss: 0.6461
Epoch   3 Batch  199/269 - Train Accuracy: 0.6421, Validation Accuracy: 0.6388, Loss: 0.6331
Epoch   3 Batch  200/269 - Train Accuracy: 0.6292, Validation Accuracy: 0.6396, Loss: 0.6238
Epoch   3 Batch  201/269 - Train Accuracy: 0.6409, Validation Accuracy: 0.6460, Loss: 0.6133
Epoch   3 Batch  202/269 - Train Accuracy: 0.6382, Validation Accuracy: 0.6440, Loss: 0.6125
Epoch   3 Batch  203/269 - Train Accuracy: 0.6187, Validation Accuracy: 0.6405, Loss: 0.6505
Epoch   3 Batch  204/269 - Train Accuracy: 0.6340, Validation Accuracy: 0.6404, Loss: 0.6502
Epoch   3 Batch  205/269 - Train Accuracy: 0.6489, Validation Accuracy: 0.6347, Loss: 0.6003
Epoch   3 Batch  206/269 - Train Accuracy: 0.6227, Validation Accuracy: 0.6364, Loss: 0.6379
Epoch   3 Batch  207/269 - Train Accuracy: 0.6519, Validation Accuracy: 0.6430, Loss: 0.5982
Epoch   3 Batch  208/269 - Train Accuracy: 0.6214, Validation Accuracy: 0.6448, Loss: 0.6398
Epoch   3 Batch  209/269 - Train Accuracy: 0.6374, Validation Accuracy: 0.6404, Loss: 0.6136
Epoch   3 Batch  210/269 - Train Accuracy: 0.6415, Validation Accuracy: 0.6397, Loss: 0.6032
Epoch   3 Batch  211/269 - Train Accuracy: 0.6263, Validation Accuracy: 0.6364, Loss: 0.6193
Epoch   3 Batch  212/269 - Train Accuracy: 0.6458, Validation Accuracy: 0.6398, Loss: 0.5971
Epoch   3 Batch  213/269 - Train Accuracy: 0.6349, Validation Accuracy: 0.6345, Loss: 0.6011
Epoch   3 Batch  214/269 - Train Accuracy: 0.6408, Validation Accuracy: 0.6404, Loss: 0.6099
Epoch   3 Batch  215/269 - Train Accuracy: 0.6632, Validation Accuracy: 0.6382, Loss: 0.5669
Epoch   3 Batch  216/269 - Train Accuracy: 0.6142, Validation Accuracy: 0.6507, Loss: 0.6475
Epoch   3 Batch  217/269 - Train Accuracy: 0.6105, Validation Accuracy: 0.6499, Loss: 0.6330
Epoch   3 Batch  218/269 - Train Accuracy: 0.6303, Validation Accuracy: 0.6373, Loss: 0.6243
Epoch   3 Batch  219/269 - Train Accuracy: 0.6389, Validation Accuracy: 0.6359, Loss: 0.6388
Epoch   3 Batch  220/269 - Train Accuracy: 0.6476, Validation Accuracy: 0.6370, Loss: 0.5705
Epoch   3 Batch  221/269 - Train Accuracy: 0.6630, Validation Accuracy: 0.6444, Loss: 0.5958
Epoch   3 Batch  222/269 - Train Accuracy: 0.6576, Validation Accuracy: 0.6362, Loss: 0.5823
Epoch   3 Batch  223/269 - Train Accuracy: 0.6239, Validation Accuracy: 0.6350, Loss: 0.5926
Epoch   3 Batch  224/269 - Train Accuracy: 0.6422, Validation Accuracy: 0.6344, Loss: 0.6214
Epoch   3 Batch  225/269 - Train Accuracy: 0.6317, Validation Accuracy: 0.6460, Loss: 0.6048
Epoch   3 Batch  226/269 - Train Accuracy: 0.6607, Validation Accuracy: 0.6550, Loss: 0.6035
Epoch   3 Batch  227/269 - Train Accuracy: 0.6966, Validation Accuracy: 0.6440, Loss: 0.5360
Epoch   3 Batch  228/269 - Train Accuracy: 0.6366, Validation Accuracy: 0.6372, Loss: 0.5991
Epoch   3 Batch  229/269 - Train Accuracy: 0.6388, Validation Accuracy: 0.6349, Loss: 0.5879
Epoch   3 Batch  230/269 - Train Accuracy: 0.6363, Validation Accuracy: 0.6452, Loss: 0.5912
Epoch   3 Batch  231/269 - Train Accuracy: 0.6308, Validation Accuracy: 0.6539, Loss: 0.6278
Epoch   3 Batch  232/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6490, Loss: 0.6245
Epoch   3 Batch  233/269 - Train Accuracy: 0.6438, Validation Accuracy: 0.6462, Loss: 0.6027
Epoch   3 Batch  234/269 - Train Accuracy: 0.6487, Validation Accuracy: 0.6444, Loss: 0.5949
Epoch   3 Batch  235/269 - Train Accuracy: 0.6496, Validation Accuracy: 0.6473, Loss: 0.5851
Epoch   3 Batch  236/269 - Train Accuracy: 0.6337, Validation Accuracy: 0.6461, Loss: 0.5875
Epoch   3 Batch  237/269 - Train Accuracy: 0.6297, Validation Accuracy: 0.6422, Loss: 0.5880
Epoch   3 Batch  238/269 - Train Accuracy: 0.6513, Validation Accuracy: 0.6365, Loss: 0.5892
Epoch   3 Batch  239/269 - Train Accuracy: 0.6379, Validation Accuracy: 0.6423, Loss: 0.5883
Epoch   3 Batch  240/269 - Train Accuracy: 0.6707, Validation Accuracy: 0.6458, Loss: 0.5481
Epoch   3 Batch  241/269 - Train Accuracy: 0.6478, Validation Accuracy: 0.6387, Loss: 0.6014
Epoch   3 Batch  242/269 - Train Accuracy: 0.6338, Validation Accuracy: 0.6411, Loss: 0.5931
Epoch   3 Batch  243/269 - Train Accuracy: 0.6632, Validation Accuracy: 0.6430, Loss: 0.5758
Epoch   3 Batch  244/269 - Train Accuracy: 0.6528, Validation Accuracy: 0.6460, Loss: 0.5946
Epoch   3 Batch  245/269 - Train Accuracy: 0.6249, Validation Accuracy: 0.6500, Loss: 0.6268
Epoch   3 Batch  246/269 - Train Accuracy: 0.6297, Validation Accuracy: 0.6496, Loss: 0.5965
Epoch   3 Batch  247/269 - Train Accuracy: 0.6236, Validation Accuracy: 0.6409, Loss: 0.6192
Epoch   3 Batch  248/269 - Train Accuracy: 0.6410, Validation Accuracy: 0.6501, Loss: 0.5875
Epoch   3 Batch  249/269 - Train Accuracy: 0.6715, Validation Accuracy: 0.6521, Loss: 0.5603
Epoch   3 Batch  250/269 - Train Accuracy: 0.6266, Validation Accuracy: 0.6460, Loss: 0.6060
Epoch   3 Batch  251/269 - Train Accuracy: 0.6549, Validation Accuracy: 0.6434, Loss: 0.5829
Epoch   3 Batch  252/269 - Train Accuracy: 0.6317, Validation Accuracy: 0.6447, Loss: 0.5991
Epoch   3 Batch  253/269 - Train Accuracy: 0.6311, Validation Accuracy: 0.6548, Loss: 0.6008
Epoch   3 Batch  254/269 - Train Accuracy: 0.6413, Validation Accuracy: 0.6469, Loss: 0.5942
Epoch   3 Batch  255/269 - Train Accuracy: 0.6466, Validation Accuracy: 0.6395, Loss: 0.5745
Epoch   3 Batch  256/269 - Train Accuracy: 0.6380, Validation Accuracy: 0.6506, Loss: 0.5957
Epoch   3 Batch  257/269 - Train Accuracy: 0.6359, Validation Accuracy: 0.6580, Loss: 0.6033
Epoch   3 Batch  258/269 - Train Accuracy: 0.6498, Validation Accuracy: 0.6544, Loss: 0.5980
Epoch   3 Batch  259/269 - Train Accuracy: 0.6333, Validation Accuracy: 0.6317, Loss: 0.5860
Epoch   3 Batch  260/269 - Train Accuracy: 0.6261, Validation Accuracy: 0.6532, Loss: 0.6261
Epoch   3 Batch  261/269 - Train Accuracy: 0.6272, Validation Accuracy: 0.6600, Loss: 0.6185
Epoch   3 Batch  262/269 - Train Accuracy: 0.6403, Validation Accuracy: 0.6440, Loss: 0.5916
Epoch   3 Batch  263/269 - Train Accuracy: 0.6267, Validation Accuracy: 0.6359, Loss: 0.6072
Epoch   3 Batch  264/269 - Train Accuracy: 0.6141, Validation Accuracy: 0.6385, Loss: 0.6126
Epoch   3 Batch  265/269 - Train Accuracy: 0.6208, Validation Accuracy: 0.6505, Loss: 0.6105
Epoch   3 Batch  266/269 - Train Accuracy: 0.6680, Validation Accuracy: 0.6582, Loss: 0.5795
Epoch   3 Batch  267/269 - Train Accuracy: 0.6429, Validation Accuracy: 0.6557, Loss: 0.5925
Epoch   4 Batch    1/269 - Train Accuracy: 0.6179, Validation Accuracy: 0.6425, Loss: 0.6001
Epoch   4 Batch    2/269 - Train Accuracy: 0.6329, Validation Accuracy: 0.6477, Loss: 0.5906
Epoch   4 Batch    3/269 - Train Accuracy: 0.6386, Validation Accuracy: 0.6466, Loss: 0.5973
Epoch   4 Batch    4/269 - Train Accuracy: 0.6025, Validation Accuracy: 0.6517, Loss: 0.6053
Epoch   4 Batch    5/269 - Train Accuracy: 0.6252, Validation Accuracy: 0.6506, Loss: 0.6014
Epoch   4 Batch    6/269 - Train Accuracy: 0.6507, Validation Accuracy: 0.6453, Loss: 0.5604
Epoch   4 Batch    7/269 - Train Accuracy: 0.6487, Validation Accuracy: 0.6479, Loss: 0.5702
Epoch   4 Batch    8/269 - Train Accuracy: 0.6272, Validation Accuracy: 0.6536, Loss: 0.6103
Epoch   4 Batch    9/269 - Train Accuracy: 0.6295, Validation Accuracy: 0.6395, Loss: 0.5892
Epoch   4 Batch   10/269 - Train Accuracy: 0.6415, Validation Accuracy: 0.6578, Loss: 0.5980
Epoch   4 Batch   11/269 - Train Accuracy: 0.6363, Validation Accuracy: 0.6562, Loss: 0.5923
Epoch   4 Batch   12/269 - Train Accuracy: 0.6394, Validation Accuracy: 0.6507, Loss: 0.6050
Epoch   4 Batch   13/269 - Train Accuracy: 0.6469, Validation Accuracy: 0.6473, Loss: 0.5407
Epoch   4 Batch   14/269 - Train Accuracy: 0.6360, Validation Accuracy: 0.6380, Loss: 0.5759
Epoch   4 Batch   15/269 - Train Accuracy: 0.6449, Validation Accuracy: 0.6586, Loss: 0.5675
Epoch   4 Batch   16/269 - Train Accuracy: 0.6535, Validation Accuracy: 0.6590, Loss: 0.5714
Epoch   4 Batch   17/269 - Train Accuracy: 0.6497, Validation Accuracy: 0.6492, Loss: 0.5706
Epoch   4 Batch   18/269 - Train Accuracy: 0.6147, Validation Accuracy: 0.6465, Loss: 0.5874
Epoch   4 Batch   19/269 - Train Accuracy: 0.6643, Validation Accuracy: 0.6424, Loss: 0.5418
Epoch   4 Batch   20/269 - Train Accuracy: 0.6547, Validation Accuracy: 0.6617, Loss: 0.6010
Epoch   4 Batch   21/269 - Train Accuracy: 0.6498, Validation Accuracy: 0.6609, Loss: 0.6117
Epoch   4 Batch   22/269 - Train Accuracy: 0.6633, Validation Accuracy: 0.6521, Loss: 0.5580
Epoch   4 Batch   23/269 - Train Accuracy: 0.6489, Validation Accuracy: 0.6486, Loss: 0.5687
Epoch   4 Batch   24/269 - Train Accuracy: 0.6393, Validation Accuracy: 0.6574, Loss: 0.6027
Epoch   4 Batch   25/269 - Train Accuracy: 0.6482, Validation Accuracy: 0.6618, Loss: 0.6063
Epoch   4 Batch   26/269 - Train Accuracy: 0.6690, Validation Accuracy: 0.6522, Loss: 0.5368
Epoch   4 Batch   27/269 - Train Accuracy: 0.6403, Validation Accuracy: 0.6523, Loss: 0.5693
Epoch   4 Batch   28/269 - Train Accuracy: 0.6049, Validation Accuracy: 0.6559, Loss: 0.6149
Epoch   4 Batch   29/269 - Train Accuracy: 0.6488, Validation Accuracy: 0.6534, Loss: 0.6037
Epoch   4 Batch   30/269 - Train Accuracy: 0.6628, Validation Accuracy: 0.6531, Loss: 0.5632
Epoch   4 Batch   31/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6523, Loss: 0.5621
Epoch   4 Batch   32/269 - Train Accuracy: 0.6447, Validation Accuracy: 0.6538, Loss: 0.5623
Epoch   4 Batch   33/269 - Train Accuracy: 0.6749, Validation Accuracy: 0.6547, Loss: 0.5447
Epoch   4 Batch   34/269 - Train Accuracy: 0.6554, Validation Accuracy: 0.6547, Loss: 0.5670
Epoch   4 Batch   35/269 - Train Accuracy: 0.6464, Validation Accuracy: 0.6546, Loss: 0.5812
Epoch   4 Batch   36/269 - Train Accuracy: 0.6532, Validation Accuracy: 0.6570, Loss: 0.5657
Epoch   4 Batch   37/269 - Train Accuracy: 0.6586, Validation Accuracy: 0.6524, Loss: 0.5636
Epoch   4 Batch   38/269 - Train Accuracy: 0.6488, Validation Accuracy: 0.6493, Loss: 0.5658
Epoch   4 Batch   39/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6503, Loss: 0.5566
Epoch   4 Batch   40/269 - Train Accuracy: 0.6284, Validation Accuracy: 0.6456, Loss: 0.5849
Epoch   4 Batch   41/269 - Train Accuracy: 0.6276, Validation Accuracy: 0.6477, Loss: 0.5752
Epoch   4 Batch   42/269 - Train Accuracy: 0.6663, Validation Accuracy: 0.6464, Loss: 0.5393
Epoch   4 Batch   43/269 - Train Accuracy: 0.6437, Validation Accuracy: 0.6578, Loss: 0.5901
Epoch   4 Batch   44/269 - Train Accuracy: 0.6474, Validation Accuracy: 0.6535, Loss: 0.5716
Epoch   4 Batch   45/269 - Train Accuracy: 0.6381, Validation Accuracy: 0.6523, Loss: 0.5898
Epoch   4 Batch   46/269 - Train Accuracy: 0.6292, Validation Accuracy: 0.6562, Loss: 0.5783
Epoch   4 Batch   47/269 - Train Accuracy: 0.6716, Validation Accuracy: 0.6570, Loss: 0.5215
Epoch   4 Batch   48/269 - Train Accuracy: 0.6618, Validation Accuracy: 0.6503, Loss: 0.5482
Epoch   4 Batch   49/269 - Train Accuracy: 0.6247, Validation Accuracy: 0.6499, Loss: 0.5770
Epoch   4 Batch   50/269 - Train Accuracy: 0.6363, Validation Accuracy: 0.6498, Loss: 0.5804
Epoch   4 Batch   51/269 - Train Accuracy: 0.6335, Validation Accuracy: 0.6485, Loss: 0.5683
Epoch   4 Batch   52/269 - Train Accuracy: 0.6361, Validation Accuracy: 0.6480, Loss: 0.5419
Epoch   4 Batch   53/269 - Train Accuracy: 0.6456, Validation Accuracy: 0.6547, Loss: 0.5954
Epoch   4 Batch   54/269 - Train Accuracy: 0.6483, Validation Accuracy: 0.6556, Loss: 0.5805
Epoch   4 Batch   55/269 - Train Accuracy: 0.6556, Validation Accuracy: 0.6444, Loss: 0.5552
Epoch   4 Batch   56/269 - Train Accuracy: 0.6498, Validation Accuracy: 0.6514, Loss: 0.5680
Epoch   4 Batch   57/269 - Train Accuracy: 0.6571, Validation Accuracy: 0.6617, Loss: 0.5726
Epoch   4 Batch   58/269 - Train Accuracy: 0.6689, Validation Accuracy: 0.6583, Loss: 0.5558
Epoch   4 Batch   59/269 - Train Accuracy: 0.6712, Validation Accuracy: 0.6485, Loss: 0.5373
Epoch   4 Batch   60/269 - Train Accuracy: 0.6648, Validation Accuracy: 0.6584, Loss: 0.5307
Epoch   4 Batch   61/269 - Train Accuracy: 0.6675, Validation Accuracy: 0.6574, Loss: 0.5229
Epoch   4 Batch   62/269 - Train Accuracy: 0.6614, Validation Accuracy: 0.6546, Loss: 0.5377
Epoch   4 Batch   63/269 - Train Accuracy: 0.6377, Validation Accuracy: 0.6586, Loss: 0.5666
Epoch   4 Batch   64/269 - Train Accuracy: 0.6607, Validation Accuracy: 0.6614, Loss: 0.5386
Epoch   4 Batch   65/269 - Train Accuracy: 0.6532, Validation Accuracy: 0.6607, Loss: 0.5556
Epoch   4 Batch   66/269 - Train Accuracy: 0.6689, Validation Accuracy: 0.6544, Loss: 0.5419
Epoch   4 Batch   67/269 - Train Accuracy: 0.6496, Validation Accuracy: 0.6590, Loss: 0.5644
Epoch   4 Batch   68/269 - Train Accuracy: 0.6635, Validation Accuracy: 0.6573, Loss: 0.5582
Epoch   4 Batch   69/269 - Train Accuracy: 0.5952, Validation Accuracy: 0.6539, Loss: 0.6121
Epoch   4 Batch   70/269 - Train Accuracy: 0.6569, Validation Accuracy: 0.6504, Loss: 0.5651
Epoch   4 Batch   71/269 - Train Accuracy: 0.6246, Validation Accuracy: 0.6509, Loss: 0.5973
Epoch   4 Batch   72/269 - Train Accuracy: 0.6535, Validation Accuracy: 0.6507, Loss: 0.5721
Epoch   4 Batch   73/269 - Train Accuracy: 0.6494, Validation Accuracy: 0.6608, Loss: 0.5854
Epoch   4 Batch   74/269 - Train Accuracy: 0.6503, Validation Accuracy: 0.6587, Loss: 0.5697
Epoch   4 Batch   75/269 - Train Accuracy: 0.6590, Validation Accuracy: 0.6552, Loss: 0.5608
Epoch   4 Batch   76/269 - Train Accuracy: 0.6230, Validation Accuracy: 0.6476, Loss: 0.5758
Epoch   4 Batch   77/269 - Train Accuracy: 0.6541, Validation Accuracy: 0.6507, Loss: 0.5543
Epoch   4 Batch   78/269 - Train Accuracy: 0.6598, Validation Accuracy: 0.6615, Loss: 0.5554
Epoch   4 Batch   79/269 - Train Accuracy: 0.6385, Validation Accuracy: 0.6606, Loss: 0.5535
Epoch   4 Batch   80/269 - Train Accuracy: 0.6584, Validation Accuracy: 0.6589, Loss: 0.5529
Epoch   4 Batch   81/269 - Train Accuracy: 0.6588, Validation Accuracy: 0.6567, Loss: 0.5744
Epoch   4 Batch   82/269 - Train Accuracy: 0.6695, Validation Accuracy: 0.6589, Loss: 0.5363
Epoch   4 Batch   83/269 - Train Accuracy: 0.6567, Validation Accuracy: 0.6657, Loss: 0.5583
Epoch   4 Batch   84/269 - Train Accuracy: 0.6534, Validation Accuracy: 0.6633, Loss: 0.5350
Epoch   4 Batch   85/269 - Train Accuracy: 0.6469, Validation Accuracy: 0.6618, Loss: 0.5541
Epoch   4 Batch   86/269 - Train Accuracy: 0.6584, Validation Accuracy: 0.6593, Loss: 0.5507
Epoch   4 Batch   87/269 - Train Accuracy: 0.6432, Validation Accuracy: 0.6669, Loss: 0.5860
Epoch   4 Batch   88/269 - Train Accuracy: 0.6518, Validation Accuracy: 0.6628, Loss: 0.5530
Epoch   4 Batch   89/269 - Train Accuracy: 0.6606, Validation Accuracy: 0.6641, Loss: 0.5567
Epoch   4 Batch   90/269 - Train Accuracy: 0.6229, Validation Accuracy: 0.6594, Loss: 0.5865
Epoch   4 Batch   91/269 - Train Accuracy: 0.6648, Validation Accuracy: 0.6614, Loss: 0.5276
Epoch   4 Batch   92/269 - Train Accuracy: 0.6745, Validation Accuracy: 0.6675, Loss: 0.5399
Epoch   4 Batch   93/269 - Train Accuracy: 0.6809, Validation Accuracy: 0.6661, Loss: 0.5248
Epoch   4 Batch   94/269 - Train Accuracy: 0.6540, Validation Accuracy: 0.6695, Loss: 0.5646
Epoch   4 Batch   95/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6635, Loss: 0.5436
Epoch   4 Batch   96/269 - Train Accuracy: 0.6580, Validation Accuracy: 0.6635, Loss: 0.5474
Epoch   4 Batch   97/269 - Train Accuracy: 0.6695, Validation Accuracy: 0.6648, Loss: 0.5410
Epoch   4 Batch   98/269 - Train Accuracy: 0.6669, Validation Accuracy: 0.6645, Loss: 0.5450
Epoch   4 Batch   99/269 - Train Accuracy: 0.6454, Validation Accuracy: 0.6658, Loss: 0.5625
Epoch   4 Batch  100/269 - Train Accuracy: 0.6817, Validation Accuracy: 0.6612, Loss: 0.5359
Epoch   4 Batch  101/269 - Train Accuracy: 0.6274, Validation Accuracy: 0.6636, Loss: 0.5873
Epoch   4 Batch  102/269 - Train Accuracy: 0.6505, Validation Accuracy: 0.6621, Loss: 0.5539
Epoch   4 Batch  103/269 - Train Accuracy: 0.6763, Validation Accuracy: 0.6634, Loss: 0.5456
Epoch   4 Batch  104/269 - Train Accuracy: 0.6584, Validation Accuracy: 0.6609, Loss: 0.5455
Epoch   4 Batch  105/269 - Train Accuracy: 0.6589, Validation Accuracy: 0.6618, Loss: 0.5521
Epoch   4 Batch  106/269 - Train Accuracy: 0.6531, Validation Accuracy: 0.6626, Loss: 0.5428
Epoch   4 Batch  107/269 - Train Accuracy: 0.6224, Validation Accuracy: 0.6622, Loss: 0.5728
Epoch   4 Batch  108/269 - Train Accuracy: 0.6676, Validation Accuracy: 0.6653, Loss: 0.5464
Epoch   4 Batch  109/269 - Train Accuracy: 0.6457, Validation Accuracy: 0.6604, Loss: 0.5544
Epoch   4 Batch  110/269 - Train Accuracy: 0.6473, Validation Accuracy: 0.6518, Loss: 0.5310
Epoch   4 Batch  111/269 - Train Accuracy: 0.6388, Validation Accuracy: 0.6599, Loss: 0.5794
Epoch   4 Batch  112/269 - Train Accuracy: 0.6505, Validation Accuracy: 0.6625, Loss: 0.5439
Epoch   4 Batch  113/269 - Train Accuracy: 0.6616, Validation Accuracy: 0.6657, Loss: 0.5246
Epoch   4 Batch  114/269 - Train Accuracy: 0.6661, Validation Accuracy: 0.6693, Loss: 0.5450
Epoch   4 Batch  115/269 - Train Accuracy: 0.6409, Validation Accuracy: 0.6657, Loss: 0.5660
Epoch   4 Batch  116/269 - Train Accuracy: 0.6652, Validation Accuracy: 0.6689, Loss: 0.5501
Epoch   4 Batch  117/269 - Train Accuracy: 0.6570, Validation Accuracy: 0.6573, Loss: 0.5429
Epoch   4 Batch  118/269 - Train Accuracy: 0.6565, Validation Accuracy: 0.6525, Loss: 0.5221
Epoch   4 Batch  119/269 - Train Accuracy: 0.6364, Validation Accuracy: 0.6602, Loss: 0.5661
Epoch   4 Batch  120/269 - Train Accuracy: 0.6437, Validation Accuracy: 0.6678, Loss: 0.5594
Epoch   4 Batch  121/269 - Train Accuracy: 0.6647, Validation Accuracy: 0.6630, Loss: 0.5364
Epoch   4 Batch  122/269 - Train Accuracy: 0.6619, Validation Accuracy: 0.6628, Loss: 0.5327
Epoch   4 Batch  123/269 - Train Accuracy: 0.6635, Validation Accuracy: 0.6673, Loss: 0.5623
Epoch   4 Batch  124/269 - Train Accuracy: 0.6585, Validation Accuracy: 0.6643, Loss: 0.5244
Epoch   4 Batch  125/269 - Train Accuracy: 0.6713, Validation Accuracy: 0.6630, Loss: 0.5284
Epoch   4 Batch  126/269 - Train Accuracy: 0.6645, Validation Accuracy: 0.6629, Loss: 0.5294
Epoch   4 Batch  127/269 - Train Accuracy: 0.6439, Validation Accuracy: 0.6658, Loss: 0.5581
Epoch   4 Batch  128/269 - Train Accuracy: 0.6692, Validation Accuracy: 0.6628, Loss: 0.5400
Epoch   4 Batch  129/269 - Train Accuracy: 0.6616, Validation Accuracy: 0.6672, Loss: 0.5374
Epoch   4 Batch  130/269 - Train Accuracy: 0.6337, Validation Accuracy: 0.6648, Loss: 0.5606
Epoch   4 Batch  131/269 - Train Accuracy: 0.6339, Validation Accuracy: 0.6598, Loss: 0.5565
Epoch   4 Batch  132/269 - Train Accuracy: 0.6355, Validation Accuracy: 0.6655, Loss: 0.5500
Epoch   4 Batch  133/269 - Train Accuracy: 0.6653, Validation Accuracy: 0.6611, Loss: 0.5249
Epoch   4 Batch  134/269 - Train Accuracy: 0.6405, Validation Accuracy: 0.6652, Loss: 0.5522
Epoch   4 Batch  135/269 - Train Accuracy: 0.6280, Validation Accuracy: 0.6599, Loss: 0.5723
Epoch   4 Batch  136/269 - Train Accuracy: 0.6342, Validation Accuracy: 0.6590, Loss: 0.5692
Epoch   4 Batch  137/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6597, Loss: 0.5622
Epoch   4 Batch  138/269 - Train Accuracy: 0.6637, Validation Accuracy: 0.6598, Loss: 0.5471
Epoch   4 Batch  139/269 - Train Accuracy: 0.6604, Validation Accuracy: 0.6645, Loss: 0.5177
Epoch   4 Batch  140/269 - Train Accuracy: 0.6589, Validation Accuracy: 0.6607, Loss: 0.5550
Epoch   4 Batch  141/269 - Train Accuracy: 0.6485, Validation Accuracy: 0.6634, Loss: 0.5539
Epoch   4 Batch  142/269 - Train Accuracy: 0.6710, Validation Accuracy: 0.6716, Loss: 0.5246
Epoch   4 Batch  143/269 - Train Accuracy: 0.6533, Validation Accuracy: 0.6655, Loss: 0.5294
Epoch   4 Batch  144/269 - Train Accuracy: 0.6722, Validation Accuracy: 0.6648, Loss: 0.5177
Epoch   4 Batch  145/269 - Train Accuracy: 0.6478, Validation Accuracy: 0.6622, Loss: 0.5319
Epoch   4 Batch  146/269 - Train Accuracy: 0.6527, Validation Accuracy: 0.6634, Loss: 0.5251
Epoch   4 Batch  147/269 - Train Accuracy: 0.6704, Validation Accuracy: 0.6652, Loss: 0.5085
Epoch   4 Batch  148/269 - Train Accuracy: 0.6458, Validation Accuracy: 0.6742, Loss: 0.5356
Epoch   4 Batch  149/269 - Train Accuracy: 0.6537, Validation Accuracy: 0.6671, Loss: 0.5430
Epoch   4 Batch  150/269 - Train Accuracy: 0.6647, Validation Accuracy: 0.6735, Loss: 0.5394
Epoch   4 Batch  151/269 - Train Accuracy: 0.6832, Validation Accuracy: 0.6739, Loss: 0.5133
Epoch   4 Batch  152/269 - Train Accuracy: 0.6537, Validation Accuracy: 0.6654, Loss: 0.5323
Epoch   4 Batch  153/269 - Train Accuracy: 0.6682, Validation Accuracy: 0.6688, Loss: 0.5211
Epoch   4 Batch  154/269 - Train Accuracy: 0.6657, Validation Accuracy: 0.6718, Loss: 0.5393
Epoch   4 Batch  155/269 - Train Accuracy: 0.6883, Validation Accuracy: 0.6784, Loss: 0.5102
Epoch   4 Batch  156/269 - Train Accuracy: 0.6406, Validation Accuracy: 0.6646, Loss: 0.5485
Epoch   4 Batch  157/269 - Train Accuracy: 0.6435, Validation Accuracy: 0.6690, Loss: 0.5294
Epoch   4 Batch  158/269 - Train Accuracy: 0.6547, Validation Accuracy: 0.6729, Loss: 0.5250
Epoch   4 Batch  159/269 - Train Accuracy: 0.6549, Validation Accuracy: 0.6680, Loss: 0.5344
Epoch   4 Batch  160/269 - Train Accuracy: 0.6597, Validation Accuracy: 0.6672, Loss: 0.5209
Epoch   4 Batch  161/269 - Train Accuracy: 0.6601, Validation Accuracy: 0.6711, Loss: 0.5319
Epoch   4 Batch  162/269 - Train Accuracy: 0.6690, Validation Accuracy: 0.6692, Loss: 0.5213
Epoch   4 Batch  163/269 - Train Accuracy: 0.6519, Validation Accuracy: 0.6649, Loss: 0.5213
Epoch   4 Batch  164/269 - Train Accuracy: 0.6677, Validation Accuracy: 0.6693, Loss: 0.5243
Epoch   4 Batch  165/269 - Train Accuracy: 0.6704, Validation Accuracy: 0.6697, Loss: 0.5411
Epoch   4 Batch  166/269 - Train Accuracy: 0.6683, Validation Accuracy: 0.6768, Loss: 0.5087
Epoch   4 Batch  167/269 - Train Accuracy: 0.6589, Validation Accuracy: 0.6645, Loss: 0.5297
Epoch   4 Batch  168/269 - Train Accuracy: 0.6563, Validation Accuracy: 0.6709, Loss: 0.5366
Epoch   4 Batch  169/269 - Train Accuracy: 0.6709, Validation Accuracy: 0.6730, Loss: 0.5305
Epoch   4 Batch  170/269 - Train Accuracy: 0.6689, Validation Accuracy: 0.6693, Loss: 0.5290
Epoch   4 Batch  171/269 - Train Accuracy: 0.6698, Validation Accuracy: 0.6700, Loss: 0.5429
Epoch   4 Batch  172/269 - Train Accuracy: 0.6589, Validation Accuracy: 0.6674, Loss: 0.5509
Epoch   4 Batch  173/269 - Train Accuracy: 0.6773, Validation Accuracy: 0.6744, Loss: 0.5110
Epoch   4 Batch  174/269 - Train Accuracy: 0.6511, Validation Accuracy: 0.6735, Loss: 0.5256
Epoch   4 Batch  175/269 - Train Accuracy: 0.6532, Validation Accuracy: 0.6725, Loss: 0.5422
Epoch   4 Batch  176/269 - Train Accuracy: 0.6450, Validation Accuracy: 0.6721, Loss: 0.5578
Epoch   4 Batch  177/269 - Train Accuracy: 0.6900, Validation Accuracy: 0.6734, Loss: 0.4982
Epoch   4 Batch  178/269 - Train Accuracy: 0.6521, Validation Accuracy: 0.6703, Loss: 0.5346
Epoch   4 Batch  179/269 - Train Accuracy: 0.6527, Validation Accuracy: 0.6721, Loss: 0.5291
Epoch   4 Batch  180/269 - Train Accuracy: 0.6639, Validation Accuracy: 0.6673, Loss: 0.5137
Epoch   4 Batch  181/269 - Train Accuracy: 0.6601, Validation Accuracy: 0.6708, Loss: 0.5265
Epoch   4 Batch  182/269 - Train Accuracy: 0.6843, Validation Accuracy: 0.6720, Loss: 0.5276
Epoch   4 Batch  183/269 - Train Accuracy: 0.7183, Validation Accuracy: 0.6736, Loss: 0.4518
Epoch   4 Batch  184/269 - Train Accuracy: 0.6335, Validation Accuracy: 0.6715, Loss: 0.5361
Epoch   4 Batch  185/269 - Train Accuracy: 0.6784, Validation Accuracy: 0.6731, Loss: 0.5176
Epoch   4 Batch  186/269 - Train Accuracy: 0.6477, Validation Accuracy: 0.6717, Loss: 0.5392
Epoch   4 Batch  187/269 - Train Accuracy: 0.6740, Validation Accuracy: 0.6789, Loss: 0.5130
Epoch   4 Batch  188/269 - Train Accuracy: 0.6655, Validation Accuracy: 0.6710, Loss: 0.4988
Epoch   4 Batch  189/269 - Train Accuracy: 0.6650, Validation Accuracy: 0.6740, Loss: 0.5070
Epoch   4 Batch  190/269 - Train Accuracy: 0.6410, Validation Accuracy: 0.6743, Loss: 0.4971
Epoch   4 Batch  191/269 - Train Accuracy: 0.6752, Validation Accuracy: 0.6815, Loss: 0.5173
Epoch   4 Batch  192/269 - Train Accuracy: 0.6798, Validation Accuracy: 0.6818, Loss: 0.5196
Epoch   4 Batch  193/269 - Train Accuracy: 0.6859, Validation Accuracy: 0.6757, Loss: 0.5119
Epoch   4 Batch  194/269 - Train Accuracy: 0.6583, Validation Accuracy: 0.6793, Loss: 0.5214
Epoch   4 Batch  195/269 - Train Accuracy: 0.6702, Validation Accuracy: 0.6696, Loss: 0.5197
Epoch   4 Batch  196/269 - Train Accuracy: 0.6644, Validation Accuracy: 0.6690, Loss: 0.5093
Epoch   4 Batch  197/269 - Train Accuracy: 0.6713, Validation Accuracy: 0.6733, Loss: 0.5400
Epoch   4 Batch  198/269 - Train Accuracy: 0.6536, Validation Accuracy: 0.6722, Loss: 0.5409
Epoch   4 Batch  199/269 - Train Accuracy: 0.6813, Validation Accuracy: 0.6746, Loss: 0.5177
Epoch   4 Batch  200/269 - Train Accuracy: 0.6745, Validation Accuracy: 0.6670, Loss: 0.5285
Epoch   4 Batch  201/269 - Train Accuracy: 0.6790, Validation Accuracy: 0.6713, Loss: 0.5159
Epoch   4 Batch  202/269 - Train Accuracy: 0.6690, Validation Accuracy: 0.6687, Loss: 0.5117
Epoch   4 Batch  203/269 - Train Accuracy: 0.6445, Validation Accuracy: 0.6772, Loss: 0.5440
Epoch   4 Batch  204/269 - Train Accuracy: 0.6538, Validation Accuracy: 0.6719, Loss: 0.5394
Epoch   4 Batch  205/269 - Train Accuracy: 0.6827, Validation Accuracy: 0.6748, Loss: 0.5025
Epoch   4 Batch  206/269 - Train Accuracy: 0.6498, Validation Accuracy: 0.6702, Loss: 0.5293
Epoch   4 Batch  207/269 - Train Accuracy: 0.6772, Validation Accuracy: 0.6783, Loss: 0.5005
Epoch   4 Batch  208/269 - Train Accuracy: 0.6584, Validation Accuracy: 0.6801, Loss: 0.5366
Epoch   4 Batch  209/269 - Train Accuracy: 0.6743, Validation Accuracy: 0.6676, Loss: 0.5209
Epoch   4 Batch  210/269 - Train Accuracy: 0.6740, Validation Accuracy: 0.6645, Loss: 0.5007
Epoch   4 Batch  211/269 - Train Accuracy: 0.6803, Validation Accuracy: 0.6713, Loss: 0.5179
Epoch   4 Batch  212/269 - Train Accuracy: 0.6699, Validation Accuracy: 0.6711, Loss: 0.5013
Epoch   4 Batch  213/269 - Train Accuracy: 0.6719, Validation Accuracy: 0.6763, Loss: 0.5084
Epoch   4 Batch  214/269 - Train Accuracy: 0.6748, Validation Accuracy: 0.6756, Loss: 0.5141
Epoch   4 Batch  215/269 - Train Accuracy: 0.6949, Validation Accuracy: 0.6657, Loss: 0.4805
Epoch   4 Batch  216/269 - Train Accuracy: 0.6434, Validation Accuracy: 0.6775, Loss: 0.5510
Epoch   4 Batch  217/269 - Train Accuracy: 0.6389, Validation Accuracy: 0.6663, Loss: 0.5404
Epoch   4 Batch  218/269 - Train Accuracy: 0.6643, Validation Accuracy: 0.6767, Loss: 0.5383
Epoch   4 Batch  219/269 - Train Accuracy: 0.6729, Validation Accuracy: 0.6776, Loss: 0.5484
Epoch   4 Batch  220/269 - Train Accuracy: 0.6704, Validation Accuracy: 0.6667, Loss: 0.4816
Epoch   4 Batch  221/269 - Train Accuracy: 0.6896, Validation Accuracy: 0.6625, Loss: 0.5099
Epoch   4 Batch  222/269 - Train Accuracy: 0.6887, Validation Accuracy: 0.6754, Loss: 0.5026
Epoch   4 Batch  223/269 - Train Accuracy: 0.6656, Validation Accuracy: 0.6709, Loss: 0.5032
Epoch   4 Batch  224/269 - Train Accuracy: 0.6619, Validation Accuracy: 0.6649, Loss: 0.5287
Epoch   4 Batch  225/269 - Train Accuracy: 0.6783, Validation Accuracy: 0.6746, Loss: 0.5241
Epoch   4 Batch  226/269 - Train Accuracy: 0.6921, Validation Accuracy: 0.6669, Loss: 0.4985
Epoch   4 Batch  227/269 - Train Accuracy: 0.7201, Validation Accuracy: 0.6735, Loss: 0.4699
Epoch   4 Batch  228/269 - Train Accuracy: 0.6671, Validation Accuracy: 0.6742, Loss: 0.5052
Epoch   4 Batch  229/269 - Train Accuracy: 0.6681, Validation Accuracy: 0.6750, Loss: 0.5023
Epoch   4 Batch  230/269 - Train Accuracy: 0.6783, Validation Accuracy: 0.6713, Loss: 0.5001
Epoch   4 Batch  231/269 - Train Accuracy: 0.6698, Validation Accuracy: 0.6723, Loss: 0.5386
Epoch   4 Batch  232/269 - Train Accuracy: 0.6366, Validation Accuracy: 0.6788, Loss: 0.5317
Epoch   4 Batch  233/269 - Train Accuracy: 0.6963, Validation Accuracy: 0.6785, Loss: 0.5173
Epoch   4 Batch  234/269 - Train Accuracy: 0.6717, Validation Accuracy: 0.6800, Loss: 0.5023
Epoch   4 Batch  235/269 - Train Accuracy: 0.6830, Validation Accuracy: 0.6831, Loss: 0.4963
Epoch   4 Batch  236/269 - Train Accuracy: 0.6644, Validation Accuracy: 0.6799, Loss: 0.4974
Epoch   4 Batch  237/269 - Train Accuracy: 0.6707, Validation Accuracy: 0.6787, Loss: 0.4997
Epoch   4 Batch  238/269 - Train Accuracy: 0.7127, Validation Accuracy: 0.6833, Loss: 0.4988
Epoch   4 Batch  239/269 - Train Accuracy: 0.6812, Validation Accuracy: 0.6880, Loss: 0.4966
Epoch   4 Batch  240/269 - Train Accuracy: 0.7031, Validation Accuracy: 0.6828, Loss: 0.4623
Epoch   4 Batch  241/269 - Train Accuracy: 0.6970, Validation Accuracy: 0.6788, Loss: 0.5109
Epoch   4 Batch  242/269 - Train Accuracy: 0.6718, Validation Accuracy: 0.6777, Loss: 0.4945
Epoch   4 Batch  243/269 - Train Accuracy: 0.6793, Validation Accuracy: 0.6798, Loss: 0.4870
Epoch   4 Batch  244/269 - Train Accuracy: 0.6899, Validation Accuracy: 0.6859, Loss: 0.4934
Epoch   4 Batch  245/269 - Train Accuracy: 0.6434, Validation Accuracy: 0.6822, Loss: 0.5267
Epoch   4 Batch  246/269 - Train Accuracy: 0.6626, Validation Accuracy: 0.6744, Loss: 0.5004
Epoch   4 Batch  247/269 - Train Accuracy: 0.6653, Validation Accuracy: 0.6758, Loss: 0.5168
Epoch   4 Batch  248/269 - Train Accuracy: 0.6896, Validation Accuracy: 0.6744, Loss: 0.4852
Epoch   4 Batch  249/269 - Train Accuracy: 0.7025, Validation Accuracy: 0.6790, Loss: 0.4691
Epoch   4 Batch  250/269 - Train Accuracy: 0.6531, Validation Accuracy: 0.6711, Loss: 0.5027
Epoch   4 Batch  251/269 - Train Accuracy: 0.7079, Validation Accuracy: 0.6726, Loss: 0.4857
Epoch   4 Batch  252/269 - Train Accuracy: 0.6654, Validation Accuracy: 0.6774, Loss: 0.4992
Epoch   4 Batch  253/269 - Train Accuracy: 0.6499, Validation Accuracy: 0.6738, Loss: 0.5042
Epoch   4 Batch  254/269 - Train Accuracy: 0.6712, Validation Accuracy: 0.6756, Loss: 0.4943
Epoch   4 Batch  255/269 - Train Accuracy: 0.6713, Validation Accuracy: 0.6681, Loss: 0.4833
Epoch   4 Batch  256/269 - Train Accuracy: 0.6778, Validation Accuracy: 0.6755, Loss: 0.5058
Epoch   4 Batch  257/269 - Train Accuracy: 0.6801, Validation Accuracy: 0.6851, Loss: 0.5024
Epoch   4 Batch  258/269 - Train Accuracy: 0.6694, Validation Accuracy: 0.6789, Loss: 0.5028
Epoch   4 Batch  259/269 - Train Accuracy: 0.6897, Validation Accuracy: 0.6773, Loss: 0.4990
Epoch   4 Batch  260/269 - Train Accuracy: 0.6580, Validation Accuracy: 0.6848, Loss: 0.5200
Epoch   4 Batch  261/269 - Train Accuracy: 0.6663, Validation Accuracy: 0.6895, Loss: 0.5159
Epoch   4 Batch  262/269 - Train Accuracy: 0.6899, Validation Accuracy: 0.6867, Loss: 0.5016
Epoch   4 Batch  263/269 - Train Accuracy: 0.6572, Validation Accuracy: 0.6814, Loss: 0.5136
Epoch   4 Batch  264/269 - Train Accuracy: 0.6601, Validation Accuracy: 0.6812, Loss: 0.5360
Epoch   4 Batch  265/269 - Train Accuracy: 0.6403, Validation Accuracy: 0.6622, Loss: 0.5615
Epoch   4 Batch  266/269 - Train Accuracy: 0.6573, Validation Accuracy: 0.6603, Loss: 0.6630
Epoch   4 Batch  267/269 - Train Accuracy: 0.6273, Validation Accuracy: 0.6323, Loss: 0.5395
Epoch   5 Batch    1/269 - Train Accuracy: 0.6289, Validation Accuracy: 0.6541, Loss: 0.5419
Epoch   5 Batch    2/269 - Train Accuracy: 0.6328, Validation Accuracy: 0.6557, Loss: 0.5596
Epoch   5 Batch    3/269 - Train Accuracy: 0.6442, Validation Accuracy: 0.6539, Loss: 0.5941
Epoch   5 Batch    4/269 - Train Accuracy: 0.6196, Validation Accuracy: 0.6511, Loss: 0.5687
Epoch   5 Batch    5/269 - Train Accuracy: 0.6143, Validation Accuracy: 0.6484, Loss: 0.5532
Epoch   5 Batch    6/269 - Train Accuracy: 0.6732, Validation Accuracy: 0.6539, Loss: 0.5301
Epoch   5 Batch    7/269 - Train Accuracy: 0.6688, Validation Accuracy: 0.6645, Loss: 0.5369
Epoch   5 Batch    8/269 - Train Accuracy: 0.6366, Validation Accuracy: 0.6571, Loss: 0.5466
Epoch   5 Batch    9/269 - Train Accuracy: 0.6368, Validation Accuracy: 0.6646, Loss: 0.5330
Epoch   5 Batch   10/269 - Train Accuracy: 0.6618, Validation Accuracy: 0.6694, Loss: 0.5393
Epoch   5 Batch   11/269 - Train Accuracy: 0.6623, Validation Accuracy: 0.6757, Loss: 0.5281
Epoch   5 Batch   12/269 - Train Accuracy: 0.6734, Validation Accuracy: 0.6810, Loss: 0.5491
Epoch   5 Batch   13/269 - Train Accuracy: 0.6857, Validation Accuracy: 0.6830, Loss: 0.4833
Epoch   5 Batch   14/269 - Train Accuracy: 0.6682, Validation Accuracy: 0.6847, Loss: 0.5223
Epoch   5 Batch   15/269 - Train Accuracy: 0.6487, Validation Accuracy: 0.6746, Loss: 0.4967
Epoch   5 Batch   16/269 - Train Accuracy: 0.6639, Validation Accuracy: 0.6692, Loss: 0.5105
Epoch   5 Batch   17/269 - Train Accuracy: 0.6628, Validation Accuracy: 0.6718, Loss: 0.5021
Epoch   5 Batch   18/269 - Train Accuracy: 0.6630, Validation Accuracy: 0.6781, Loss: 0.5186
Epoch   5 Batch   19/269 - Train Accuracy: 0.6908, Validation Accuracy: 0.6847, Loss: 0.4798
Epoch   5 Batch   20/269 - Train Accuracy: 0.6738, Validation Accuracy: 0.6878, Loss: 0.5183
Epoch   5 Batch   21/269 - Train Accuracy: 0.6735, Validation Accuracy: 0.6856, Loss: 0.5401
Epoch   5 Batch   22/269 - Train Accuracy: 0.7050, Validation Accuracy: 0.6833, Loss: 0.4882
Epoch   5 Batch   23/269 - Train Accuracy: 0.6739, Validation Accuracy: 0.6834, Loss: 0.4923
Epoch   5 Batch   24/269 - Train Accuracy: 0.6676, Validation Accuracy: 0.6769, Loss: 0.5198
Epoch   5 Batch   25/269 - Train Accuracy: 0.6608, Validation Accuracy: 0.6784, Loss: 0.5301
Epoch   5 Batch   26/269 - Train Accuracy: 0.6964, Validation Accuracy: 0.6799, Loss: 0.4645
Epoch   5 Batch   27/269 - Train Accuracy: 0.6942, Validation Accuracy: 0.6857, Loss: 0.4961
Epoch   5 Batch   28/269 - Train Accuracy: 0.6421, Validation Accuracy: 0.6878, Loss: 0.5340
Epoch   5 Batch   29/269 - Train Accuracy: 0.7027, Validation Accuracy: 0.6850, Loss: 0.5110
Epoch   5 Batch   30/269 - Train Accuracy: 0.6947, Validation Accuracy: 0.6861, Loss: 0.4820
Epoch   5 Batch   31/269 - Train Accuracy: 0.6866, Validation Accuracy: 0.6813, Loss: 0.4827
Epoch   5 Batch   32/269 - Train Accuracy: 0.6911, Validation Accuracy: 0.6826, Loss: 0.4837
Epoch   5 Batch   33/269 - Train Accuracy: 0.7038, Validation Accuracy: 0.6843, Loss: 0.4774
Epoch   5 Batch   34/269 - Train Accuracy: 0.6834, Validation Accuracy: 0.6830, Loss: 0.4806
Epoch   5 Batch   35/269 - Train Accuracy: 0.6824, Validation Accuracy: 0.6852, Loss: 0.5006
Epoch   5 Batch   36/269 - Train Accuracy: 0.6827, Validation Accuracy: 0.6791, Loss: 0.4853
Epoch   5 Batch   37/269 - Train Accuracy: 0.7068, Validation Accuracy: 0.6803, Loss: 0.4841
Epoch   5 Batch   38/269 - Train Accuracy: 0.6926, Validation Accuracy: 0.6815, Loss: 0.4910
Epoch   5 Batch   39/269 - Train Accuracy: 0.6814, Validation Accuracy: 0.6866, Loss: 0.4792
Epoch   5 Batch   40/269 - Train Accuracy: 0.6785, Validation Accuracy: 0.6824, Loss: 0.5069
Epoch   5 Batch   41/269 - Train Accuracy: 0.6700, Validation Accuracy: 0.6812, Loss: 0.4903
Epoch   5 Batch   42/269 - Train Accuracy: 0.7027, Validation Accuracy: 0.6782, Loss: 0.4654
Epoch   5 Batch   43/269 - Train Accuracy: 0.6764, Validation Accuracy: 0.6851, Loss: 0.4926
Epoch   5 Batch   44/269 - Train Accuracy: 0.6841, Validation Accuracy: 0.6808, Loss: 0.4850
Epoch   5 Batch   45/269 - Train Accuracy: 0.6677, Validation Accuracy: 0.6831, Loss: 0.4977
Epoch   5 Batch   46/269 - Train Accuracy: 0.6689, Validation Accuracy: 0.6816, Loss: 0.4991
Epoch   5 Batch   47/269 - Train Accuracy: 0.7022, Validation Accuracy: 0.6831, Loss: 0.4495
Epoch   5 Batch   48/269 - Train Accuracy: 0.6917, Validation Accuracy: 0.6811, Loss: 0.4733
Epoch   5 Batch   49/269 - Train Accuracy: 0.6694, Validation Accuracy: 0.6783, Loss: 0.4892
Epoch   5 Batch   50/269 - Train Accuracy: 0.6699, Validation Accuracy: 0.6802, Loss: 0.4993
Epoch   5 Batch   51/269 - Train Accuracy: 0.6690, Validation Accuracy: 0.6852, Loss: 0.4854
Epoch   5 Batch   52/269 - Train Accuracy: 0.6734, Validation Accuracy: 0.6930, Loss: 0.4650
Epoch   5 Batch   53/269 - Train Accuracy: 0.6852, Validation Accuracy: 0.6892, Loss: 0.5062
Epoch   5 Batch   54/269 - Train Accuracy: 0.7001, Validation Accuracy: 0.6887, Loss: 0.4958
Epoch   5 Batch   55/269 - Train Accuracy: 0.7048, Validation Accuracy: 0.6879, Loss: 0.4745
Epoch   5 Batch   56/269 - Train Accuracy: 0.6930, Validation Accuracy: 0.6919, Loss: 0.4776
Epoch   5 Batch   57/269 - Train Accuracy: 0.6835, Validation Accuracy: 0.6892, Loss: 0.4891
Epoch   5 Batch   58/269 - Train Accuracy: 0.7083, Validation Accuracy: 0.6919, Loss: 0.4713
Epoch   5 Batch   59/269 - Train Accuracy: 0.7058, Validation Accuracy: 0.6852, Loss: 0.4542
Epoch   5 Batch   60/269 - Train Accuracy: 0.6987, Validation Accuracy: 0.6923, Loss: 0.4583
Epoch   5 Batch   61/269 - Train Accuracy: 0.7139, Validation Accuracy: 0.6901, Loss: 0.4429
Epoch   5 Batch   62/269 - Train Accuracy: 0.7131, Validation Accuracy: 0.6885, Loss: 0.4562
Epoch   5 Batch   63/269 - Train Accuracy: 0.6750, Validation Accuracy: 0.6905, Loss: 0.4781
Epoch   5 Batch   64/269 - Train Accuracy: 0.6903, Validation Accuracy: 0.6918, Loss: 0.4676
Epoch   5 Batch   65/269 - Train Accuracy: 0.6863, Validation Accuracy: 0.6906, Loss: 0.4757
Epoch   5 Batch   66/269 - Train Accuracy: 0.7031, Validation Accuracy: 0.6875, Loss: 0.4599
Epoch   5 Batch   67/269 - Train Accuracy: 0.6899, Validation Accuracy: 0.6986, Loss: 0.4840
Epoch   5 Batch   68/269 - Train Accuracy: 0.6752, Validation Accuracy: 0.6949, Loss: 0.4771
Epoch   5 Batch   69/269 - Train Accuracy: 0.6467, Validation Accuracy: 0.6821, Loss: 0.5238
Epoch   5 Batch   70/269 - Train Accuracy: 0.7021, Validation Accuracy: 0.6812, Loss: 0.4805
Epoch   5 Batch   71/269 - Train Accuracy: 0.6683, Validation Accuracy: 0.6894, Loss: 0.5029
Epoch   5 Batch   72/269 - Train Accuracy: 0.6950, Validation Accuracy: 0.6948, Loss: 0.4676
Epoch   5 Batch   73/269 - Train Accuracy: 0.6844, Validation Accuracy: 0.6972, Loss: 0.4894
Epoch   5 Batch   74/269 - Train Accuracy: 0.6971, Validation Accuracy: 0.6904, Loss: 0.4871
Epoch   5 Batch   75/269 - Train Accuracy: 0.6876, Validation Accuracy: 0.6792, Loss: 0.4674
Epoch   5 Batch   76/269 - Train Accuracy: 0.6816, Validation Accuracy: 0.6858, Loss: 0.4839
Epoch   5 Batch   77/269 - Train Accuracy: 0.6949, Validation Accuracy: 0.6957, Loss: 0.4650
Epoch   5 Batch   78/269 - Train Accuracy: 0.7034, Validation Accuracy: 0.6896, Loss: 0.4742
Epoch   5 Batch   79/269 - Train Accuracy: 0.7041, Validation Accuracy: 0.6898, Loss: 0.4717
Epoch   5 Batch   80/269 - Train Accuracy: 0.7021, Validation Accuracy: 0.6865, Loss: 0.4630
Epoch   5 Batch   81/269 - Train Accuracy: 0.7055, Validation Accuracy: 0.6885, Loss: 0.4904
Epoch   5 Batch   82/269 - Train Accuracy: 0.7094, Validation Accuracy: 0.6891, Loss: 0.4486
Epoch   5 Batch   83/269 - Train Accuracy: 0.6848, Validation Accuracy: 0.6934, Loss: 0.4735
Epoch   5 Batch   84/269 - Train Accuracy: 0.6890, Validation Accuracy: 0.6900, Loss: 0.4628
Epoch   5 Batch   85/269 - Train Accuracy: 0.6958, Validation Accuracy: 0.6907, Loss: 0.4694
Epoch   5 Batch   86/269 - Train Accuracy: 0.7021, Validation Accuracy: 0.6964, Loss: 0.4638
Epoch   5 Batch   87/269 - Train Accuracy: 0.6800, Validation Accuracy: 0.6879, Loss: 0.4981
Epoch   5 Batch   88/269 - Train Accuracy: 0.6839, Validation Accuracy: 0.6857, Loss: 0.4675
Epoch   5 Batch   89/269 - Train Accuracy: 0.6913, Validation Accuracy: 0.6920, Loss: 0.4699
Epoch   5 Batch   90/269 - Train Accuracy: 0.6784, Validation Accuracy: 0.7014, Loss: 0.4947
Epoch   5 Batch   91/269 - Train Accuracy: 0.7124, Validation Accuracy: 0.6996, Loss: 0.4514
Epoch   5 Batch   92/269 - Train Accuracy: 0.6961, Validation Accuracy: 0.6964, Loss: 0.4612
Epoch   5 Batch   93/269 - Train Accuracy: 0.7057, Validation Accuracy: 0.6966, Loss: 0.4471
Epoch   5 Batch   94/269 - Train Accuracy: 0.6862, Validation Accuracy: 0.6984, Loss: 0.4804
Epoch   5 Batch   95/269 - Train Accuracy: 0.6866, Validation Accuracy: 0.6990, Loss: 0.4605
Epoch   5 Batch   96/269 - Train Accuracy: 0.6895, Validation Accuracy: 0.6990, Loss: 0.4676
Epoch   5 Batch   97/269 - Train Accuracy: 0.7086, Validation Accuracy: 0.7006, Loss: 0.4585
Epoch   5 Batch   98/269 - Train Accuracy: 0.7013, Validation Accuracy: 0.6998, Loss: 0.4675
Epoch   5 Batch   99/269 - Train Accuracy: 0.6850, Validation Accuracy: 0.7020, Loss: 0.4773
Epoch   5 Batch  100/269 - Train Accuracy: 0.7121, Validation Accuracy: 0.7010, Loss: 0.4484
Epoch   5 Batch  101/269 - Train Accuracy: 0.6735, Validation Accuracy: 0.7072, Loss: 0.4947
Epoch   5 Batch  102/269 - Train Accuracy: 0.6825, Validation Accuracy: 0.6993, Loss: 0.4597
Epoch   5 Batch  103/269 - Train Accuracy: 0.7145, Validation Accuracy: 0.6956, Loss: 0.4678
Epoch   5 Batch  104/269 - Train Accuracy: 0.6795, Validation Accuracy: 0.7011, Loss: 0.4531
Epoch   5 Batch  105/269 - Train Accuracy: 0.7085, Validation Accuracy: 0.7026, Loss: 0.4606
Epoch   5 Batch  106/269 - Train Accuracy: 0.6972, Validation Accuracy: 0.7052, Loss: 0.4589
Epoch   5 Batch  107/269 - Train Accuracy: 0.6756, Validation Accuracy: 0.7042, Loss: 0.4853
Epoch   5 Batch  108/269 - Train Accuracy: 0.6974, Validation Accuracy: 0.6957, Loss: 0.4588
Epoch   5 Batch  109/269 - Train Accuracy: 0.6875, Validation Accuracy: 0.6978, Loss: 0.4632
Epoch   5 Batch  110/269 - Train Accuracy: 0.7017, Validation Accuracy: 0.6921, Loss: 0.4552
Epoch   5 Batch  111/269 - Train Accuracy: 0.6899, Validation Accuracy: 0.6943, Loss: 0.4992
Epoch   5 Batch  112/269 - Train Accuracy: 0.6830, Validation Accuracy: 0.6988, Loss: 0.4598
Epoch   5 Batch  113/269 - Train Accuracy: 0.7006, Validation Accuracy: 0.6916, Loss: 0.4416
Epoch   5 Batch  114/269 - Train Accuracy: 0.7036, Validation Accuracy: 0.6929, Loss: 0.4557
Epoch   5 Batch  115/269 - Train Accuracy: 0.6797, Validation Accuracy: 0.6970, Loss: 0.4770
Epoch   5 Batch  116/269 - Train Accuracy: 0.7124, Validation Accuracy: 0.7048, Loss: 0.4699
Epoch   5 Batch  117/269 - Train Accuracy: 0.7001, Validation Accuracy: 0.6879, Loss: 0.4606
Epoch   5 Batch  118/269 - Train Accuracy: 0.7024, Validation Accuracy: 0.6852, Loss: 0.4455
Epoch   5 Batch  119/269 - Train Accuracy: 0.7028, Validation Accuracy: 0.6963, Loss: 0.4863
Epoch   5 Batch  120/269 - Train Accuracy: 0.6771, Validation Accuracy: 0.6976, Loss: 0.4719
Epoch   5 Batch  121/269 - Train Accuracy: 0.6882, Validation Accuracy: 0.7024, Loss: 0.4468
Epoch   5 Batch  122/269 - Train Accuracy: 0.6944, Validation Accuracy: 0.7029, Loss: 0.4532
Epoch   5 Batch  123/269 - Train Accuracy: 0.6929, Validation Accuracy: 0.6985, Loss: 0.4735
Epoch   5 Batch  124/269 - Train Accuracy: 0.6853, Validation Accuracy: 0.7077, Loss: 0.4491
Epoch   5 Batch  125/269 - Train Accuracy: 0.7086, Validation Accuracy: 0.7102, Loss: 0.4411
Epoch   5 Batch  126/269 - Train Accuracy: 0.7039, Validation Accuracy: 0.7047, Loss: 0.4533
Epoch   5 Batch  127/269 - Train Accuracy: 0.6744, Validation Accuracy: 0.7044, Loss: 0.4709
Epoch   5 Batch  128/269 - Train Accuracy: 0.7065, Validation Accuracy: 0.7035, Loss: 0.4494
Epoch   5 Batch  129/269 - Train Accuracy: 0.7051, Validation Accuracy: 0.7032, Loss: 0.4497
Epoch   5 Batch  130/269 - Train Accuracy: 0.6863, Validation Accuracy: 0.7055, Loss: 0.4787
Epoch   5 Batch  131/269 - Train Accuracy: 0.6852, Validation Accuracy: 0.7046, Loss: 0.4613
Epoch   5 Batch  132/269 - Train Accuracy: 0.6936, Validation Accuracy: 0.7054, Loss: 0.4687
Epoch   5 Batch  133/269 - Train Accuracy: 0.7087, Validation Accuracy: 0.7074, Loss: 0.4349
Epoch   5 Batch  134/269 - Train Accuracy: 0.6734, Validation Accuracy: 0.7072, Loss: 0.4675
Epoch   5 Batch  135/269 - Train Accuracy: 0.6827, Validation Accuracy: 0.7118, Loss: 0.4805
Epoch   5 Batch  136/269 - Train Accuracy: 0.6792, Validation Accuracy: 0.7007, Loss: 0.4791
Epoch   5 Batch  137/269 - Train Accuracy: 0.6998, Validation Accuracy: 0.7090, Loss: 0.4815
Epoch   5 Batch  138/269 - Train Accuracy: 0.7143, Validation Accuracy: 0.7027, Loss: 0.4611
Epoch   5 Batch  139/269 - Train Accuracy: 0.7216, Validation Accuracy: 0.7006, Loss: 0.4382
Epoch   5 Batch  140/269 - Train Accuracy: 0.7098, Validation Accuracy: 0.6999, Loss: 0.4610
Epoch   5 Batch  141/269 - Train Accuracy: 0.7021, Validation Accuracy: 0.7025, Loss: 0.4655
Epoch   5 Batch  142/269 - Train Accuracy: 0.7182, Validation Accuracy: 0.7049, Loss: 0.4456
Epoch   5 Batch  143/269 - Train Accuracy: 0.6892, Validation Accuracy: 0.7098, Loss: 0.4471
Epoch   5 Batch  144/269 - Train Accuracy: 0.7055, Validation Accuracy: 0.7126, Loss: 0.4286
Epoch   5 Batch  145/269 - Train Accuracy: 0.7096, Validation Accuracy: 0.7067, Loss: 0.4460
Epoch   5 Batch  146/269 - Train Accuracy: 0.7075, Validation Accuracy: 0.7045, Loss: 0.4339
Epoch   5 Batch  147/269 - Train Accuracy: 0.7194, Validation Accuracy: 0.7087, Loss: 0.4313
Epoch   5 Batch  148/269 - Train Accuracy: 0.6848, Validation Accuracy: 0.7033, Loss: 0.4543
Epoch   5 Batch  149/269 - Train Accuracy: 0.6890, Validation Accuracy: 0.7023, Loss: 0.4657
Epoch   5 Batch  150/269 - Train Accuracy: 0.7161, Validation Accuracy: 0.6967, Loss: 0.4503
Epoch   5 Batch  151/269 - Train Accuracy: 0.7218, Validation Accuracy: 0.6987, Loss: 0.4314
Epoch   5 Batch  152/269 - Train Accuracy: 0.6952, Validation Accuracy: 0.7066, Loss: 0.4470
Epoch   5 Batch  153/269 - Train Accuracy: 0.7108, Validation Accuracy: 0.7027, Loss: 0.4449
Epoch   5 Batch  154/269 - Train Accuracy: 0.7057, Validation Accuracy: 0.7088, Loss: 0.4532
Epoch   5 Batch  155/269 - Train Accuracy: 0.7178, Validation Accuracy: 0.7069, Loss: 0.4269
Epoch   5 Batch  156/269 - Train Accuracy: 0.6896, Validation Accuracy: 0.7009, Loss: 0.4641
Epoch   5 Batch  157/269 - Train Accuracy: 0.6985, Validation Accuracy: 0.7099, Loss: 0.4369
Epoch   5 Batch  158/269 - Train Accuracy: 0.7001, Validation Accuracy: 0.7115, Loss: 0.4370
Epoch   5 Batch  159/269 - Train Accuracy: 0.6978, Validation Accuracy: 0.7121, Loss: 0.4584
Epoch   5 Batch  160/269 - Train Accuracy: 0.7161, Validation Accuracy: 0.7137, Loss: 0.4488
Epoch   5 Batch  161/269 - Train Accuracy: 0.6868, Validation Accuracy: 0.7037, Loss: 0.4519
Epoch   5 Batch  162/269 - Train Accuracy: 0.7196, Validation Accuracy: 0.7100, Loss: 0.4462
Epoch   5 Batch  163/269 - Train Accuracy: 0.7041, Validation Accuracy: 0.7078, Loss: 0.4572
Epoch   5 Batch  164/269 - Train Accuracy: 0.7061, Validation Accuracy: 0.7051, Loss: 0.4520
Epoch   5 Batch  165/269 - Train Accuracy: 0.6896, Validation Accuracy: 0.7051, Loss: 0.4572
Epoch   5 Batch  166/269 - Train Accuracy: 0.7098, Validation Accuracy: 0.7001, Loss: 0.4284
Epoch   5 Batch  167/269 - Train Accuracy: 0.7003, Validation Accuracy: 0.7008, Loss: 0.4500
Epoch   5 Batch  168/269 - Train Accuracy: 0.7135, Validation Accuracy: 0.7069, Loss: 0.4568
Epoch   5 Batch  169/269 - Train Accuracy: 0.7031, Validation Accuracy: 0.7119, Loss: 0.4490
Epoch   5 Batch  170/269 - Train Accuracy: 0.7120, Validation Accuracy: 0.7138, Loss: 0.4456
Epoch   5 Batch  171/269 - Train Accuracy: 0.7130, Validation Accuracy: 0.7118, Loss: 0.4588
Epoch   5 Batch  172/269 - Train Accuracy: 0.6954, Validation Accuracy: 0.7140, Loss: 0.4494
Epoch   5 Batch  173/269 - Train Accuracy: 0.7255, Validation Accuracy: 0.7193, Loss: 0.4325
Epoch   5 Batch  174/269 - Train Accuracy: 0.7012, Validation Accuracy: 0.7175, Loss: 0.4494
Epoch   5 Batch  175/269 - Train Accuracy: 0.7035, Validation Accuracy: 0.7178, Loss: 0.4524
Epoch   5 Batch  176/269 - Train Accuracy: 0.6951, Validation Accuracy: 0.7142, Loss: 0.4607
Epoch   5 Batch  177/269 - Train Accuracy: 0.7243, Validation Accuracy: 0.7112, Loss: 0.4179
Epoch   5 Batch  178/269 - Train Accuracy: 0.7271, Validation Accuracy: 0.7168, Loss: 0.4524
Epoch   5 Batch  179/269 - Train Accuracy: 0.7107, Validation Accuracy: 0.7186, Loss: 0.4442
Epoch   5 Batch  180/269 - Train Accuracy: 0.7443, Validation Accuracy: 0.7222, Loss: 0.4305
Epoch   5 Batch  181/269 - Train Accuracy: 0.7033, Validation Accuracy: 0.7141, Loss: 0.4419
Epoch   5 Batch  182/269 - Train Accuracy: 0.7320, Validation Accuracy: 0.7151, Loss: 0.4383
Epoch   5 Batch  183/269 - Train Accuracy: 0.7700, Validation Accuracy: 0.7236, Loss: 0.3801
Epoch   5 Batch  184/269 - Train Accuracy: 0.6950, Validation Accuracy: 0.7206, Loss: 0.4552
Epoch   5 Batch  185/269 - Train Accuracy: 0.7294, Validation Accuracy: 0.7134, Loss: 0.4315
Epoch   5 Batch  186/269 - Train Accuracy: 0.6994, Validation Accuracy: 0.7162, Loss: 0.4400
Epoch   5 Batch  187/269 - Train Accuracy: 0.7189, Validation Accuracy: 0.7198, Loss: 0.4263
Epoch   5 Batch  188/269 - Train Accuracy: 0.7175, Validation Accuracy: 0.7235, Loss: 0.4191
Epoch   5 Batch  189/269 - Train Accuracy: 0.7278, Validation Accuracy: 0.7156, Loss: 0.4225
Epoch   5 Batch  190/269 - Train Accuracy: 0.7207, Validation Accuracy: 0.7268, Loss: 0.4203
Epoch   5 Batch  191/269 - Train Accuracy: 0.7183, Validation Accuracy: 0.7208, Loss: 0.4232
Epoch   5 Batch  192/269 - Train Accuracy: 0.7153, Validation Accuracy: 0.7065, Loss: 0.4391
Epoch   5 Batch  193/269 - Train Accuracy: 0.7286, Validation Accuracy: 0.7263, Loss: 0.4263
Epoch   5 Batch  194/269 - Train Accuracy: 0.7088, Validation Accuracy: 0.7245, Loss: 0.4428
Epoch   5 Batch  195/269 - Train Accuracy: 0.7259, Validation Accuracy: 0.7270, Loss: 0.4393
Epoch   5 Batch  196/269 - Train Accuracy: 0.6970, Validation Accuracy: 0.7037, Loss: 0.4206
Epoch   5 Batch  197/269 - Train Accuracy: 0.7110, Validation Accuracy: 0.7245, Loss: 0.4503
Epoch   5 Batch  198/269 - Train Accuracy: 0.6869, Validation Accuracy: 0.7180, Loss: 0.4601
Epoch   5 Batch  199/269 - Train Accuracy: 0.7136, Validation Accuracy: 0.7241, Loss: 0.4507
Epoch   5 Batch  200/269 - Train Accuracy: 0.7047, Validation Accuracy: 0.7115, Loss: 0.4479
Epoch   5 Batch  201/269 - Train Accuracy: 0.7195, Validation Accuracy: 0.7136, Loss: 0.4361
Epoch   5 Batch  202/269 - Train Accuracy: 0.7147, Validation Accuracy: 0.7240, Loss: 0.4342
Epoch   5 Batch  203/269 - Train Accuracy: 0.6893, Validation Accuracy: 0.7148, Loss: 0.4595
Epoch   5 Batch  204/269 - Train Accuracy: 0.7046, Validation Accuracy: 0.7251, Loss: 0.4580
Epoch   5 Batch  205/269 - Train Accuracy: 0.7230, Validation Accuracy: 0.7146, Loss: 0.4234
Epoch   5 Batch  206/269 - Train Accuracy: 0.7081, Validation Accuracy: 0.7166, Loss: 0.4553
Epoch   5 Batch  207/269 - Train Accuracy: 0.7236, Validation Accuracy: 0.7271, Loss: 0.4148
Epoch   5 Batch  208/269 - Train Accuracy: 0.7157, Validation Accuracy: 0.7240, Loss: 0.4450
Epoch   5 Batch  209/269 - Train Accuracy: 0.7360, Validation Accuracy: 0.7251, Loss: 0.4310
Epoch   5 Batch  210/269 - Train Accuracy: 0.7210, Validation Accuracy: 0.7226, Loss: 0.4203
Epoch   5 Batch  211/269 - Train Accuracy: 0.7082, Validation Accuracy: 0.7234, Loss: 0.4346
Epoch   5 Batch  212/269 - Train Accuracy: 0.7125, Validation Accuracy: 0.7257, Loss: 0.4280
Epoch   5 Batch  213/269 - Train Accuracy: 0.7188, Validation Accuracy: 0.7301, Loss: 0.4271
Epoch   5 Batch  214/269 - Train Accuracy: 0.7098, Validation Accuracy: 0.7263, Loss: 0.4320
Epoch   5 Batch  215/269 - Train Accuracy: 0.7460, Validation Accuracy: 0.7258, Loss: 0.3977
Epoch   5 Batch  216/269 - Train Accuracy: 0.6834, Validation Accuracy: 0.7294, Loss: 0.4629
Epoch   5 Batch  217/269 - Train Accuracy: 0.7089, Validation Accuracy: 0.7329, Loss: 0.4451
Epoch   5 Batch  218/269 - Train Accuracy: 0.7258, Validation Accuracy: 0.7239, Loss: 0.4434
Epoch   5 Batch  219/269 - Train Accuracy: 0.7118, Validation Accuracy: 0.7154, Loss: 0.4553
Epoch   5 Batch  220/269 - Train Accuracy: 0.7425, Validation Accuracy: 0.7232, Loss: 0.4083
Epoch   5 Batch  221/269 - Train Accuracy: 0.7466, Validation Accuracy: 0.7259, Loss: 0.4292
Epoch   5 Batch  222/269 - Train Accuracy: 0.7518, Validation Accuracy: 0.7321, Loss: 0.4069
Epoch   5 Batch  223/269 - Train Accuracy: 0.7348, Validation Accuracy: 0.7275, Loss: 0.4145
Epoch   5 Batch  224/269 - Train Accuracy: 0.7320, Validation Accuracy: 0.7344, Loss: 0.4383
Epoch   5 Batch  225/269 - Train Accuracy: 0.7293, Validation Accuracy: 0.7262, Loss: 0.4216
Epoch   5 Batch  226/269 - Train Accuracy: 0.7322, Validation Accuracy: 0.7206, Loss: 0.4139
Epoch   5 Batch  227/269 - Train Accuracy: 0.7579, Validation Accuracy: 0.7331, Loss: 0.3892
Epoch   5 Batch  228/269 - Train Accuracy: 0.7257, Validation Accuracy: 0.7294, Loss: 0.4218
Epoch   5 Batch  229/269 - Train Accuracy: 0.7344, Validation Accuracy: 0.7295, Loss: 0.4171
Epoch   5 Batch  230/269 - Train Accuracy: 0.7180, Validation Accuracy: 0.7231, Loss: 0.4194
Epoch   5 Batch  231/269 - Train Accuracy: 0.7185, Validation Accuracy: 0.7251, Loss: 0.4463
Epoch   5 Batch  232/269 - Train Accuracy: 0.7120, Validation Accuracy: 0.7339, Loss: 0.4363
Epoch   5 Batch  233/269 - Train Accuracy: 0.7393, Validation Accuracy: 0.7300, Loss: 0.4292
Epoch   5 Batch  234/269 - Train Accuracy: 0.7187, Validation Accuracy: 0.7175, Loss: 0.4239
Epoch   5 Batch  235/269 - Train Accuracy: 0.7344, Validation Accuracy: 0.7304, Loss: 0.4092
Epoch   5 Batch  236/269 - Train Accuracy: 0.7188, Validation Accuracy: 0.7267, Loss: 0.4153
Epoch   5 Batch  237/269 - Train Accuracy: 0.7299, Validation Accuracy: 0.7259, Loss: 0.4212
Epoch   5 Batch  238/269 - Train Accuracy: 0.7329, Validation Accuracy: 0.7329, Loss: 0.4180
Epoch   5 Batch  239/269 - Train Accuracy: 0.7255, Validation Accuracy: 0.7298, Loss: 0.4189
Epoch   5 Batch  240/269 - Train Accuracy: 0.7505, Validation Accuracy: 0.7251, Loss: 0.3827
Epoch   5 Batch  241/269 - Train Accuracy: 0.7324, Validation Accuracy: 0.7178, Loss: 0.4333
Epoch   5 Batch  242/269 - Train Accuracy: 0.7286, Validation Accuracy: 0.7280, Loss: 0.4203
Epoch   5 Batch  243/269 - Train Accuracy: 0.7282, Validation Accuracy: 0.7237, Loss: 0.4043
Epoch   5 Batch  244/269 - Train Accuracy: 0.7120, Validation Accuracy: 0.7262, Loss: 0.4156
Epoch   5 Batch  245/269 - Train Accuracy: 0.6998, Validation Accuracy: 0.7293, Loss: 0.4653
Epoch   5 Batch  246/269 - Train Accuracy: 0.7158, Validation Accuracy: 0.7249, Loss: 0.4272
Epoch   5 Batch  247/269 - Train Accuracy: 0.7202, Validation Accuracy: 0.7283, Loss: 0.4353
Epoch   5 Batch  248/269 - Train Accuracy: 0.7118, Validation Accuracy: 0.7237, Loss: 0.4091
Epoch   5 Batch  249/269 - Train Accuracy: 0.7551, Validation Accuracy: 0.7355, Loss: 0.3943
Epoch   5 Batch  250/269 - Train Accuracy: 0.7124, Validation Accuracy: 0.7201, Loss: 0.4191
Epoch   5 Batch  251/269 - Train Accuracy: 0.7487, Validation Accuracy: 0.7346, Loss: 0.4065
Epoch   5 Batch  252/269 - Train Accuracy: 0.7121, Validation Accuracy: 0.7184, Loss: 0.4191
Epoch   5 Batch  253/269 - Train Accuracy: 0.7126, Validation Accuracy: 0.7275, Loss: 0.4248
Epoch   5 Batch  254/269 - Train Accuracy: 0.7347, Validation Accuracy: 0.7379, Loss: 0.4171
Epoch   5 Batch  255/269 - Train Accuracy: 0.7348, Validation Accuracy: 0.7341, Loss: 0.4129
Epoch   5 Batch  256/269 - Train Accuracy: 0.7070, Validation Accuracy: 0.7303, Loss: 0.4229
Epoch   5 Batch  257/269 - Train Accuracy: 0.7144, Validation Accuracy: 0.7322, Loss: 0.4234
Epoch   5 Batch  258/269 - Train Accuracy: 0.7429, Validation Accuracy: 0.7460, Loss: 0.4210
Epoch   5 Batch  259/269 - Train Accuracy: 0.7305, Validation Accuracy: 0.7432, Loss: 0.4129
Epoch   5 Batch  260/269 - Train Accuracy: 0.7154, Validation Accuracy: 0.7425, Loss: 0.4335
Epoch   5 Batch  261/269 - Train Accuracy: 0.7219, Validation Accuracy: 0.7325, Loss: 0.4417
Epoch   5 Batch  262/269 - Train Accuracy: 0.7244, Validation Accuracy: 0.7429, Loss: 0.4206
Epoch   5 Batch  263/269 - Train Accuracy: 0.7262, Validation Accuracy: 0.7440, Loss: 0.4251
Epoch   5 Batch  264/269 - Train Accuracy: 0.7215, Validation Accuracy: 0.7377, Loss: 0.4265
Epoch   5 Batch  265/269 - Train Accuracy: 0.7213, Validation Accuracy: 0.7387, Loss: 0.4137
Epoch   5 Batch  266/269 - Train Accuracy: 0.7451, Validation Accuracy: 0.7409, Loss: 0.4080
Epoch   5 Batch  267/269 - Train Accuracy: 0.7302, Validation Accuracy: 0.7415, Loss: 0.4233
Epoch   6 Batch    1/269 - Train Accuracy: 0.7192, Validation Accuracy: 0.7435, Loss: 0.4269
Epoch   6 Batch    2/269 - Train Accuracy: 0.7308, Validation Accuracy: 0.7380, Loss: 0.4206
Epoch   6 Batch    3/269 - Train Accuracy: 0.7356, Validation Accuracy: 0.7269, Loss: 0.4150
Epoch   6 Batch    4/269 - Train Accuracy: 0.7120, Validation Accuracy: 0.7450, Loss: 0.4344
Epoch   6 Batch    5/269 - Train Accuracy: 0.6963, Validation Accuracy: 0.7403, Loss: 0.4273
Epoch   6 Batch    6/269 - Train Accuracy: 0.7460, Validation Accuracy: 0.7480, Loss: 0.3991
Epoch   6 Batch    7/269 - Train Accuracy: 0.7241, Validation Accuracy: 0.7231, Loss: 0.3954
Epoch   6 Batch    8/269 - Train Accuracy: 0.7204, Validation Accuracy: 0.7367, Loss: 0.4329
Epoch   6 Batch    9/269 - Train Accuracy: 0.7201, Validation Accuracy: 0.7423, Loss: 0.4245
Epoch   6 Batch   10/269 - Train Accuracy: 0.7350, Validation Accuracy: 0.7383, Loss: 0.4227
Epoch   6 Batch   11/269 - Train Accuracy: 0.7305, Validation Accuracy: 0.7375, Loss: 0.4111
Epoch   6 Batch   12/269 - Train Accuracy: 0.7174, Validation Accuracy: 0.7430, Loss: 0.4375
Epoch   6 Batch   13/269 - Train Accuracy: 0.7502, Validation Accuracy: 0.7441, Loss: 0.3835
Epoch   6 Batch   14/269 - Train Accuracy: 0.7197, Validation Accuracy: 0.7411, Loss: 0.4167
Epoch   6 Batch   15/269 - Train Accuracy: 0.7311, Validation Accuracy: 0.7448, Loss: 0.3970
Epoch   6 Batch   16/269 - Train Accuracy: 0.7231, Validation Accuracy: 0.7203, Loss: 0.4116
Epoch   6 Batch   17/269 - Train Accuracy: 0.7331, Validation Accuracy: 0.7384, Loss: 0.3983
Epoch   6 Batch   18/269 - Train Accuracy: 0.7250, Validation Accuracy: 0.7421, Loss: 0.4134
Epoch   6 Batch   19/269 - Train Accuracy: 0.7520, Validation Accuracy: 0.7426, Loss: 0.3849
Epoch   6 Batch   20/269 - Train Accuracy: 0.7312, Validation Accuracy: 0.7427, Loss: 0.4145
Epoch   6 Batch   21/269 - Train Accuracy: 0.7218, Validation Accuracy: 0.7362, Loss: 0.4399
Epoch   6 Batch   22/269 - Train Accuracy: 0.7611, Validation Accuracy: 0.7356, Loss: 0.3969
Epoch   6 Batch   23/269 - Train Accuracy: 0.7252, Validation Accuracy: 0.7326, Loss: 0.4007
Epoch   6 Batch   24/269 - Train Accuracy: 0.7100, Validation Accuracy: 0.7312, Loss: 0.4224
Epoch   6 Batch   25/269 - Train Accuracy: 0.7210, Validation Accuracy: 0.7361, Loss: 0.4423
Epoch   6 Batch   26/269 - Train Accuracy: 0.7463, Validation Accuracy: 0.7388, Loss: 0.3828
Epoch   6 Batch   27/269 - Train Accuracy: 0.7374, Validation Accuracy: 0.7417, Loss: 0.4030
Epoch   6 Batch   28/269 - Train Accuracy: 0.6948, Validation Accuracy: 0.7351, Loss: 0.4412
Epoch   6 Batch   29/269 - Train Accuracy: 0.7466, Validation Accuracy: 0.7443, Loss: 0.4270
Epoch   6 Batch   30/269 - Train Accuracy: 0.7297, Validation Accuracy: 0.7414, Loss: 0.3997
Epoch   6 Batch   31/269 - Train Accuracy: 0.7418, Validation Accuracy: 0.7421, Loss: 0.3987
Epoch   6 Batch   32/269 - Train Accuracy: 0.7413, Validation Accuracy: 0.7400, Loss: 0.4033
Epoch   6 Batch   33/269 - Train Accuracy: 0.7634, Validation Accuracy: 0.7358, Loss: 0.3810
Epoch   6 Batch   34/269 - Train Accuracy: 0.7347, Validation Accuracy: 0.7440, Loss: 0.3966
Epoch   6 Batch   35/269 - Train Accuracy: 0.7394, Validation Accuracy: 0.7446, Loss: 0.4139
Epoch   6 Batch   36/269 - Train Accuracy: 0.7338, Validation Accuracy: 0.7447, Loss: 0.4023
Epoch   6 Batch   37/269 - Train Accuracy: 0.7473, Validation Accuracy: 0.7573, Loss: 0.4019
Epoch   6 Batch   38/269 - Train Accuracy: 0.7436, Validation Accuracy: 0.7534, Loss: 0.4020
Epoch   6 Batch   39/269 - Train Accuracy: 0.7312, Validation Accuracy: 0.7474, Loss: 0.4021
Epoch   6 Batch   40/269 - Train Accuracy: 0.7162, Validation Accuracy: 0.7506, Loss: 0.4160
Epoch   6 Batch   41/269 - Train Accuracy: 0.7459, Validation Accuracy: 0.7486, Loss: 0.4137
Epoch   6 Batch   42/269 - Train Accuracy: 0.7554, Validation Accuracy: 0.7537, Loss: 0.3777
Epoch   6 Batch   43/269 - Train Accuracy: 0.7258, Validation Accuracy: 0.7401, Loss: 0.4115
Epoch   6 Batch   44/269 - Train Accuracy: 0.7345, Validation Accuracy: 0.7445, Loss: 0.4004
Epoch   6 Batch   45/269 - Train Accuracy: 0.7345, Validation Accuracy: 0.7321, Loss: 0.4137
Epoch   6 Batch   46/269 - Train Accuracy: 0.7271, Validation Accuracy: 0.7456, Loss: 0.4087
Epoch   6 Batch   47/269 - Train Accuracy: 0.7567, Validation Accuracy: 0.7462, Loss: 0.3754
Epoch   6 Batch   48/269 - Train Accuracy: 0.7459, Validation Accuracy: 0.7367, Loss: 0.3868
Epoch   6 Batch   49/269 - Train Accuracy: 0.7226, Validation Accuracy: 0.7415, Loss: 0.4033
Epoch   6 Batch   50/269 - Train Accuracy: 0.7333, Validation Accuracy: 0.7546, Loss: 0.4224
Epoch   6 Batch   51/269 - Train Accuracy: 0.7496, Validation Accuracy: 0.7572, Loss: 0.4003
Epoch   6 Batch   52/269 - Train Accuracy: 0.7309, Validation Accuracy: 0.7518, Loss: 0.3824
Epoch   6 Batch   53/269 - Train Accuracy: 0.7384, Validation Accuracy: 0.7390, Loss: 0.4196
Epoch   6 Batch   54/269 - Train Accuracy: 0.7491, Validation Accuracy: 0.7449, Loss: 0.4038
Epoch   6 Batch   55/269 - Train Accuracy: 0.7415, Validation Accuracy: 0.7469, Loss: 0.3884
Epoch   6 Batch   56/269 - Train Accuracy: 0.7396, Validation Accuracy: 0.7500, Loss: 0.4051
Epoch   6 Batch   57/269 - Train Accuracy: 0.7536, Validation Accuracy: 0.7497, Loss: 0.4125
Epoch   6 Batch   58/269 - Train Accuracy: 0.7414, Validation Accuracy: 0.7427, Loss: 0.3827
Epoch   6 Batch   59/269 - Train Accuracy: 0.7653, Validation Accuracy: 0.7546, Loss: 0.3782
Epoch   6 Batch   60/269 - Train Accuracy: 0.7445, Validation Accuracy: 0.7567, Loss: 0.3747
Epoch   6 Batch   61/269 - Train Accuracy: 0.7629, Validation Accuracy: 0.7656, Loss: 0.3693
Epoch   6 Batch   62/269 - Train Accuracy: 0.7625, Validation Accuracy: 0.7547, Loss: 0.3769
Epoch   6 Batch   63/269 - Train Accuracy: 0.7426, Validation Accuracy: 0.7363, Loss: 0.3954
Epoch   6 Batch   64/269 - Train Accuracy: 0.7431, Validation Accuracy: 0.7578, Loss: 0.3876
Epoch   6 Batch   65/269 - Train Accuracy: 0.7353, Validation Accuracy: 0.7603, Loss: 0.3915
Epoch   6 Batch   66/269 - Train Accuracy: 0.7415, Validation Accuracy: 0.7461, Loss: 0.3876
Epoch   6 Batch   67/269 - Train Accuracy: 0.7371, Validation Accuracy: 0.7536, Loss: 0.3997
Epoch   6 Batch   68/269 - Train Accuracy: 0.7420, Validation Accuracy: 0.7572, Loss: 0.4056
Epoch   6 Batch   69/269 - Train Accuracy: 0.7154, Validation Accuracy: 0.7479, Loss: 0.4348
Epoch   6 Batch   70/269 - Train Accuracy: 0.7538, Validation Accuracy: 0.7418, Loss: 0.4010
Epoch   6 Batch   71/269 - Train Accuracy: 0.7353, Validation Accuracy: 0.7433, Loss: 0.4134
Epoch   6 Batch   72/269 - Train Accuracy: 0.7514, Validation Accuracy: 0.7456, Loss: 0.3968
Epoch   6 Batch   73/269 - Train Accuracy: 0.7457, Validation Accuracy: 0.7503, Loss: 0.4097
Epoch   6 Batch   74/269 - Train Accuracy: 0.7452, Validation Accuracy: 0.7504, Loss: 0.3902
Epoch   6 Batch   75/269 - Train Accuracy: 0.7475, Validation Accuracy: 0.7475, Loss: 0.3900
Epoch   6 Batch   76/269 - Train Accuracy: 0.7417, Validation Accuracy: 0.7549, Loss: 0.3996
Epoch   6 Batch   77/269 - Train Accuracy: 0.7515, Validation Accuracy: 0.7568, Loss: 0.3898
Epoch   6 Batch   78/269 - Train Accuracy: 0.7606, Validation Accuracy: 0.7483, Loss: 0.3870
Epoch   6 Batch   79/269 - Train Accuracy: 0.7456, Validation Accuracy: 0.7567, Loss: 0.3879
Epoch   6 Batch   80/269 - Train Accuracy: 0.7612, Validation Accuracy: 0.7526, Loss: 0.3876
Epoch   6 Batch   81/269 - Train Accuracy: 0.7440, Validation Accuracy: 0.7539, Loss: 0.4052
Epoch   6 Batch   82/269 - Train Accuracy: 0.7689, Validation Accuracy: 0.7575, Loss: 0.3724
Epoch   6 Batch   83/269 - Train Accuracy: 0.7434, Validation Accuracy: 0.7486, Loss: 0.4035
Epoch   6 Batch   84/269 - Train Accuracy: 0.7547, Validation Accuracy: 0.7441, Loss: 0.3853
Epoch   6 Batch   85/269 - Train Accuracy: 0.7538, Validation Accuracy: 0.7576, Loss: 0.3879
Epoch   6 Batch   86/269 - Train Accuracy: 0.7542, Validation Accuracy: 0.7530, Loss: 0.3847
Epoch   6 Batch   87/269 - Train Accuracy: 0.7291, Validation Accuracy: 0.7484, Loss: 0.4215
Epoch   6 Batch   88/269 - Train Accuracy: 0.7370, Validation Accuracy: 0.7469, Loss: 0.3947
Epoch   6 Batch   89/269 - Train Accuracy: 0.7510, Validation Accuracy: 0.7387, Loss: 0.3962
Epoch   6 Batch   90/269 - Train Accuracy: 0.7350, Validation Accuracy: 0.7520, Loss: 0.4122
Epoch   6 Batch   91/269 - Train Accuracy: 0.7505, Validation Accuracy: 0.7520, Loss: 0.3794
Epoch   6 Batch   92/269 - Train Accuracy: 0.7613, Validation Accuracy: 0.7504, Loss: 0.3812
Epoch   6 Batch   93/269 - Train Accuracy: 0.7316, Validation Accuracy: 0.7482, Loss: 0.3761
Epoch   6 Batch   94/269 - Train Accuracy: 0.7331, Validation Accuracy: 0.7593, Loss: 0.4052
Epoch   6 Batch   95/269 - Train Accuracy: 0.7406, Validation Accuracy: 0.7567, Loss: 0.3876
Epoch   6 Batch   96/269 - Train Accuracy: 0.7501, Validation Accuracy: 0.7631, Loss: 0.3812
Epoch   6 Batch   97/269 - Train Accuracy: 0.7636, Validation Accuracy: 0.7588, Loss: 0.3781
Epoch   6 Batch   98/269 - Train Accuracy: 0.7456, Validation Accuracy: 0.7533, Loss: 0.3843
Epoch   6 Batch   99/269 - Train Accuracy: 0.7280, Validation Accuracy: 0.7594, Loss: 0.3995
Epoch   6 Batch  100/269 - Train Accuracy: 0.7639, Validation Accuracy: 0.7546, Loss: 0.3829
Epoch   6 Batch  101/269 - Train Accuracy: 0.7272, Validation Accuracy: 0.7525, Loss: 0.4088
Epoch   6 Batch  102/269 - Train Accuracy: 0.7310, Validation Accuracy: 0.7546, Loss: 0.3864
Epoch   6 Batch  103/269 - Train Accuracy: 0.7476, Validation Accuracy: 0.7514, Loss: 0.3910
Epoch   6 Batch  104/269 - Train Accuracy: 0.7460, Validation Accuracy: 0.7567, Loss: 0.3816
Epoch   6 Batch  105/269 - Train Accuracy: 0.7341, Validation Accuracy: 0.7460, Loss: 0.3921
Epoch   6 Batch  106/269 - Train Accuracy: 0.7487, Validation Accuracy: 0.7540, Loss: 0.3823
Epoch   6 Batch  107/269 - Train Accuracy: 0.7273, Validation Accuracy: 0.7413, Loss: 0.4018
Epoch   6 Batch  108/269 - Train Accuracy: 0.7403, Validation Accuracy: 0.7616, Loss: 0.3915
Epoch   6 Batch  109/269 - Train Accuracy: 0.7324, Validation Accuracy: 0.7579, Loss: 0.4038
Epoch   6 Batch  110/269 - Train Accuracy: 0.7623, Validation Accuracy: 0.7637, Loss: 0.3858
Epoch   6 Batch  111/269 - Train Accuracy: 0.7433, Validation Accuracy: 0.7575, Loss: 0.4126
Epoch   6 Batch  112/269 - Train Accuracy: 0.7335, Validation Accuracy: 0.7596, Loss: 0.3901
Epoch   6 Batch  113/269 - Train Accuracy: 0.7479, Validation Accuracy: 0.7625, Loss: 0.3688
Epoch   6 Batch  114/269 - Train Accuracy: 0.7546, Validation Accuracy: 0.7568, Loss: 0.3811
Epoch   6 Batch  115/269 - Train Accuracy: 0.7294, Validation Accuracy: 0.7622, Loss: 0.4077
Epoch   6 Batch  116/269 - Train Accuracy: 0.7631, Validation Accuracy: 0.7527, Loss: 0.3861
Epoch   6 Batch  117/269 - Train Accuracy: 0.7467, Validation Accuracy: 0.7520, Loss: 0.3813
Epoch   6 Batch  118/269 - Train Accuracy: 0.7626, Validation Accuracy: 0.7617, Loss: 0.3692
Epoch   6 Batch  119/269 - Train Accuracy: 0.7499, Validation Accuracy: 0.7650, Loss: 0.3991
Epoch   6 Batch  120/269 - Train Accuracy: 0.7462, Validation Accuracy: 0.7694, Loss: 0.3943
Epoch   6 Batch  121/269 - Train Accuracy: 0.7440, Validation Accuracy: 0.7590, Loss: 0.3656
Epoch   6 Batch  122/269 - Train Accuracy: 0.7468, Validation Accuracy: 0.7527, Loss: 0.3760
Epoch   6 Batch  123/269 - Train Accuracy: 0.7500, Validation Accuracy: 0.7654, Loss: 0.3957
Epoch   6 Batch  124/269 - Train Accuracy: 0.7414, Validation Accuracy: 0.7615, Loss: 0.3713
Epoch   6 Batch  125/269 - Train Accuracy: 0.7693, Validation Accuracy: 0.7516, Loss: 0.3679
Epoch   6 Batch  126/269 - Train Accuracy: 0.7547, Validation Accuracy: 0.7394, Loss: 0.3799
Epoch   6 Batch  127/269 - Train Accuracy: 0.7460, Validation Accuracy: 0.7615, Loss: 0.3982
Epoch   6 Batch  128/269 - Train Accuracy: 0.7567, Validation Accuracy: 0.7592, Loss: 0.3750
Epoch   6 Batch  129/269 - Train Accuracy: 0.7521, Validation Accuracy: 0.7620, Loss: 0.3706
Epoch   6 Batch  130/269 - Train Accuracy: 0.7186, Validation Accuracy: 0.7467, Loss: 0.3999
Epoch   6 Batch  131/269 - Train Accuracy: 0.7366, Validation Accuracy: 0.7476, Loss: 0.3898
Epoch   6 Batch  132/269 - Train Accuracy: 0.7283, Validation Accuracy: 0.7567, Loss: 0.3920
Epoch   6 Batch  133/269 - Train Accuracy: 0.7698, Validation Accuracy: 0.7662, Loss: 0.3711
Epoch   6 Batch  134/269 - Train Accuracy: 0.7340, Validation Accuracy: 0.7591, Loss: 0.3878
Epoch   6 Batch  135/269 - Train Accuracy: 0.7265, Validation Accuracy: 0.7609, Loss: 0.4098
Epoch   6 Batch  136/269 - Train Accuracy: 0.7446, Validation Accuracy: 0.7678, Loss: 0.4086
Epoch   6 Batch  137/269 - Train Accuracy: 0.7511, Validation Accuracy: 0.7688, Loss: 0.3993
Epoch   6 Batch  138/269 - Train Accuracy: 0.7602, Validation Accuracy: 0.7648, Loss: 0.3838
Epoch   6 Batch  139/269 - Train Accuracy: 0.7583, Validation Accuracy: 0.7676, Loss: 0.3622
Epoch   6 Batch  140/269 - Train Accuracy: 0.7641, Validation Accuracy: 0.7540, Loss: 0.3914
Epoch   6 Batch  141/269 - Train Accuracy: 0.7655, Validation Accuracy: 0.7635, Loss: 0.3852
Epoch   6 Batch  142/269 - Train Accuracy: 0.7687, Validation Accuracy: 0.7596, Loss: 0.3663
Epoch   6 Batch  143/269 - Train Accuracy: 0.7568, Validation Accuracy: 0.7670, Loss: 0.3761
Epoch   6 Batch  144/269 - Train Accuracy: 0.7631, Validation Accuracy: 0.7610, Loss: 0.3640
Epoch   6 Batch  145/269 - Train Accuracy: 0.7582, Validation Accuracy: 0.7598, Loss: 0.3635
Epoch   6 Batch  146/269 - Train Accuracy: 0.7617, Validation Accuracy: 0.7639, Loss: 0.3701
Epoch   6 Batch  147/269 - Train Accuracy: 0.7760, Validation Accuracy: 0.7625, Loss: 0.3618
Epoch   6 Batch  148/269 - Train Accuracy: 0.7548, Validation Accuracy: 0.7690, Loss: 0.3797
Epoch   6 Batch  149/269 - Train Accuracy: 0.7400, Validation Accuracy: 0.7732, Loss: 0.3850
Epoch   6 Batch  150/269 - Train Accuracy: 0.7666, Validation Accuracy: 0.7652, Loss: 0.3763
Epoch   6 Batch  151/269 - Train Accuracy: 0.7693, Validation Accuracy: 0.7662, Loss: 0.3621
Epoch   6 Batch  152/269 - Train Accuracy: 0.7483, Validation Accuracy: 0.7685, Loss: 0.3713
Epoch   6 Batch  153/269 - Train Accuracy: 0.7628, Validation Accuracy: 0.7685, Loss: 0.3602
Epoch   6 Batch  154/269 - Train Accuracy: 0.7622, Validation Accuracy: 0.7678, Loss: 0.3815
Epoch   6 Batch  155/269 - Train Accuracy: 0.7743, Validation Accuracy: 0.7590, Loss: 0.3492
Epoch   6 Batch  156/269 - Train Accuracy: 0.7417, Validation Accuracy: 0.7617, Loss: 0.3855
Epoch   6 Batch  157/269 - Train Accuracy: 0.7518, Validation Accuracy: 0.7669, Loss: 0.3638
Epoch   6 Batch  158/269 - Train Accuracy: 0.7511, Validation Accuracy: 0.7630, Loss: 0.3742
Epoch   6 Batch  159/269 - Train Accuracy: 0.7458, Validation Accuracy: 0.7643, Loss: 0.3770
Epoch   6 Batch  160/269 - Train Accuracy: 0.7653, Validation Accuracy: 0.7664, Loss: 0.3673
Epoch   6 Batch  161/269 - Train Accuracy: 0.7564, Validation Accuracy: 0.7696, Loss: 0.3753
Epoch   6 Batch  162/269 - Train Accuracy: 0.7680, Validation Accuracy: 0.7636, Loss: 0.3667
Epoch   6 Batch  163/269 - Train Accuracy: 0.7575, Validation Accuracy: 0.7623, Loss: 0.3771
Epoch   6 Batch  164/269 - Train Accuracy: 0.7729, Validation Accuracy: 0.7719, Loss: 0.3709
Epoch   6 Batch  165/269 - Train Accuracy: 0.7653, Validation Accuracy: 0.7740, Loss: 0.3744
Epoch   6 Batch  166/269 - Train Accuracy: 0.7617, Validation Accuracy: 0.7655, Loss: 0.3478
Epoch   6 Batch  167/269 - Train Accuracy: 0.7546, Validation Accuracy: 0.7677, Loss: 0.3762
Epoch   6 Batch  168/269 - Train Accuracy: 0.7480, Validation Accuracy: 0.7704, Loss: 0.3834
Epoch   6 Batch  169/269 - Train Accuracy: 0.7476, Validation Accuracy: 0.7636, Loss: 0.3728
Epoch   6 Batch  170/269 - Train Accuracy: 0.7495, Validation Accuracy: 0.7632, Loss: 0.3707
Epoch   6 Batch  171/269 - Train Accuracy: 0.7752, Validation Accuracy: 0.7668, Loss: 0.3856
Epoch   6 Batch  172/269 - Train Accuracy: 0.7586, Validation Accuracy: 0.7638, Loss: 0.3763
Epoch   6 Batch  173/269 - Train Accuracy: 0.7653, Validation Accuracy: 0.7685, Loss: 0.3634
Epoch   6 Batch  174/269 - Train Accuracy: 0.7553, Validation Accuracy: 0.7662, Loss: 0.3736
Epoch   6 Batch  175/269 - Train Accuracy: 0.7525, Validation Accuracy: 0.7723, Loss: 0.3887
Epoch   6 Batch  176/269 - Train Accuracy: 0.7635, Validation Accuracy: 0.7701, Loss: 0.3821
Epoch   6 Batch  177/269 - Train Accuracy: 0.7752, Validation Accuracy: 0.7746, Loss: 0.3523
Epoch   6 Batch  178/269 - Train Accuracy: 0.7588, Validation Accuracy: 0.7622, Loss: 0.3716
Epoch   6 Batch  179/269 - Train Accuracy: 0.7532, Validation Accuracy: 0.7599, Loss: 0.3655
Epoch   6 Batch  180/269 - Train Accuracy: 0.7646, Validation Accuracy: 0.7685, Loss: 0.3622
Epoch   6 Batch  181/269 - Train Accuracy: 0.7404, Validation Accuracy: 0.7770, Loss: 0.3750
Epoch   6 Batch  182/269 - Train Accuracy: 0.7767, Validation Accuracy: 0.7722, Loss: 0.3666
Epoch   6 Batch  183/269 - Train Accuracy: 0.8135, Validation Accuracy: 0.7718, Loss: 0.3168
Epoch   6 Batch  184/269 - Train Accuracy: 0.7513, Validation Accuracy: 0.7706, Loss: 0.3719
Epoch   6 Batch  185/269 - Train Accuracy: 0.7762, Validation Accuracy: 0.7757, Loss: 0.3651
Epoch   6 Batch  186/269 - Train Accuracy: 0.7615, Validation Accuracy: 0.7700, Loss: 0.3680
Epoch   6 Batch  187/269 - Train Accuracy: 0.7764, Validation Accuracy: 0.7725, Loss: 0.3555
Epoch   6 Batch  188/269 - Train Accuracy: 0.7797, Validation Accuracy: 0.7731, Loss: 0.3462
Epoch   6 Batch  189/269 - Train Accuracy: 0.7742, Validation Accuracy: 0.7735, Loss: 0.3485
Epoch   6 Batch  190/269 - Train Accuracy: 0.7612, Validation Accuracy: 0.7740, Loss: 0.3448
Epoch   6 Batch  191/269 - Train Accuracy: 0.7560, Validation Accuracy: 0.7721, Loss: 0.3529
Epoch   6 Batch  192/269 - Train Accuracy: 0.7708, Validation Accuracy: 0.7732, Loss: 0.3613
Epoch   6 Batch  193/269 - Train Accuracy: 0.7905, Validation Accuracy: 0.7857, Loss: 0.3518
Epoch   6 Batch  194/269 - Train Accuracy: 0.7658, Validation Accuracy: 0.7815, Loss: 0.3585
Epoch   6 Batch  195/269 - Train Accuracy: 0.7682, Validation Accuracy: 0.7742, Loss: 0.3640
Epoch   6 Batch  196/269 - Train Accuracy: 0.7526, Validation Accuracy: 0.7763, Loss: 0.3518
Epoch   6 Batch  197/269 - Train Accuracy: 0.7505, Validation Accuracy: 0.7638, Loss: 0.3812
Epoch   6 Batch  198/269 - Train Accuracy: 0.7396, Validation Accuracy: 0.7710, Loss: 0.3922
Epoch   6 Batch  199/269 - Train Accuracy: 0.7630, Validation Accuracy: 0.7771, Loss: 0.3851
Epoch   6 Batch  200/269 - Train Accuracy: 0.7654, Validation Accuracy: 0.7731, Loss: 0.3704
Epoch   6 Batch  201/269 - Train Accuracy: 0.7718, Validation Accuracy: 0.7703, Loss: 0.3655
Epoch   6 Batch  202/269 - Train Accuracy: 0.7547, Validation Accuracy: 0.7706, Loss: 0.3618
Epoch   6 Batch  203/269 - Train Accuracy: 0.7691, Validation Accuracy: 0.7754, Loss: 0.3848
Epoch   6 Batch  204/269 - Train Accuracy: 0.7551, Validation Accuracy: 0.7617, Loss: 0.3823
Epoch   6 Batch  205/269 - Train Accuracy: 0.7659, Validation Accuracy: 0.7785, Loss: 0.3537
Epoch   6 Batch  206/269 - Train Accuracy: 0.7612, Validation Accuracy: 0.7621, Loss: 0.3782
Epoch   6 Batch  207/269 - Train Accuracy: 0.7730, Validation Accuracy: 0.7782, Loss: 0.3565
Epoch   6 Batch  208/269 - Train Accuracy: 0.7718, Validation Accuracy: 0.7814, Loss: 0.3662
Epoch   6 Batch  209/269 - Train Accuracy: 0.7768, Validation Accuracy: 0.7716, Loss: 0.3586
Epoch   6 Batch  210/269 - Train Accuracy: 0.7655, Validation Accuracy: 0.7756, Loss: 0.3537
Epoch   6 Batch  211/269 - Train Accuracy: 0.7679, Validation Accuracy: 0.7805, Loss: 0.3603
Epoch   6 Batch  212/269 - Train Accuracy: 0.7773, Validation Accuracy: 0.7795, Loss: 0.3581
Epoch   6 Batch  213/269 - Train Accuracy: 0.7755, Validation Accuracy: 0.7778, Loss: 0.3573
Epoch   6 Batch  214/269 - Train Accuracy: 0.7603, Validation Accuracy: 0.7776, Loss: 0.3652
Epoch   6 Batch  215/269 - Train Accuracy: 0.7891, Validation Accuracy: 0.7741, Loss: 0.3350
Epoch   6 Batch  216/269 - Train Accuracy: 0.7597, Validation Accuracy: 0.7822, Loss: 0.3901
Epoch   6 Batch  217/269 - Train Accuracy: 0.7655, Validation Accuracy: 0.7822, Loss: 0.3673
Epoch   6 Batch  218/269 - Train Accuracy: 0.7818, Validation Accuracy: 0.7781, Loss: 0.3718
Epoch   6 Batch  219/269 - Train Accuracy: 0.7688, Validation Accuracy: 0.7790, Loss: 0.3672
Epoch   6 Batch  220/269 - Train Accuracy: 0.7991, Validation Accuracy: 0.7804, Loss: 0.3400
Epoch   6 Batch  221/269 - Train Accuracy: 0.8016, Validation Accuracy: 0.7764, Loss: 0.3599
Epoch   6 Batch  222/269 - Train Accuracy: 0.8024, Validation Accuracy: 0.7737, Loss: 0.3388
Epoch   6 Batch  223/269 - Train Accuracy: 0.7897, Validation Accuracy: 0.7763, Loss: 0.3481
Epoch   6 Batch  224/269 - Train Accuracy: 0.7692, Validation Accuracy: 0.7682, Loss: 0.3611
Epoch   6 Batch  225/269 - Train Accuracy: 0.7604, Validation Accuracy: 0.7592, Loss: 0.3638
Epoch   6 Batch  226/269 - Train Accuracy: 0.7811, Validation Accuracy: 0.7796, Loss: 0.3651
Epoch   6 Batch  227/269 - Train Accuracy: 0.8004, Validation Accuracy: 0.7725, Loss: 0.3350
Epoch   6 Batch  228/269 - Train Accuracy: 0.7499, Validation Accuracy: 0.7505, Loss: 0.3615
Epoch   6 Batch  229/269 - Train Accuracy: 0.7681, Validation Accuracy: 0.7644, Loss: 0.3664
Epoch   6 Batch  230/269 - Train Accuracy: 0.7580, Validation Accuracy: 0.7720, Loss: 0.3484
Epoch   6 Batch  231/269 - Train Accuracy: 0.7530, Validation Accuracy: 0.7665, Loss: 0.3743
Epoch   6 Batch  232/269 - Train Accuracy: 0.7476, Validation Accuracy: 0.7733, Loss: 0.3840
Epoch   6 Batch  233/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.7739, Loss: 0.3624
Epoch   6 Batch  234/269 - Train Accuracy: 0.7694, Validation Accuracy: 0.7757, Loss: 0.3559
Epoch   6 Batch  235/269 - Train Accuracy: 0.7769, Validation Accuracy: 0.7724, Loss: 0.3476
Epoch   6 Batch  236/269 - Train Accuracy: 0.7652, Validation Accuracy: 0.7697, Loss: 0.3495
Epoch   6 Batch  237/269 - Train Accuracy: 0.7826, Validation Accuracy: 0.7815, Loss: 0.3605
Epoch   6 Batch  238/269 - Train Accuracy: 0.7710, Validation Accuracy: 0.7708, Loss: 0.3512
Epoch   6 Batch  239/269 - Train Accuracy: 0.7846, Validation Accuracy: 0.7833, Loss: 0.3624
Epoch   6 Batch  240/269 - Train Accuracy: 0.7897, Validation Accuracy: 0.7785, Loss: 0.3237
Epoch   6 Batch  241/269 - Train Accuracy: 0.7842, Validation Accuracy: 0.7797, Loss: 0.3658
Epoch   6 Batch  242/269 - Train Accuracy: 0.7717, Validation Accuracy: 0.7700, Loss: 0.3402
Epoch   6 Batch  243/269 - Train Accuracy: 0.7869, Validation Accuracy: 0.7846, Loss: 0.3376
Epoch   6 Batch  244/269 - Train Accuracy: 0.7637, Validation Accuracy: 0.7828, Loss: 0.3530
Epoch   6 Batch  245/269 - Train Accuracy: 0.7521, Validation Accuracy: 0.7705, Loss: 0.3766
Epoch   6 Batch  246/269 - Train Accuracy: 0.7635, Validation Accuracy: 0.7727, Loss: 0.3562
Epoch   6 Batch  247/269 - Train Accuracy: 0.7639, Validation Accuracy: 0.7739, Loss: 0.3613
Epoch   6 Batch  248/269 - Train Accuracy: 0.7830, Validation Accuracy: 0.7747, Loss: 0.3405
Epoch   6 Batch  249/269 - Train Accuracy: 0.8038, Validation Accuracy: 0.7808, Loss: 0.3271
Epoch   6 Batch  250/269 - Train Accuracy: 0.7602, Validation Accuracy: 0.7769, Loss: 0.3504
Epoch   6 Batch  251/269 - Train Accuracy: 0.7992, Validation Accuracy: 0.7801, Loss: 0.3403
Epoch   6 Batch  252/269 - Train Accuracy: 0.7575, Validation Accuracy: 0.7766, Loss: 0.3527
Epoch   6 Batch  253/269 - Train Accuracy: 0.7680, Validation Accuracy: 0.7852, Loss: 0.3641
Epoch   6 Batch  254/269 - Train Accuracy: 0.7904, Validation Accuracy: 0.7828, Loss: 0.3478
Epoch   6 Batch  255/269 - Train Accuracy: 0.7793, Validation Accuracy: 0.7767, Loss: 0.3435
Epoch   6 Batch  256/269 - Train Accuracy: 0.7677, Validation Accuracy: 0.7797, Loss: 0.3534
Epoch   6 Batch  257/269 - Train Accuracy: 0.7888, Validation Accuracy: 0.7818, Loss: 0.3489
Epoch   6 Batch  258/269 - Train Accuracy: 0.7873, Validation Accuracy: 0.7778, Loss: 0.3553
Epoch   6 Batch  259/269 - Train Accuracy: 0.7840, Validation Accuracy: 0.7834, Loss: 0.3490
Epoch   6 Batch  260/269 - Train Accuracy: 0.7648, Validation Accuracy: 0.7866, Loss: 0.3687
Epoch   6 Batch  261/269 - Train Accuracy: 0.7884, Validation Accuracy: 0.7894, Loss: 0.3650
Epoch   6 Batch  262/269 - Train Accuracy: 0.7809, Validation Accuracy: 0.7952, Loss: 0.3439
Epoch   6 Batch  263/269 - Train Accuracy: 0.7652, Validation Accuracy: 0.7888, Loss: 0.3571
Epoch   6 Batch  264/269 - Train Accuracy: 0.7671, Validation Accuracy: 0.7872, Loss: 0.3631
Epoch   6 Batch  265/269 - Train Accuracy: 0.7856, Validation Accuracy: 0.7866, Loss: 0.3493
Epoch   6 Batch  266/269 - Train Accuracy: 0.7800, Validation Accuracy: 0.7883, Loss: 0.3385
Epoch   6 Batch  267/269 - Train Accuracy: 0.7692, Validation Accuracy: 0.7825, Loss: 0.3569
Epoch   7 Batch    1/269 - Train Accuracy: 0.7770, Validation Accuracy: 0.7754, Loss: 0.3528
Epoch   7 Batch    2/269 - Train Accuracy: 0.7717, Validation Accuracy: 0.7856, Loss: 0.3498
Epoch   7 Batch    3/269 - Train Accuracy: 0.7872, Validation Accuracy: 0.7778, Loss: 0.3557
Epoch   7 Batch    4/269 - Train Accuracy: 0.7424, Validation Accuracy: 0.7741, Loss: 0.3639
Epoch   7 Batch    5/269 - Train Accuracy: 0.7491, Validation Accuracy: 0.7893, Loss: 0.3612
Epoch   7 Batch    6/269 - Train Accuracy: 0.7917, Validation Accuracy: 0.7781, Loss: 0.3312
Epoch   7 Batch    7/269 - Train Accuracy: 0.7839, Validation Accuracy: 0.7769, Loss: 0.3456
Epoch   7 Batch    8/269 - Train Accuracy: 0.7734, Validation Accuracy: 0.7841, Loss: 0.3618
Epoch   7 Batch    9/269 - Train Accuracy: 0.7621, Validation Accuracy: 0.7701, Loss: 0.3566
Epoch   7 Batch   10/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7844, Loss: 0.3537
Epoch   7 Batch   11/269 - Train Accuracy: 0.7825, Validation Accuracy: 0.7890, Loss: 0.3527
Epoch   7 Batch   12/269 - Train Accuracy: 0.7825, Validation Accuracy: 0.7834, Loss: 0.3625
Epoch   7 Batch   13/269 - Train Accuracy: 0.7886, Validation Accuracy: 0.7881, Loss: 0.3173
Epoch   7 Batch   14/269 - Train Accuracy: 0.7601, Validation Accuracy: 0.7645, Loss: 0.3412
Epoch   7 Batch   15/269 - Train Accuracy: 0.7795, Validation Accuracy: 0.7884, Loss: 0.3394
Epoch   7 Batch   16/269 - Train Accuracy: 0.7731, Validation Accuracy: 0.7820, Loss: 0.3515
Epoch   7 Batch   17/269 - Train Accuracy: 0.7901, Validation Accuracy: 0.7830, Loss: 0.3368
Epoch   7 Batch   18/269 - Train Accuracy: 0.7684, Validation Accuracy: 0.7820, Loss: 0.3539
Epoch   7 Batch   19/269 - Train Accuracy: 0.8056, Validation Accuracy: 0.7833, Loss: 0.3173
Epoch   7 Batch   20/269 - Train Accuracy: 0.7793, Validation Accuracy: 0.7834, Loss: 0.3471
Epoch   7 Batch   21/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.7908, Loss: 0.3660
Epoch   7 Batch   22/269 - Train Accuracy: 0.7967, Validation Accuracy: 0.7858, Loss: 0.3309
Epoch   7 Batch   23/269 - Train Accuracy: 0.7750, Validation Accuracy: 0.7798, Loss: 0.3312
Epoch   7 Batch   24/269 - Train Accuracy: 0.7783, Validation Accuracy: 0.7907, Loss: 0.3486
Epoch   7 Batch   25/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7888, Loss: 0.3614
Epoch   7 Batch   26/269 - Train Accuracy: 0.7892, Validation Accuracy: 0.7786, Loss: 0.3131
Epoch   7 Batch   27/269 - Train Accuracy: 0.7793, Validation Accuracy: 0.7728, Loss: 0.3308
Epoch   7 Batch   28/269 - Train Accuracy: 0.7406, Validation Accuracy: 0.7887, Loss: 0.3704
Epoch   7 Batch   29/269 - Train Accuracy: 0.8040, Validation Accuracy: 0.7819, Loss: 0.3531
Epoch   7 Batch   30/269 - Train Accuracy: 0.7768, Validation Accuracy: 0.7764, Loss: 0.3320
Epoch   7 Batch   31/269 - Train Accuracy: 0.7766, Validation Accuracy: 0.7773, Loss: 0.3260
Epoch   7 Batch   32/269 - Train Accuracy: 0.7731, Validation Accuracy: 0.7766, Loss: 0.3416
Epoch   7 Batch   33/269 - Train Accuracy: 0.7992, Validation Accuracy: 0.7882, Loss: 0.3274
Epoch   7 Batch   34/269 - Train Accuracy: 0.7820, Validation Accuracy: 0.7829, Loss: 0.3352
Epoch   7 Batch   35/269 - Train Accuracy: 0.7767, Validation Accuracy: 0.7694, Loss: 0.3559
Epoch   7 Batch   36/269 - Train Accuracy: 0.7733, Validation Accuracy: 0.7947, Loss: 0.3440
Epoch   7 Batch   37/269 - Train Accuracy: 0.7801, Validation Accuracy: 0.7813, Loss: 0.3348
Epoch   7 Batch   38/269 - Train Accuracy: 0.7793, Validation Accuracy: 0.7788, Loss: 0.3453
Epoch   7 Batch   39/269 - Train Accuracy: 0.7744, Validation Accuracy: 0.7765, Loss: 0.3384
Epoch   7 Batch   40/269 - Train Accuracy: 0.7591, Validation Accuracy: 0.7821, Loss: 0.3566
Epoch   7 Batch   41/269 - Train Accuracy: 0.7741, Validation Accuracy: 0.7923, Loss: 0.3554
Epoch   7 Batch   42/269 - Train Accuracy: 0.7970, Validation Accuracy: 0.7862, Loss: 0.3201
Epoch   7 Batch   43/269 - Train Accuracy: 0.7664, Validation Accuracy: 0.7836, Loss: 0.3532
Epoch   7 Batch   44/269 - Train Accuracy: 0.7846, Validation Accuracy: 0.7837, Loss: 0.3331
Epoch   7 Batch   45/269 - Train Accuracy: 0.7716, Validation Accuracy: 0.7730, Loss: 0.3531
Epoch   7 Batch   46/269 - Train Accuracy: 0.7733, Validation Accuracy: 0.7874, Loss: 0.3500
Epoch   7 Batch   47/269 - Train Accuracy: 0.7919, Validation Accuracy: 0.7828, Loss: 0.3097
Epoch   7 Batch   48/269 - Train Accuracy: 0.7990, Validation Accuracy: 0.7820, Loss: 0.3324
Epoch   7 Batch   49/269 - Train Accuracy: 0.7569, Validation Accuracy: 0.7664, Loss: 0.3372
Epoch   7 Batch   50/269 - Train Accuracy: 0.7707, Validation Accuracy: 0.7939, Loss: 0.3599
Epoch   7 Batch   51/269 - Train Accuracy: 0.7779, Validation Accuracy: 0.7941, Loss: 0.3323
Epoch   7 Batch   52/269 - Train Accuracy: 0.7717, Validation Accuracy: 0.7983, Loss: 0.3141
Epoch   7 Batch   53/269 - Train Accuracy: 0.7786, Validation Accuracy: 0.7827, Loss: 0.3501
Epoch   7 Batch   54/269 - Train Accuracy: 0.7953, Validation Accuracy: 0.7907, Loss: 0.3429
Epoch   7 Batch   55/269 - Train Accuracy: 0.7848, Validation Accuracy: 0.7882, Loss: 0.3221
Epoch   7 Batch   56/269 - Train Accuracy: 0.7723, Validation Accuracy: 0.7878, Loss: 0.3356
Epoch   7 Batch   57/269 - Train Accuracy: 0.7966, Validation Accuracy: 0.7992, Loss: 0.3494
Epoch   7 Batch   58/269 - Train Accuracy: 0.7833, Validation Accuracy: 0.7815, Loss: 0.3220
Epoch   7 Batch   59/269 - Train Accuracy: 0.8036, Validation Accuracy: 0.7805, Loss: 0.3086
Epoch   7 Batch   60/269 - Train Accuracy: 0.7910, Validation Accuracy: 0.7895, Loss: 0.3205
Epoch   7 Batch   61/269 - Train Accuracy: 0.7957, Validation Accuracy: 0.7906, Loss: 0.3117
Epoch   7 Batch   62/269 - Train Accuracy: 0.7971, Validation Accuracy: 0.7954, Loss: 0.3232
Epoch   7 Batch   63/269 - Train Accuracy: 0.7786, Validation Accuracy: 0.7872, Loss: 0.3362
Epoch   7 Batch   64/269 - Train Accuracy: 0.7859, Validation Accuracy: 0.8017, Loss: 0.3162
Epoch   7 Batch   65/269 - Train Accuracy: 0.7792, Validation Accuracy: 0.7983, Loss: 0.3270
Epoch   7 Batch   66/269 - Train Accuracy: 0.7887, Validation Accuracy: 0.8023, Loss: 0.3216
Epoch   7 Batch   67/269 - Train Accuracy: 0.7932, Validation Accuracy: 0.8024, Loss: 0.3408
Epoch   7 Batch   68/269 - Train Accuracy: 0.7818, Validation Accuracy: 0.8003, Loss: 0.3408
Epoch   7 Batch   69/269 - Train Accuracy: 0.7667, Validation Accuracy: 0.7922, Loss: 0.3678
Epoch   7 Batch   70/269 - Train Accuracy: 0.8113, Validation Accuracy: 0.7932, Loss: 0.3328
Epoch   7 Batch   71/269 - Train Accuracy: 0.7757, Validation Accuracy: 0.7902, Loss: 0.3465
Epoch   7 Batch   72/269 - Train Accuracy: 0.7831, Validation Accuracy: 0.7983, Loss: 0.3294
Epoch   7 Batch   73/269 - Train Accuracy: 0.7813, Validation Accuracy: 0.7944, Loss: 0.3401
Epoch   7 Batch   74/269 - Train Accuracy: 0.7954, Validation Accuracy: 0.7997, Loss: 0.3288
Epoch   7 Batch   75/269 - Train Accuracy: 0.8012, Validation Accuracy: 0.7961, Loss: 0.3231
Epoch   7 Batch   76/269 - Train Accuracy: 0.7867, Validation Accuracy: 0.7968, Loss: 0.3361
Epoch   7 Batch   77/269 - Train Accuracy: 0.7903, Validation Accuracy: 0.7902, Loss: 0.3245
Epoch   7 Batch   78/269 - Train Accuracy: 0.8031, Validation Accuracy: 0.7931, Loss: 0.3252
Epoch   7 Batch   79/269 - Train Accuracy: 0.7799, Validation Accuracy: 0.7914, Loss: 0.3229
Epoch   7 Batch   80/269 - Train Accuracy: 0.8072, Validation Accuracy: 0.7904, Loss: 0.3259
Epoch   7 Batch   81/269 - Train Accuracy: 0.7904, Validation Accuracy: 0.7970, Loss: 0.3503
Epoch   7 Batch   82/269 - Train Accuracy: 0.8125, Validation Accuracy: 0.7965, Loss: 0.3098
Epoch   7 Batch   83/269 - Train Accuracy: 0.7764, Validation Accuracy: 0.7967, Loss: 0.3360
Epoch   7 Batch   84/269 - Train Accuracy: 0.7997, Validation Accuracy: 0.7932, Loss: 0.3225
Epoch   7 Batch   85/269 - Train Accuracy: 0.8031, Validation Accuracy: 0.7899, Loss: 0.3277
Epoch   7 Batch   86/269 - Train Accuracy: 0.7919, Validation Accuracy: 0.7936, Loss: 0.3302
Epoch   7 Batch   87/269 - Train Accuracy: 0.7761, Validation Accuracy: 0.7980, Loss: 0.3561
Epoch   7 Batch   88/269 - Train Accuracy: 0.7824, Validation Accuracy: 0.7951, Loss: 0.3383
Epoch   7 Batch   89/269 - Train Accuracy: 0.7869, Validation Accuracy: 0.7811, Loss: 0.3326
Epoch   7 Batch   90/269 - Train Accuracy: 0.7793, Validation Accuracy: 0.7955, Loss: 0.3481
Epoch   7 Batch   91/269 - Train Accuracy: 0.8043, Validation Accuracy: 0.7891, Loss: 0.3132
Epoch   7 Batch   92/269 - Train Accuracy: 0.8039, Validation Accuracy: 0.7985, Loss: 0.3238
Epoch   7 Batch   93/269 - Train Accuracy: 0.7969, Validation Accuracy: 0.7927, Loss: 0.3151
Epoch   7 Batch   94/269 - Train Accuracy: 0.7835, Validation Accuracy: 0.7978, Loss: 0.3412
Epoch   7 Batch   95/269 - Train Accuracy: 0.7996, Validation Accuracy: 0.8016, Loss: 0.3239
Epoch   7 Batch   96/269 - Train Accuracy: 0.7773, Validation Accuracy: 0.7917, Loss: 0.3197
Epoch   7 Batch   97/269 - Train Accuracy: 0.8052, Validation Accuracy: 0.7993, Loss: 0.3268
Epoch   7 Batch   98/269 - Train Accuracy: 0.8005, Validation Accuracy: 0.7966, Loss: 0.3242
Epoch   7 Batch   99/269 - Train Accuracy: 0.7650, Validation Accuracy: 0.8016, Loss: 0.3343
Epoch   7 Batch  100/269 - Train Accuracy: 0.8178, Validation Accuracy: 0.8028, Loss: 0.3260
Epoch   7 Batch  101/269 - Train Accuracy: 0.7739, Validation Accuracy: 0.7918, Loss: 0.3497
Epoch   7 Batch  102/269 - Train Accuracy: 0.7745, Validation Accuracy: 0.7919, Loss: 0.3232
Epoch   7 Batch  103/269 - Train Accuracy: 0.8065, Validation Accuracy: 0.7973, Loss: 0.3313
Epoch   7 Batch  104/269 - Train Accuracy: 0.7879, Validation Accuracy: 0.7843, Loss: 0.3167
Epoch   7 Batch  105/269 - Train Accuracy: 0.7938, Validation Accuracy: 0.8013, Loss: 0.3292
Epoch   7 Batch  106/269 - Train Accuracy: 0.7928, Validation Accuracy: 0.7926, Loss: 0.3161
Epoch   7 Batch  107/269 - Train Accuracy: 0.7808, Validation Accuracy: 0.7947, Loss: 0.3403
Epoch   7 Batch  108/269 - Train Accuracy: 0.7978, Validation Accuracy: 0.7952, Loss: 0.3225
Epoch   7 Batch  109/269 - Train Accuracy: 0.7746, Validation Accuracy: 0.8067, Loss: 0.3289
Epoch   7 Batch  110/269 - Train Accuracy: 0.7960, Validation Accuracy: 0.8094, Loss: 0.3214
Epoch   7 Batch  111/269 - Train Accuracy: 0.7847, Validation Accuracy: 0.7951, Loss: 0.3508
Epoch   7 Batch  112/269 - Train Accuracy: 0.7839, Validation Accuracy: 0.7884, Loss: 0.3161
Epoch   7 Batch  113/269 - Train Accuracy: 0.7970, Validation Accuracy: 0.8034, Loss: 0.3128
Epoch   7 Batch  114/269 - Train Accuracy: 0.8087, Validation Accuracy: 0.8076, Loss: 0.3198
Epoch   7 Batch  115/269 - Train Accuracy: 0.7767, Validation Accuracy: 0.8086, Loss: 0.3437
Epoch   7 Batch  116/269 - Train Accuracy: 0.8078, Validation Accuracy: 0.8011, Loss: 0.3323
Epoch   7 Batch  117/269 - Train Accuracy: 0.7818, Validation Accuracy: 0.7978, Loss: 0.3166
Epoch   7 Batch  118/269 - Train Accuracy: 0.8006, Validation Accuracy: 0.8000, Loss: 0.3095
Epoch   7 Batch  119/269 - Train Accuracy: 0.7898, Validation Accuracy: 0.7992, Loss: 0.3304
Epoch   7 Batch  120/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.8058, Loss: 0.3341
Epoch   7 Batch  121/269 - Train Accuracy: 0.7883, Validation Accuracy: 0.8046, Loss: 0.3123
Epoch   7 Batch  122/269 - Train Accuracy: 0.7902, Validation Accuracy: 0.7995, Loss: 0.3138
Epoch   7 Batch  123/269 - Train Accuracy: 0.7932, Validation Accuracy: 0.7861, Loss: 0.3341
Epoch   7 Batch  124/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7952, Loss: 0.3095
Epoch   7 Batch  125/269 - Train Accuracy: 0.7959, Validation Accuracy: 0.7822, Loss: 0.3067
Epoch   7 Batch  126/269 - Train Accuracy: 0.7917, Validation Accuracy: 0.7877, Loss: 0.3219
Epoch   7 Batch  127/269 - Train Accuracy: 0.7914, Validation Accuracy: 0.7917, Loss: 0.3279
Epoch   7 Batch  128/269 - Train Accuracy: 0.7877, Validation Accuracy: 0.7974, Loss: 0.3204
Epoch   7 Batch  129/269 - Train Accuracy: 0.7999, Validation Accuracy: 0.8026, Loss: 0.3170
Epoch   7 Batch  130/269 - Train Accuracy: 0.7763, Validation Accuracy: 0.7877, Loss: 0.3327
Epoch   7 Batch  131/269 - Train Accuracy: 0.7826, Validation Accuracy: 0.7963, Loss: 0.3287
Epoch   7 Batch  132/269 - Train Accuracy: 0.7790, Validation Accuracy: 0.8089, Loss: 0.3280
Epoch   7 Batch  133/269 - Train Accuracy: 0.8079, Validation Accuracy: 0.7984, Loss: 0.3081
Epoch   7 Batch  134/269 - Train Accuracy: 0.7742, Validation Accuracy: 0.8009, Loss: 0.3213
Epoch   7 Batch  135/269 - Train Accuracy: 0.7881, Validation Accuracy: 0.8023, Loss: 0.3399
Epoch   7 Batch  136/269 - Train Accuracy: 0.7918, Validation Accuracy: 0.8059, Loss: 0.3305
Epoch   7 Batch  137/269 - Train Accuracy: 0.7765, Validation Accuracy: 0.8053, Loss: 0.3311
Epoch   7 Batch  138/269 - Train Accuracy: 0.8038, Validation Accuracy: 0.7985, Loss: 0.3156
Epoch   7 Batch  139/269 - Train Accuracy: 0.8056, Validation Accuracy: 0.8066, Loss: 0.3045
Epoch   7 Batch  140/269 - Train Accuracy: 0.8073, Validation Accuracy: 0.8088, Loss: 0.3252
Epoch   7 Batch  141/269 - Train Accuracy: 0.8003, Validation Accuracy: 0.8096, Loss: 0.3234
Epoch   7 Batch  142/269 - Train Accuracy: 0.8057, Validation Accuracy: 0.8101, Loss: 0.3016
Epoch   7 Batch  143/269 - Train Accuracy: 0.8051, Validation Accuracy: 0.8092, Loss: 0.3160
Epoch   7 Batch  144/269 - Train Accuracy: 0.8013, Validation Accuracy: 0.8081, Loss: 0.3020
Epoch   7 Batch  145/269 - Train Accuracy: 0.8051, Validation Accuracy: 0.8079, Loss: 0.3127
Epoch   7 Batch  146/269 - Train Accuracy: 0.8093, Validation Accuracy: 0.8041, Loss: 0.3065
Epoch   7 Batch  147/269 - Train Accuracy: 0.8165, Validation Accuracy: 0.8049, Loss: 0.3010
Epoch   7 Batch  148/269 - Train Accuracy: 0.7941, Validation Accuracy: 0.8060, Loss: 0.3135
Epoch   7 Batch  149/269 - Train Accuracy: 0.7782, Validation Accuracy: 0.8089, Loss: 0.3171
Epoch   7 Batch  150/269 - Train Accuracy: 0.7954, Validation Accuracy: 0.8108, Loss: 0.3113
Epoch   7 Batch  151/269 - Train Accuracy: 0.8082, Validation Accuracy: 0.8135, Loss: 0.3053
Epoch   7 Batch  152/269 - Train Accuracy: 0.7985, Validation Accuracy: 0.8085, Loss: 0.3096
Epoch   7 Batch  153/269 - Train Accuracy: 0.8060, Validation Accuracy: 0.8039, Loss: 0.3005
Epoch   7 Batch  154/269 - Train Accuracy: 0.8018, Validation Accuracy: 0.8089, Loss: 0.3195
Epoch   7 Batch  155/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8079, Loss: 0.2999
Epoch   7 Batch  156/269 - Train Accuracy: 0.7854, Validation Accuracy: 0.8089, Loss: 0.3194
Epoch   7 Batch  157/269 - Train Accuracy: 0.8074, Validation Accuracy: 0.8119, Loss: 0.3025
Epoch   7 Batch  158/269 - Train Accuracy: 0.7998, Validation Accuracy: 0.8098, Loss: 0.3095
Epoch   7 Batch  159/269 - Train Accuracy: 0.7844, Validation Accuracy: 0.8143, Loss: 0.3072
Epoch   7 Batch  160/269 - Train Accuracy: 0.8083, Validation Accuracy: 0.8139, Loss: 0.3063
Epoch   7 Batch  161/269 - Train Accuracy: 0.8022, Validation Accuracy: 0.8127, Loss: 0.3142
Epoch   7 Batch  162/269 - Train Accuracy: 0.8155, Validation Accuracy: 0.8118, Loss: 0.2957
Epoch   7 Batch  163/269 - Train Accuracy: 0.8144, Validation Accuracy: 0.8000, Loss: 0.3074
Epoch   7 Batch  164/269 - Train Accuracy: 0.8167, Validation Accuracy: 0.8070, Loss: 0.3078
Epoch   7 Batch  165/269 - Train Accuracy: 0.8044, Validation Accuracy: 0.8047, Loss: 0.3157
Epoch   7 Batch  166/269 - Train Accuracy: 0.8126, Validation Accuracy: 0.8111, Loss: 0.2981
Epoch   7 Batch  167/269 - Train Accuracy: 0.8134, Validation Accuracy: 0.8050, Loss: 0.3069
Epoch   7 Batch  168/269 - Train Accuracy: 0.7973, Validation Accuracy: 0.8112, Loss: 0.3221
Epoch   7 Batch  169/269 - Train Accuracy: 0.7951, Validation Accuracy: 0.8096, Loss: 0.3145
Epoch   7 Batch  170/269 - Train Accuracy: 0.8090, Validation Accuracy: 0.8088, Loss: 0.3051
Epoch   7 Batch  171/269 - Train Accuracy: 0.8185, Validation Accuracy: 0.8113, Loss: 0.3119
Epoch   7 Batch  172/269 - Train Accuracy: 0.7955, Validation Accuracy: 0.8061, Loss: 0.3179
Epoch   7 Batch  173/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8081, Loss: 0.2954
Epoch   7 Batch  174/269 - Train Accuracy: 0.8111, Validation Accuracy: 0.8050, Loss: 0.3087
Epoch   7 Batch  175/269 - Train Accuracy: 0.8001, Validation Accuracy: 0.8124, Loss: 0.3275
Epoch   7 Batch  176/269 - Train Accuracy: 0.7871, Validation Accuracy: 0.8091, Loss: 0.3198
Epoch   7 Batch  177/269 - Train Accuracy: 0.8059, Validation Accuracy: 0.8050, Loss: 0.2918
Epoch   7 Batch  178/269 - Train Accuracy: 0.8144, Validation Accuracy: 0.8132, Loss: 0.3095
Epoch   7 Batch  179/269 - Train Accuracy: 0.7964, Validation Accuracy: 0.8061, Loss: 0.3076
Epoch   7 Batch  180/269 - Train Accuracy: 0.8196, Validation Accuracy: 0.8067, Loss: 0.3022
Epoch   7 Batch  181/269 - Train Accuracy: 0.7871, Validation Accuracy: 0.8155, Loss: 0.3074
Epoch   7 Batch  182/269 - Train Accuracy: 0.8084, Validation Accuracy: 0.8110, Loss: 0.3086
Epoch   7 Batch  183/269 - Train Accuracy: 0.8359, Validation Accuracy: 0.8137, Loss: 0.2678
Epoch   7 Batch  184/269 - Train Accuracy: 0.7978, Validation Accuracy: 0.8135, Loss: 0.3122
Epoch   7 Batch  185/269 - Train Accuracy: 0.8140, Validation Accuracy: 0.8119, Loss: 0.3004
Epoch   7 Batch  186/269 - Train Accuracy: 0.8111, Validation Accuracy: 0.8145, Loss: 0.3063
Epoch   7 Batch  187/269 - Train Accuracy: 0.8063, Validation Accuracy: 0.8129, Loss: 0.2941
Epoch   7 Batch  188/269 - Train Accuracy: 0.8252, Validation Accuracy: 0.8205, Loss: 0.2930
Epoch   7 Batch  189/269 - Train Accuracy: 0.8162, Validation Accuracy: 0.8132, Loss: 0.2924
Epoch   7 Batch  190/269 - Train Accuracy: 0.8037, Validation Accuracy: 0.8106, Loss: 0.2905
Epoch   7 Batch  191/269 - Train Accuracy: 0.8008, Validation Accuracy: 0.8111, Loss: 0.2951
Epoch   7 Batch  192/269 - Train Accuracy: 0.8131, Validation Accuracy: 0.8158, Loss: 0.3041
Epoch   7 Batch  193/269 - Train Accuracy: 0.8248, Validation Accuracy: 0.8140, Loss: 0.2958
Epoch   7 Batch  194/269 - Train Accuracy: 0.8053, Validation Accuracy: 0.8174, Loss: 0.3023
Epoch   7 Batch  195/269 - Train Accuracy: 0.8175, Validation Accuracy: 0.8116, Loss: 0.3039
Epoch   7 Batch  196/269 - Train Accuracy: 0.8096, Validation Accuracy: 0.8094, Loss: 0.2883
Epoch   7 Batch  197/269 - Train Accuracy: 0.7986, Validation Accuracy: 0.8112, Loss: 0.3179
Epoch   7 Batch  198/269 - Train Accuracy: 0.7915, Validation Accuracy: 0.8106, Loss: 0.3193
Epoch   7 Batch  199/269 - Train Accuracy: 0.8050, Validation Accuracy: 0.8123, Loss: 0.3130
Epoch   7 Batch  200/269 - Train Accuracy: 0.8076, Validation Accuracy: 0.8112, Loss: 0.3092
Epoch   7 Batch  201/269 - Train Accuracy: 0.8169, Validation Accuracy: 0.8067, Loss: 0.3005
Epoch   7 Batch  202/269 - Train Accuracy: 0.7869, Validation Accuracy: 0.7966, Loss: 0.3046
Epoch   7 Batch  203/269 - Train Accuracy: 0.7956, Validation Accuracy: 0.7980, Loss: 0.3336
Epoch   7 Batch  204/269 - Train Accuracy: 0.7971, Validation Accuracy: 0.8065, Loss: 0.3263
Epoch   7 Batch  205/269 - Train Accuracy: 0.8015, Validation Accuracy: 0.7947, Loss: 0.3013
Epoch   7 Batch  206/269 - Train Accuracy: 0.7925, Validation Accuracy: 0.8008, Loss: 0.3191
Epoch   7 Batch  207/269 - Train Accuracy: 0.7980, Validation Accuracy: 0.7879, Loss: 0.3010
Epoch   7 Batch  208/269 - Train Accuracy: 0.8159, Validation Accuracy: 0.8031, Loss: 0.3168
Epoch   7 Batch  209/269 - Train Accuracy: 0.8261, Validation Accuracy: 0.8084, Loss: 0.2986
Epoch   7 Batch  210/269 - Train Accuracy: 0.8107, Validation Accuracy: 0.8031, Loss: 0.2932
Epoch   7 Batch  211/269 - Train Accuracy: 0.8026, Validation Accuracy: 0.8035, Loss: 0.3076
Epoch   7 Batch  212/269 - Train Accuracy: 0.8111, Validation Accuracy: 0.8124, Loss: 0.2990
Epoch   7 Batch  213/269 - Train Accuracy: 0.8061, Validation Accuracy: 0.8079, Loss: 0.2999
Epoch   7 Batch  214/269 - Train Accuracy: 0.7977, Validation Accuracy: 0.8092, Loss: 0.3078
Epoch   7 Batch  215/269 - Train Accuracy: 0.8247, Validation Accuracy: 0.8049, Loss: 0.2725
Epoch   7 Batch  216/269 - Train Accuracy: 0.7903, Validation Accuracy: 0.8089, Loss: 0.3270
Epoch   7 Batch  217/269 - Train Accuracy: 0.7966, Validation Accuracy: 0.8056, Loss: 0.3106
Epoch   7 Batch  218/269 - Train Accuracy: 0.8243, Validation Accuracy: 0.8053, Loss: 0.3089
Epoch   7 Batch  219/269 - Train Accuracy: 0.8046, Validation Accuracy: 0.8098, Loss: 0.3151
Epoch   7 Batch  220/269 - Train Accuracy: 0.8362, Validation Accuracy: 0.8109, Loss: 0.2769
Epoch   7 Batch  221/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8070, Loss: 0.3001
Epoch   7 Batch  222/269 - Train Accuracy: 0.8427, Validation Accuracy: 0.8102, Loss: 0.2858
Epoch   7 Batch  223/269 - Train Accuracy: 0.8131, Validation Accuracy: 0.8034, Loss: 0.2916
Epoch   7 Batch  224/269 - Train Accuracy: 0.8171, Validation Accuracy: 0.8119, Loss: 0.3105
Epoch   7 Batch  225/269 - Train Accuracy: 0.8117, Validation Accuracy: 0.8109, Loss: 0.2929
Epoch   7 Batch  226/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8115, Loss: 0.2992
Epoch   7 Batch  227/269 - Train Accuracy: 0.8360, Validation Accuracy: 0.8083, Loss: 0.2777
Epoch   7 Batch  228/269 - Train Accuracy: 0.8038, Validation Accuracy: 0.8011, Loss: 0.2973
Epoch   7 Batch  229/269 - Train Accuracy: 0.8076, Validation Accuracy: 0.8118, Loss: 0.2946
Epoch   7 Batch  230/269 - Train Accuracy: 0.7981, Validation Accuracy: 0.7995, Loss: 0.2907
Epoch   7 Batch  231/269 - Train Accuracy: 0.7988, Validation Accuracy: 0.8105, Loss: 0.3169
Epoch   7 Batch  232/269 - Train Accuracy: 0.7968, Validation Accuracy: 0.8120, Loss: 0.3202
Epoch   7 Batch  233/269 - Train Accuracy: 0.8172, Validation Accuracy: 0.8058, Loss: 0.2996
Epoch   7 Batch  234/269 - Train Accuracy: 0.8134, Validation Accuracy: 0.8070, Loss: 0.2954
Epoch   7 Batch  235/269 - Train Accuracy: 0.8182, Validation Accuracy: 0.8101, Loss: 0.2847
Epoch   7 Batch  236/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8145, Loss: 0.2892
Epoch   7 Batch  237/269 - Train Accuracy: 0.8136, Validation Accuracy: 0.8047, Loss: 0.2891
Epoch   7 Batch  238/269 - Train Accuracy: 0.8247, Validation Accuracy: 0.8144, Loss: 0.2968
Epoch   7 Batch  239/269 - Train Accuracy: 0.8163, Validation Accuracy: 0.8090, Loss: 0.2876
Epoch   7 Batch  240/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8123, Loss: 0.2670
Epoch   7 Batch  241/269 - Train Accuracy: 0.8135, Validation Accuracy: 0.8051, Loss: 0.2995
Epoch   7 Batch  242/269 - Train Accuracy: 0.8158, Validation Accuracy: 0.8146, Loss: 0.2914
Epoch   7 Batch  243/269 - Train Accuracy: 0.8209, Validation Accuracy: 0.8116, Loss: 0.2831
Epoch   7 Batch  244/269 - Train Accuracy: 0.8063, Validation Accuracy: 0.8098, Loss: 0.2929
Epoch   7 Batch  245/269 - Train Accuracy: 0.7929, Validation Accuracy: 0.8110, Loss: 0.3163
Epoch   7 Batch  246/269 - Train Accuracy: 0.8042, Validation Accuracy: 0.8124, Loss: 0.2945
Epoch   7 Batch  247/269 - Train Accuracy: 0.8032, Validation Accuracy: 0.8110, Loss: 0.3067
Epoch   7 Batch  248/269 - Train Accuracy: 0.8246, Validation Accuracy: 0.8008, Loss: 0.2860
Epoch   7 Batch  249/269 - Train Accuracy: 0.8366, Validation Accuracy: 0.7989, Loss: 0.2726
Epoch   7 Batch  250/269 - Train Accuracy: 0.7911, Validation Accuracy: 0.8073, Loss: 0.2910
Epoch   7 Batch  251/269 - Train Accuracy: 0.8369, Validation Accuracy: 0.8073, Loss: 0.2839
Epoch   7 Batch  252/269 - Train Accuracy: 0.8071, Validation Accuracy: 0.8030, Loss: 0.2889
Epoch   7 Batch  253/269 - Train Accuracy: 0.8026, Validation Accuracy: 0.8063, Loss: 0.3003
Epoch   7 Batch  254/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8086, Loss: 0.2917
Epoch   7 Batch  255/269 - Train Accuracy: 0.8204, Validation Accuracy: 0.8092, Loss: 0.2887
Epoch   7 Batch  256/269 - Train Accuracy: 0.7941, Validation Accuracy: 0.8164, Loss: 0.2948
Epoch   7 Batch  257/269 - Train Accuracy: 0.8012, Validation Accuracy: 0.8090, Loss: 0.3107
Epoch   7 Batch  258/269 - Train Accuracy: 0.8227, Validation Accuracy: 0.8143, Loss: 0.2964
Epoch   7 Batch  259/269 - Train Accuracy: 0.8232, Validation Accuracy: 0.8146, Loss: 0.2855
Epoch   7 Batch  260/269 - Train Accuracy: 0.7916, Validation Accuracy: 0.8142, Loss: 0.3131
Epoch   7 Batch  261/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8224, Loss: 0.3016
Epoch   7 Batch  262/269 - Train Accuracy: 0.8223, Validation Accuracy: 0.8233, Loss: 0.2910
Epoch   7 Batch  263/269 - Train Accuracy: 0.8023, Validation Accuracy: 0.8073, Loss: 0.2981
Epoch   7 Batch  264/269 - Train Accuracy: 0.7918, Validation Accuracy: 0.8168, Loss: 0.3034
Epoch   7 Batch  265/269 - Train Accuracy: 0.8207, Validation Accuracy: 0.8193, Loss: 0.2910
Epoch   7 Batch  266/269 - Train Accuracy: 0.8169, Validation Accuracy: 0.8182, Loss: 0.2849
Epoch   7 Batch  267/269 - Train Accuracy: 0.8025, Validation Accuracy: 0.8086, Loss: 0.3012
Epoch   8 Batch    1/269 - Train Accuracy: 0.8189, Validation Accuracy: 0.8142, Loss: 0.2917
Epoch   8 Batch    2/269 - Train Accuracy: 0.8133, Validation Accuracy: 0.8192, Loss: 0.2932
Epoch   8 Batch    3/269 - Train Accuracy: 0.8269, Validation Accuracy: 0.8203, Loss: 0.2866
Epoch   8 Batch    4/269 - Train Accuracy: 0.7921, Validation Accuracy: 0.8191, Loss: 0.3020
Epoch   8 Batch    5/269 - Train Accuracy: 0.7914, Validation Accuracy: 0.8177, Loss: 0.3006
Epoch   8 Batch    6/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8220, Loss: 0.2762
Epoch   8 Batch    7/269 - Train Accuracy: 0.8091, Validation Accuracy: 0.8090, Loss: 0.2823
Epoch   8 Batch    8/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8183, Loss: 0.3083
Epoch   8 Batch    9/269 - Train Accuracy: 0.8079, Validation Accuracy: 0.8162, Loss: 0.2935
Epoch   8 Batch   10/269 - Train Accuracy: 0.8205, Validation Accuracy: 0.8074, Loss: 0.2873
Epoch   8 Batch   11/269 - Train Accuracy: 0.8135, Validation Accuracy: 0.8169, Loss: 0.2959
Epoch   8 Batch   12/269 - Train Accuracy: 0.8184, Validation Accuracy: 0.8179, Loss: 0.3098
Epoch   8 Batch   13/269 - Train Accuracy: 0.8295, Validation Accuracy: 0.8170, Loss: 0.2617
Epoch   8 Batch   14/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8185, Loss: 0.2852
Epoch   8 Batch   15/269 - Train Accuracy: 0.8214, Validation Accuracy: 0.8147, Loss: 0.2754
Epoch   8 Batch   16/269 - Train Accuracy: 0.8131, Validation Accuracy: 0.8208, Loss: 0.2873
Epoch   8 Batch   17/269 - Train Accuracy: 0.8224, Validation Accuracy: 0.8227, Loss: 0.2714
Epoch   8 Batch   18/269 - Train Accuracy: 0.8082, Validation Accuracy: 0.8216, Loss: 0.2880
Epoch   8 Batch   19/269 - Train Accuracy: 0.8321, Validation Accuracy: 0.8215, Loss: 0.2680
Epoch   8 Batch   20/269 - Train Accuracy: 0.8307, Validation Accuracy: 0.8251, Loss: 0.2890
Epoch   8 Batch   21/269 - Train Accuracy: 0.8071, Validation Accuracy: 0.8167, Loss: 0.3112
Epoch   8 Batch   22/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8228, Loss: 0.2720
Epoch   8 Batch   23/269 - Train Accuracy: 0.8121, Validation Accuracy: 0.8219, Loss: 0.2841
Epoch   8 Batch   24/269 - Train Accuracy: 0.8077, Validation Accuracy: 0.8137, Loss: 0.2905
Epoch   8 Batch   25/269 - Train Accuracy: 0.8131, Validation Accuracy: 0.8152, Loss: 0.3042
Epoch   8 Batch   26/269 - Train Accuracy: 0.8308, Validation Accuracy: 0.8176, Loss: 0.2589
Epoch   8 Batch   27/269 - Train Accuracy: 0.8124, Validation Accuracy: 0.8188, Loss: 0.2793
Epoch   8 Batch   28/269 - Train Accuracy: 0.7750, Validation Accuracy: 0.8142, Loss: 0.2996
Epoch   8 Batch   29/269 - Train Accuracy: 0.8332, Validation Accuracy: 0.8261, Loss: 0.3014
Epoch   8 Batch   30/269 - Train Accuracy: 0.8205, Validation Accuracy: 0.8207, Loss: 0.2815
Epoch   8 Batch   31/269 - Train Accuracy: 0.8232, Validation Accuracy: 0.8125, Loss: 0.2723
Epoch   8 Batch   32/269 - Train Accuracy: 0.8182, Validation Accuracy: 0.8191, Loss: 0.2803
Epoch   8 Batch   33/269 - Train Accuracy: 0.8342, Validation Accuracy: 0.8161, Loss: 0.2669
Epoch   8 Batch   34/269 - Train Accuracy: 0.8283, Validation Accuracy: 0.8210, Loss: 0.2762
Epoch   8 Batch   35/269 - Train Accuracy: 0.8170, Validation Accuracy: 0.8225, Loss: 0.2868
Epoch   8 Batch   36/269 - Train Accuracy: 0.8075, Validation Accuracy: 0.8218, Loss: 0.2789
Epoch   8 Batch   37/269 - Train Accuracy: 0.8205, Validation Accuracy: 0.8154, Loss: 0.2847
Epoch   8 Batch   38/269 - Train Accuracy: 0.8247, Validation Accuracy: 0.8183, Loss: 0.2788
Epoch   8 Batch   39/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8236, Loss: 0.2828
Epoch   8 Batch   40/269 - Train Accuracy: 0.8164, Validation Accuracy: 0.8185, Loss: 0.2903
Epoch   8 Batch   41/269 - Train Accuracy: 0.8216, Validation Accuracy: 0.8207, Loss: 0.2846
Epoch   8 Batch   42/269 - Train Accuracy: 0.8417, Validation Accuracy: 0.8229, Loss: 0.2662
Epoch   8 Batch   43/269 - Train Accuracy: 0.8046, Validation Accuracy: 0.8161, Loss: 0.2918
Epoch   8 Batch   44/269 - Train Accuracy: 0.8187, Validation Accuracy: 0.8199, Loss: 0.2791
Epoch   8 Batch   45/269 - Train Accuracy: 0.8129, Validation Accuracy: 0.8207, Loss: 0.2964
Epoch   8 Batch   46/269 - Train Accuracy: 0.8123, Validation Accuracy: 0.8201, Loss: 0.2867
Epoch   8 Batch   47/269 - Train Accuracy: 0.8309, Validation Accuracy: 0.8256, Loss: 0.2546
Epoch   8 Batch   48/269 - Train Accuracy: 0.8307, Validation Accuracy: 0.8169, Loss: 0.2682
Epoch   8 Batch   49/269 - Train Accuracy: 0.8067, Validation Accuracy: 0.8139, Loss: 0.2785
Epoch   8 Batch   50/269 - Train Accuracy: 0.7880, Validation Accuracy: 0.8126, Loss: 0.2991
Epoch   8 Batch   51/269 - Train Accuracy: 0.8070, Validation Accuracy: 0.8132, Loss: 0.2907
Epoch   8 Batch   52/269 - Train Accuracy: 0.8227, Validation Accuracy: 0.8216, Loss: 0.2679
Epoch   8 Batch   53/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8105, Loss: 0.2932
Epoch   8 Batch   54/269 - Train Accuracy: 0.8111, Validation Accuracy: 0.8183, Loss: 0.2872
Epoch   8 Batch   55/269 - Train Accuracy: 0.8187, Validation Accuracy: 0.8130, Loss: 0.2699
Epoch   8 Batch   56/269 - Train Accuracy: 0.8101, Validation Accuracy: 0.8004, Loss: 0.2814
Epoch   8 Batch   57/269 - Train Accuracy: 0.8232, Validation Accuracy: 0.8140, Loss: 0.2993
Epoch   8 Batch   58/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8140, Loss: 0.2750
Epoch   8 Batch   59/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8118, Loss: 0.2586
Epoch   8 Batch   60/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8164, Loss: 0.2707
Epoch   8 Batch   61/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8148, Loss: 0.2552
Epoch   8 Batch   62/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8266, Loss: 0.2652
Epoch   8 Batch   63/269 - Train Accuracy: 0.8199, Validation Accuracy: 0.8288, Loss: 0.2802
Epoch   8 Batch   64/269 - Train Accuracy: 0.8217, Validation Accuracy: 0.8269, Loss: 0.2656
Epoch   8 Batch   65/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8262, Loss: 0.2755
Epoch   8 Batch   66/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8252, Loss: 0.2709
Epoch   8 Batch   67/269 - Train Accuracy: 0.8243, Validation Accuracy: 0.8175, Loss: 0.2805
Epoch   8 Batch   68/269 - Train Accuracy: 0.8192, Validation Accuracy: 0.8188, Loss: 0.2814
Epoch   8 Batch   69/269 - Train Accuracy: 0.7886, Validation Accuracy: 0.8251, Loss: 0.3069
Epoch   8 Batch   70/269 - Train Accuracy: 0.8383, Validation Accuracy: 0.8272, Loss: 0.2810
Epoch   8 Batch   71/269 - Train Accuracy: 0.8109, Validation Accuracy: 0.8101, Loss: 0.2893
Epoch   8 Batch   72/269 - Train Accuracy: 0.8287, Validation Accuracy: 0.8097, Loss: 0.2763
Epoch   8 Batch   73/269 - Train Accuracy: 0.8085, Validation Accuracy: 0.8221, Loss: 0.2964
Epoch   8 Batch   74/269 - Train Accuracy: 0.8231, Validation Accuracy: 0.8208, Loss: 0.2725
Epoch   8 Batch   75/269 - Train Accuracy: 0.8251, Validation Accuracy: 0.8149, Loss: 0.2812
Epoch   8 Batch   76/269 - Train Accuracy: 0.8160, Validation Accuracy: 0.8162, Loss: 0.2757
Epoch   8 Batch   77/269 - Train Accuracy: 0.8269, Validation Accuracy: 0.8259, Loss: 0.2700
Epoch   8 Batch   78/269 - Train Accuracy: 0.8371, Validation Accuracy: 0.8227, Loss: 0.2670
Epoch   8 Batch   79/269 - Train Accuracy: 0.8132, Validation Accuracy: 0.8198, Loss: 0.2726
Epoch   8 Batch   80/269 - Train Accuracy: 0.8309, Validation Accuracy: 0.8237, Loss: 0.2642
Epoch   8 Batch   81/269 - Train Accuracy: 0.8150, Validation Accuracy: 0.8234, Loss: 0.2828
Epoch   8 Batch   82/269 - Train Accuracy: 0.8386, Validation Accuracy: 0.8161, Loss: 0.2645
Epoch   8 Batch   83/269 - Train Accuracy: 0.8048, Validation Accuracy: 0.8131, Loss: 0.2827
Epoch   8 Batch   84/269 - Train Accuracy: 0.8371, Validation Accuracy: 0.8214, Loss: 0.2681
Epoch   8 Batch   85/269 - Train Accuracy: 0.8309, Validation Accuracy: 0.8237, Loss: 0.2659
Epoch   8 Batch   86/269 - Train Accuracy: 0.8314, Validation Accuracy: 0.8237, Loss: 0.2797
Epoch   8 Batch   87/269 - Train Accuracy: 0.8104, Validation Accuracy: 0.8230, Loss: 0.2955
Epoch   8 Batch   88/269 - Train Accuracy: 0.8140, Validation Accuracy: 0.8151, Loss: 0.2786
Epoch   8 Batch   89/269 - Train Accuracy: 0.8224, Validation Accuracy: 0.8208, Loss: 0.2761
Epoch   8 Batch   90/269 - Train Accuracy: 0.8048, Validation Accuracy: 0.8180, Loss: 0.2876
Epoch   8 Batch   91/269 - Train Accuracy: 0.8297, Validation Accuracy: 0.8006, Loss: 0.2678
Epoch   8 Batch   92/269 - Train Accuracy: 0.8367, Validation Accuracy: 0.8218, Loss: 0.2725
Epoch   8 Batch   93/269 - Train Accuracy: 0.8294, Validation Accuracy: 0.8162, Loss: 0.2619
Epoch   8 Batch   94/269 - Train Accuracy: 0.8060, Validation Accuracy: 0.8123, Loss: 0.2954
Epoch   8 Batch   95/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8146, Loss: 0.2740
Epoch   8 Batch   96/269 - Train Accuracy: 0.8192, Validation Accuracy: 0.8190, Loss: 0.2676
Epoch   8 Batch   97/269 - Train Accuracy: 0.8350, Validation Accuracy: 0.8251, Loss: 0.2768
Epoch   8 Batch   98/269 - Train Accuracy: 0.8220, Validation Accuracy: 0.8233, Loss: 0.2744
Epoch   8 Batch   99/269 - Train Accuracy: 0.8110, Validation Accuracy: 0.8142, Loss: 0.2795
Epoch   8 Batch  100/269 - Train Accuracy: 0.8373, Validation Accuracy: 0.8202, Loss: 0.2693
Epoch   8 Batch  101/269 - Train Accuracy: 0.8042, Validation Accuracy: 0.8184, Loss: 0.2946
Epoch   8 Batch  102/269 - Train Accuracy: 0.8207, Validation Accuracy: 0.8236, Loss: 0.2706
Epoch   8 Batch  103/269 - Train Accuracy: 0.8351, Validation Accuracy: 0.8240, Loss: 0.2784
Epoch   8 Batch  104/269 - Train Accuracy: 0.8082, Validation Accuracy: 0.8239, Loss: 0.2644
Epoch   8 Batch  105/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8303, Loss: 0.2654
Epoch   8 Batch  106/269 - Train Accuracy: 0.8266, Validation Accuracy: 0.8217, Loss: 0.2610
Epoch   8 Batch  107/269 - Train Accuracy: 0.8237, Validation Accuracy: 0.8220, Loss: 0.2802
Epoch   8 Batch  108/269 - Train Accuracy: 0.8306, Validation Accuracy: 0.8228, Loss: 0.2636
Epoch   8 Batch  109/269 - Train Accuracy: 0.8018, Validation Accuracy: 0.8236, Loss: 0.2762
Epoch   8 Batch  110/269 - Train Accuracy: 0.8233, Validation Accuracy: 0.8131, Loss: 0.2656
Epoch   8 Batch  111/269 - Train Accuracy: 0.8214, Validation Accuracy: 0.8177, Loss: 0.3006
Epoch   8 Batch  112/269 - Train Accuracy: 0.8100, Validation Accuracy: 0.8247, Loss: 0.2687
Epoch   8 Batch  113/269 - Train Accuracy: 0.8210, Validation Accuracy: 0.8207, Loss: 0.2641
Epoch   8 Batch  114/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8182, Loss: 0.2672
Epoch   8 Batch  115/269 - Train Accuracy: 0.8004, Validation Accuracy: 0.8244, Loss: 0.2777
Epoch   8 Batch  116/269 - Train Accuracy: 0.8365, Validation Accuracy: 0.8259, Loss: 0.2806
Epoch   8 Batch  117/269 - Train Accuracy: 0.8062, Validation Accuracy: 0.8215, Loss: 0.2667
Epoch   8 Batch  118/269 - Train Accuracy: 0.8290, Validation Accuracy: 0.8208, Loss: 0.2508
Epoch   8 Batch  119/269 - Train Accuracy: 0.8173, Validation Accuracy: 0.8312, Loss: 0.2890
Epoch   8 Batch  120/269 - Train Accuracy: 0.8183, Validation Accuracy: 0.8270, Loss: 0.2728
Epoch   8 Batch  121/269 - Train Accuracy: 0.8212, Validation Accuracy: 0.8191, Loss: 0.2584
Epoch   8 Batch  122/269 - Train Accuracy: 0.8170, Validation Accuracy: 0.8208, Loss: 0.2637
Epoch   8 Batch  123/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8177, Loss: 0.2733
Epoch   8 Batch  124/269 - Train Accuracy: 0.8151, Validation Accuracy: 0.8177, Loss: 0.2532
Epoch   8 Batch  125/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8194, Loss: 0.2523
Epoch   8 Batch  126/269 - Train Accuracy: 0.8199, Validation Accuracy: 0.8200, Loss: 0.2623
Epoch   8 Batch  127/269 - Train Accuracy: 0.8150, Validation Accuracy: 0.8194, Loss: 0.2832
Epoch   8 Batch  128/269 - Train Accuracy: 0.8179, Validation Accuracy: 0.8138, Loss: 0.2628
Epoch   8 Batch  129/269 - Train Accuracy: 0.8296, Validation Accuracy: 0.8246, Loss: 0.2694
Epoch   8 Batch  130/269 - Train Accuracy: 0.8359, Validation Accuracy: 0.8263, Loss: 0.2747
Epoch   8 Batch  131/269 - Train Accuracy: 0.8104, Validation Accuracy: 0.8289, Loss: 0.2691
Epoch   8 Batch  132/269 - Train Accuracy: 0.8075, Validation Accuracy: 0.8262, Loss: 0.2736
Epoch   8 Batch  133/269 - Train Accuracy: 0.8382, Validation Accuracy: 0.8263, Loss: 0.2561
Epoch   8 Batch  134/269 - Train Accuracy: 0.8153, Validation Accuracy: 0.8346, Loss: 0.2735
Epoch   8 Batch  135/269 - Train Accuracy: 0.8086, Validation Accuracy: 0.8287, Loss: 0.2837
Epoch   8 Batch  136/269 - Train Accuracy: 0.8110, Validation Accuracy: 0.8325, Loss: 0.2869
Epoch   8 Batch  137/269 - Train Accuracy: 0.8113, Validation Accuracy: 0.8254, Loss: 0.2787
Epoch   8 Batch  138/269 - Train Accuracy: 0.8354, Validation Accuracy: 0.8207, Loss: 0.2633
Epoch   8 Batch  139/269 - Train Accuracy: 0.8239, Validation Accuracy: 0.8244, Loss: 0.2534
Epoch   8 Batch  140/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8273, Loss: 0.2664
Epoch   8 Batch  141/269 - Train Accuracy: 0.8199, Validation Accuracy: 0.8250, Loss: 0.2739
Epoch   8 Batch  142/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8281, Loss: 0.2534
Epoch   8 Batch  143/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8170, Loss: 0.2589
Epoch   8 Batch  144/269 - Train Accuracy: 0.8306, Validation Accuracy: 0.8229, Loss: 0.2492
Epoch   8 Batch  145/269 - Train Accuracy: 0.8236, Validation Accuracy: 0.8300, Loss: 0.2560
Epoch   8 Batch  146/269 - Train Accuracy: 0.8337, Validation Accuracy: 0.8206, Loss: 0.2557
Epoch   8 Batch  147/269 - Train Accuracy: 0.8370, Validation Accuracy: 0.8327, Loss: 0.2536
Epoch   8 Batch  148/269 - Train Accuracy: 0.8198, Validation Accuracy: 0.8260, Loss: 0.2702
Epoch   8 Batch  149/269 - Train Accuracy: 0.7985, Validation Accuracy: 0.8173, Loss: 0.2689
Epoch   8 Batch  150/269 - Train Accuracy: 0.8210, Validation Accuracy: 0.8271, Loss: 0.2653
Epoch   8 Batch  151/269 - Train Accuracy: 0.8295, Validation Accuracy: 0.8240, Loss: 0.2518
Epoch   8 Batch  152/269 - Train Accuracy: 0.8245, Validation Accuracy: 0.8190, Loss: 0.2679
Epoch   8 Batch  153/269 - Train Accuracy: 0.8323, Validation Accuracy: 0.8272, Loss: 0.2641
Epoch   8 Batch  154/269 - Train Accuracy: 0.8380, Validation Accuracy: 0.8288, Loss: 0.2650
Epoch   8 Batch  155/269 - Train Accuracy: 0.8382, Validation Accuracy: 0.8234, Loss: 0.2458
Epoch   8 Batch  156/269 - Train Accuracy: 0.8073, Validation Accuracy: 0.8239, Loss: 0.2669
Epoch   8 Batch  157/269 - Train Accuracy: 0.8222, Validation Accuracy: 0.8258, Loss: 0.2594
Epoch   8 Batch  158/269 - Train Accuracy: 0.8240, Validation Accuracy: 0.8254, Loss: 0.2573
Epoch   8 Batch  159/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8325, Loss: 0.2664
Epoch   8 Batch  160/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8231, Loss: 0.2611
Epoch   8 Batch  161/269 - Train Accuracy: 0.8215, Validation Accuracy: 0.8190, Loss: 0.2585
Epoch   8 Batch  162/269 - Train Accuracy: 0.8365, Validation Accuracy: 0.8326, Loss: 0.2540
Epoch   8 Batch  163/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8320, Loss: 0.2572
Epoch   8 Batch  164/269 - Train Accuracy: 0.8382, Validation Accuracy: 0.8199, Loss: 0.2523
Epoch   8 Batch  165/269 - Train Accuracy: 0.8361, Validation Accuracy: 0.8254, Loss: 0.2583
Epoch   8 Batch  166/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8326, Loss: 0.2434
Epoch   8 Batch  167/269 - Train Accuracy: 0.8323, Validation Accuracy: 0.8236, Loss: 0.2647
Epoch   8 Batch  168/269 - Train Accuracy: 0.8312, Validation Accuracy: 0.8307, Loss: 0.2782
Epoch   8 Batch  169/269 - Train Accuracy: 0.8198, Validation Accuracy: 0.8295, Loss: 0.2599
Epoch   8 Batch  170/269 - Train Accuracy: 0.8314, Validation Accuracy: 0.8276, Loss: 0.2550
Epoch   8 Batch  171/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8291, Loss: 0.2664
Epoch   8 Batch  172/269 - Train Accuracy: 0.8132, Validation Accuracy: 0.8299, Loss: 0.2715
Epoch   8 Batch  173/269 - Train Accuracy: 0.8389, Validation Accuracy: 0.8239, Loss: 0.2549
Epoch   8 Batch  174/269 - Train Accuracy: 0.8322, Validation Accuracy: 0.8313, Loss: 0.2594
Epoch   8 Batch  175/269 - Train Accuracy: 0.8218, Validation Accuracy: 0.8236, Loss: 0.2785
Epoch   8 Batch  176/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8331, Loss: 0.2722
Epoch   8 Batch  177/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8294, Loss: 0.2500
Epoch   8 Batch  178/269 - Train Accuracy: 0.8435, Validation Accuracy: 0.8192, Loss: 0.2620
Epoch   8 Batch  179/269 - Train Accuracy: 0.8290, Validation Accuracy: 0.8256, Loss: 0.2547
Epoch   8 Batch  180/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8279, Loss: 0.2474
Epoch   8 Batch  181/269 - Train Accuracy: 0.8203, Validation Accuracy: 0.8317, Loss: 0.2542
Epoch   8 Batch  182/269 - Train Accuracy: 0.8315, Validation Accuracy: 0.8233, Loss: 0.2571
Epoch   8 Batch  183/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8246, Loss: 0.2225
Epoch   8 Batch  184/269 - Train Accuracy: 0.8219, Validation Accuracy: 0.8280, Loss: 0.2558
Epoch   8 Batch  185/269 - Train Accuracy: 0.8519, Validation Accuracy: 0.8298, Loss: 0.2419
Epoch   8 Batch  186/269 - Train Accuracy: 0.8324, Validation Accuracy: 0.8201, Loss: 0.2556
Epoch   8 Batch  187/269 - Train Accuracy: 0.8279, Validation Accuracy: 0.8259, Loss: 0.2510
Epoch   8 Batch  188/269 - Train Accuracy: 0.8448, Validation Accuracy: 0.8308, Loss: 0.2441
Epoch   8 Batch  189/269 - Train Accuracy: 0.8370, Validation Accuracy: 0.8331, Loss: 0.2422
Epoch   8 Batch  190/269 - Train Accuracy: 0.8264, Validation Accuracy: 0.8279, Loss: 0.2384
Epoch   8 Batch  191/269 - Train Accuracy: 0.8182, Validation Accuracy: 0.8280, Loss: 0.2475
Epoch   8 Batch  192/269 - Train Accuracy: 0.8365, Validation Accuracy: 0.8301, Loss: 0.2540
Epoch   8 Batch  193/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8268, Loss: 0.2484
Epoch   8 Batch  194/269 - Train Accuracy: 0.8230, Validation Accuracy: 0.8251, Loss: 0.2581
Epoch   8 Batch  195/269 - Train Accuracy: 0.8400, Validation Accuracy: 0.8315, Loss: 0.2558
Epoch   8 Batch  196/269 - Train Accuracy: 0.8234, Validation Accuracy: 0.8350, Loss: 0.2456
Epoch   8 Batch  197/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8302, Loss: 0.2655
Epoch   8 Batch  198/269 - Train Accuracy: 0.8152, Validation Accuracy: 0.8313, Loss: 0.2689
Epoch   8 Batch  199/269 - Train Accuracy: 0.8292, Validation Accuracy: 0.8318, Loss: 0.2559
Epoch   8 Batch  200/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8361, Loss: 0.2627
Epoch   8 Batch  201/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8311, Loss: 0.2497
Epoch   8 Batch  202/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8271, Loss: 0.2509
Epoch   8 Batch  203/269 - Train Accuracy: 0.8332, Validation Accuracy: 0.8360, Loss: 0.2784
Epoch   8 Batch  204/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8346, Loss: 0.2698
Epoch   8 Batch  205/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8394, Loss: 0.2539
Epoch   8 Batch  206/269 - Train Accuracy: 0.8157, Validation Accuracy: 0.8332, Loss: 0.2693
Epoch   8 Batch  207/269 - Train Accuracy: 0.8181, Validation Accuracy: 0.8257, Loss: 0.2516
Epoch   8 Batch  208/269 - Train Accuracy: 0.8335, Validation Accuracy: 0.8305, Loss: 0.2585
Epoch   8 Batch  209/269 - Train Accuracy: 0.8411, Validation Accuracy: 0.8157, Loss: 0.2403
Epoch   8 Batch  210/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8311, Loss: 0.2588
Epoch   8 Batch  211/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8276, Loss: 0.2561
Epoch   8 Batch  212/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8310, Loss: 0.2492
Epoch   8 Batch  213/269 - Train Accuracy: 0.8399, Validation Accuracy: 0.8298, Loss: 0.2505
Epoch   8 Batch  214/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8283, Loss: 0.2621
Epoch   8 Batch  215/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8318, Loss: 0.2332
Epoch   8 Batch  216/269 - Train Accuracy: 0.8174, Validation Accuracy: 0.8320, Loss: 0.2792
Epoch   8 Batch  217/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8285, Loss: 0.2589
Epoch   8 Batch  218/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8335, Loss: 0.2571
Epoch   8 Batch  219/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8349, Loss: 0.2709
Epoch   8 Batch  220/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8369, Loss: 0.2345
Epoch   8 Batch  221/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8410, Loss: 0.2505
Epoch   8 Batch  222/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8357, Loss: 0.2369
Epoch   8 Batch  223/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8374, Loss: 0.2427
Epoch   8 Batch  224/269 - Train Accuracy: 0.8403, Validation Accuracy: 0.8380, Loss: 0.2706
Epoch   8 Batch  225/269 - Train Accuracy: 0.8319, Validation Accuracy: 0.8292, Loss: 0.2470
Epoch   8 Batch  226/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8303, Loss: 0.2489
Epoch   8 Batch  227/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8357, Loss: 0.2365
Epoch   8 Batch  228/269 - Train Accuracy: 0.8321, Validation Accuracy: 0.8291, Loss: 0.2520
Epoch   8 Batch  229/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8305, Loss: 0.2418
Epoch   8 Batch  230/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8331, Loss: 0.2452
Epoch   8 Batch  231/269 - Train Accuracy: 0.8214, Validation Accuracy: 0.8326, Loss: 0.2612
Epoch   8 Batch  232/269 - Train Accuracy: 0.8279, Validation Accuracy: 0.8333, Loss: 0.2513
Epoch   8 Batch  233/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8367, Loss: 0.2512
Epoch   8 Batch  234/269 - Train Accuracy: 0.8407, Validation Accuracy: 0.8327, Loss: 0.2475
Epoch   8 Batch  235/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8342, Loss: 0.2367
Epoch   8 Batch  236/269 - Train Accuracy: 0.8223, Validation Accuracy: 0.8425, Loss: 0.2407
Epoch   8 Batch  237/269 - Train Accuracy: 0.8357, Validation Accuracy: 0.8388, Loss: 0.2461
Epoch   8 Batch  238/269 - Train Accuracy: 0.8453, Validation Accuracy: 0.8253, Loss: 0.2485
Epoch   8 Batch  239/269 - Train Accuracy: 0.8330, Validation Accuracy: 0.8361, Loss: 0.2430
Epoch   8 Batch  240/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8311, Loss: 0.2228
Epoch   8 Batch  241/269 - Train Accuracy: 0.8452, Validation Accuracy: 0.8310, Loss: 0.2595
Epoch   8 Batch  242/269 - Train Accuracy: 0.8364, Validation Accuracy: 0.8303, Loss: 0.2381
Epoch   8 Batch  243/269 - Train Accuracy: 0.8418, Validation Accuracy: 0.8382, Loss: 0.2360
Epoch   8 Batch  244/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8336, Loss: 0.2407
Epoch   8 Batch  245/269 - Train Accuracy: 0.8236, Validation Accuracy: 0.8380, Loss: 0.2690
Epoch   8 Batch  246/269 - Train Accuracy: 0.8162, Validation Accuracy: 0.8240, Loss: 0.2459
Epoch   8 Batch  247/269 - Train Accuracy: 0.8334, Validation Accuracy: 0.8276, Loss: 0.2521
Epoch   8 Batch  248/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8340, Loss: 0.2374
Epoch   8 Batch  249/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8400, Loss: 0.2327
Epoch   8 Batch  250/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8265, Loss: 0.2423
Epoch   8 Batch  251/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8351, Loss: 0.2378
Epoch   8 Batch  252/269 - Train Accuracy: 0.8340, Validation Accuracy: 0.8399, Loss: 0.2464
Epoch   8 Batch  253/269 - Train Accuracy: 0.8214, Validation Accuracy: 0.8262, Loss: 0.2596
Epoch   8 Batch  254/269 - Train Accuracy: 0.8364, Validation Accuracy: 0.8383, Loss: 0.2414
Epoch   8 Batch  255/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8381, Loss: 0.2388
Epoch   8 Batch  256/269 - Train Accuracy: 0.8146, Validation Accuracy: 0.8263, Loss: 0.2486
Epoch   8 Batch  257/269 - Train Accuracy: 0.8182, Validation Accuracy: 0.8402, Loss: 0.2568
Epoch   8 Batch  258/269 - Train Accuracy: 0.8380, Validation Accuracy: 0.8397, Loss: 0.2493
Epoch   8 Batch  259/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8381, Loss: 0.2417
Epoch   8 Batch  260/269 - Train Accuracy: 0.8136, Validation Accuracy: 0.8427, Loss: 0.2670
Epoch   8 Batch  261/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8366, Loss: 0.2590
Epoch   8 Batch  262/269 - Train Accuracy: 0.8458, Validation Accuracy: 0.8354, Loss: 0.2492
Epoch   8 Batch  263/269 - Train Accuracy: 0.8376, Validation Accuracy: 0.8365, Loss: 0.2482
Epoch   8 Batch  264/269 - Train Accuracy: 0.8152, Validation Accuracy: 0.8370, Loss: 0.2616
Epoch   8 Batch  265/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8340, Loss: 0.2427
Epoch   8 Batch  266/269 - Train Accuracy: 0.8417, Validation Accuracy: 0.8330, Loss: 0.2278
Epoch   8 Batch  267/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8309, Loss: 0.2489
Epoch   9 Batch    1/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8364, Loss: 0.2459
Epoch   9 Batch    2/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8321, Loss: 0.2442
Epoch   9 Batch    3/269 - Train Accuracy: 0.8363, Validation Accuracy: 0.8281, Loss: 0.2427
Epoch   9 Batch    4/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8413, Loss: 0.2480
Epoch   9 Batch    5/269 - Train Accuracy: 0.8306, Validation Accuracy: 0.8395, Loss: 0.2453
Epoch   9 Batch    6/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8265, Loss: 0.2352
Epoch   9 Batch    7/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8303, Loss: 0.2357
Epoch   9 Batch    8/269 - Train Accuracy: 0.8296, Validation Accuracy: 0.8350, Loss: 0.2447
Epoch   9 Batch    9/269 - Train Accuracy: 0.8326, Validation Accuracy: 0.8292, Loss: 0.2585
Epoch   9 Batch   10/269 - Train Accuracy: 0.8351, Validation Accuracy: 0.8207, Loss: 0.2415
Epoch   9 Batch   11/269 - Train Accuracy: 0.8340, Validation Accuracy: 0.8324, Loss: 0.2576
Epoch   9 Batch   12/269 - Train Accuracy: 0.8388, Validation Accuracy: 0.8362, Loss: 0.2577
Epoch   9 Batch   13/269 - Train Accuracy: 0.8426, Validation Accuracy: 0.8347, Loss: 0.2170
Epoch   9 Batch   14/269 - Train Accuracy: 0.8251, Validation Accuracy: 0.8396, Loss: 0.2436
Epoch   9 Batch   15/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8424, Loss: 0.2322
Epoch   9 Batch   16/269 - Train Accuracy: 0.8338, Validation Accuracy: 0.8395, Loss: 0.2436
Epoch   9 Batch   17/269 - Train Accuracy: 0.8378, Validation Accuracy: 0.8338, Loss: 0.2331
Epoch   9 Batch   18/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8416, Loss: 0.2436
Epoch   9 Batch   19/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8428, Loss: 0.2258
Epoch   9 Batch   20/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8423, Loss: 0.2493
Epoch   9 Batch   21/269 - Train Accuracy: 0.8399, Validation Accuracy: 0.8339, Loss: 0.2620
Epoch   9 Batch   22/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8383, Loss: 0.2400
Epoch   9 Batch   23/269 - Train Accuracy: 0.8219, Validation Accuracy: 0.8322, Loss: 0.2474
Epoch   9 Batch   24/269 - Train Accuracy: 0.8416, Validation Accuracy: 0.8297, Loss: 0.2424
Epoch   9 Batch   25/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8349, Loss: 0.2596
Epoch   9 Batch   26/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8319, Loss: 0.2185
Epoch   9 Batch   27/269 - Train Accuracy: 0.8326, Validation Accuracy: 0.8351, Loss: 0.2372
Epoch   9 Batch   28/269 - Train Accuracy: 0.8040, Validation Accuracy: 0.8369, Loss: 0.2613
Epoch   9 Batch   29/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8379, Loss: 0.2518
Epoch   9 Batch   30/269 - Train Accuracy: 0.8406, Validation Accuracy: 0.8286, Loss: 0.2349
Epoch   9 Batch   31/269 - Train Accuracy: 0.8499, Validation Accuracy: 0.8369, Loss: 0.2363
Epoch   9 Batch   32/269 - Train Accuracy: 0.8315, Validation Accuracy: 0.8311, Loss: 0.2318
Epoch   9 Batch   33/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8295, Loss: 0.2217
Epoch   9 Batch   34/269 - Train Accuracy: 0.8519, Validation Accuracy: 0.8392, Loss: 0.2426
Epoch   9 Batch   35/269 - Train Accuracy: 0.8351, Validation Accuracy: 0.8277, Loss: 0.2499
Epoch   9 Batch   36/269 - Train Accuracy: 0.8116, Validation Accuracy: 0.8347, Loss: 0.2475
Epoch   9 Batch   37/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8379, Loss: 0.2444
Epoch   9 Batch   38/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8310, Loss: 0.2389
Epoch   9 Batch   39/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8419, Loss: 0.2390
Epoch   9 Batch   40/269 - Train Accuracy: 0.8255, Validation Accuracy: 0.8353, Loss: 0.2498
Epoch   9 Batch   41/269 - Train Accuracy: 0.8289, Validation Accuracy: 0.8276, Loss: 0.2354
Epoch   9 Batch   42/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8383, Loss: 0.2297
Epoch   9 Batch   43/269 - Train Accuracy: 0.8139, Validation Accuracy: 0.8327, Loss: 0.2455
Epoch   9 Batch   44/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8388, Loss: 0.2392
Epoch   9 Batch   45/269 - Train Accuracy: 0.8406, Validation Accuracy: 0.8290, Loss: 0.2438
Epoch   9 Batch   46/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8329, Loss: 0.2417
Epoch   9 Batch   47/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8358, Loss: 0.2159
Epoch   9 Batch   48/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8345, Loss: 0.2305
Epoch   9 Batch   49/269 - Train Accuracy: 0.8308, Validation Accuracy: 0.8432, Loss: 0.2374
Epoch   9 Batch   50/269 - Train Accuracy: 0.8169, Validation Accuracy: 0.8449, Loss: 0.2487
Epoch   9 Batch   51/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8335, Loss: 0.2484
Epoch   9 Batch   52/269 - Train Accuracy: 0.8356, Validation Accuracy: 0.8386, Loss: 0.2187
Epoch   9 Batch   53/269 - Train Accuracy: 0.8407, Validation Accuracy: 0.8476, Loss: 0.2513
Epoch   9 Batch   54/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8399, Loss: 0.2380
Epoch   9 Batch   55/269 - Train Accuracy: 0.8383, Validation Accuracy: 0.8329, Loss: 0.2341
Epoch   9 Batch   56/269 - Train Accuracy: 0.8287, Validation Accuracy: 0.8301, Loss: 0.2439
Epoch   9 Batch   57/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8327, Loss: 0.2483
Epoch   9 Batch   58/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8326, Loss: 0.2306
Epoch   9 Batch   59/269 - Train Accuracy: 0.8468, Validation Accuracy: 0.8383, Loss: 0.2143
Epoch   9 Batch   60/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8403, Loss: 0.2246
Epoch   9 Batch   61/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8405, Loss: 0.2119
Epoch   9 Batch   62/269 - Train Accuracy: 0.8454, Validation Accuracy: 0.8318, Loss: 0.2275
Epoch   9 Batch   63/269 - Train Accuracy: 0.8324, Validation Accuracy: 0.8368, Loss: 0.2389
Epoch   9 Batch   64/269 - Train Accuracy: 0.8416, Validation Accuracy: 0.8374, Loss: 0.2258
Epoch   9 Batch   65/269 - Train Accuracy: 0.8377, Validation Accuracy: 0.8335, Loss: 0.2310
Epoch   9 Batch   66/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8429, Loss: 0.2288
Epoch   9 Batch   67/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8365, Loss: 0.2419
Epoch   9 Batch   68/269 - Train Accuracy: 0.8286, Validation Accuracy: 0.8374, Loss: 0.2392
Epoch   9 Batch   69/269 - Train Accuracy: 0.8142, Validation Accuracy: 0.8414, Loss: 0.2642
Epoch   9 Batch   70/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8430, Loss: 0.2371
Epoch   9 Batch   71/269 - Train Accuracy: 0.8330, Validation Accuracy: 0.8378, Loss: 0.2448
Epoch   9 Batch   72/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8383, Loss: 0.2335
Epoch   9 Batch   73/269 - Train Accuracy: 0.8357, Validation Accuracy: 0.8431, Loss: 0.2510
Epoch   9 Batch   74/269 - Train Accuracy: 0.8398, Validation Accuracy: 0.8382, Loss: 0.2281
Epoch   9 Batch   75/269 - Train Accuracy: 0.8406, Validation Accuracy: 0.8408, Loss: 0.2345
Epoch   9 Batch   76/269 - Train Accuracy: 0.8362, Validation Accuracy: 0.8390, Loss: 0.2331
Epoch   9 Batch   77/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8317, Loss: 0.2238
Epoch   9 Batch   78/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8331, Loss: 0.2252
Epoch   9 Batch   79/269 - Train Accuracy: 0.8378, Validation Accuracy: 0.8321, Loss: 0.2336
Epoch   9 Batch   80/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8288, Loss: 0.2211
Epoch   9 Batch   81/269 - Train Accuracy: 0.8233, Validation Accuracy: 0.8285, Loss: 0.2493
Epoch   9 Batch   82/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8336, Loss: 0.2157
Epoch   9 Batch   83/269 - Train Accuracy: 0.8315, Validation Accuracy: 0.8427, Loss: 0.2425
Epoch   9 Batch   84/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8277, Loss: 0.2248
Epoch   9 Batch   85/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8323, Loss: 0.2344
Epoch   9 Batch   86/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8380, Loss: 0.2288
Epoch   9 Batch   87/269 - Train Accuracy: 0.8287, Validation Accuracy: 0.8441, Loss: 0.2465
Epoch   9 Batch   88/269 - Train Accuracy: 0.8246, Validation Accuracy: 0.8296, Loss: 0.2381
Epoch   9 Batch   89/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8431, Loss: 0.2367
Epoch   9 Batch   90/269 - Train Accuracy: 0.8150, Validation Accuracy: 0.8265, Loss: 0.2386
Epoch   9 Batch   91/269 - Train Accuracy: 0.8463, Validation Accuracy: 0.8352, Loss: 0.2319
Epoch   9 Batch   92/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8293, Loss: 0.2275
Epoch   9 Batch   93/269 - Train Accuracy: 0.8607, Validation Accuracy: 0.8340, Loss: 0.2265
Epoch   9 Batch   94/269 - Train Accuracy: 0.8342, Validation Accuracy: 0.8381, Loss: 0.2507
Epoch   9 Batch   95/269 - Train Accuracy: 0.8396, Validation Accuracy: 0.8217, Loss: 0.2213
Epoch   9 Batch   96/269 - Train Accuracy: 0.8310, Validation Accuracy: 0.8365, Loss: 0.2434
Epoch   9 Batch   97/269 - Train Accuracy: 0.8378, Validation Accuracy: 0.8327, Loss: 0.2408
Epoch   9 Batch   98/269 - Train Accuracy: 0.8354, Validation Accuracy: 0.8287, Loss: 0.2364
Epoch   9 Batch   99/269 - Train Accuracy: 0.8060, Validation Accuracy: 0.8255, Loss: 0.2448
Epoch   9 Batch  100/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8380, Loss: 0.2309
Epoch   9 Batch  101/269 - Train Accuracy: 0.8102, Validation Accuracy: 0.8142, Loss: 0.2543
Epoch   9 Batch  102/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8354, Loss: 0.2437
Epoch   9 Batch  103/269 - Train Accuracy: 0.8402, Validation Accuracy: 0.8359, Loss: 0.2316
Epoch   9 Batch  104/269 - Train Accuracy: 0.8376, Validation Accuracy: 0.8366, Loss: 0.2288
Epoch   9 Batch  105/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8295, Loss: 0.2406
Epoch   9 Batch  106/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8254, Loss: 0.2265
Epoch   9 Batch  107/269 - Train Accuracy: 0.8301, Validation Accuracy: 0.8407, Loss: 0.2451
Epoch   9 Batch  108/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8396, Loss: 0.2264
Epoch   9 Batch  109/269 - Train Accuracy: 0.8220, Validation Accuracy: 0.8333, Loss: 0.2474
Epoch   9 Batch  110/269 - Train Accuracy: 0.8406, Validation Accuracy: 0.8342, Loss: 0.2248
Epoch   9 Batch  111/269 - Train Accuracy: 0.8394, Validation Accuracy: 0.8453, Loss: 0.2516
Epoch   9 Batch  112/269 - Train Accuracy: 0.8488, Validation Accuracy: 0.8420, Loss: 0.2289
Epoch   9 Batch  113/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8365, Loss: 0.2223
Epoch   9 Batch  114/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8327, Loss: 0.2255
Epoch   9 Batch  115/269 - Train Accuracy: 0.8246, Validation Accuracy: 0.8402, Loss: 0.2426
Epoch   9 Batch  116/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8427, Loss: 0.2296
Epoch   9 Batch  117/269 - Train Accuracy: 0.8268, Validation Accuracy: 0.8446, Loss: 0.2303
Epoch   9 Batch  118/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8356, Loss: 0.2133
Epoch   9 Batch  119/269 - Train Accuracy: 0.8366, Validation Accuracy: 0.8437, Loss: 0.2431
Epoch   9 Batch  120/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8456, Loss: 0.2307
Epoch   9 Batch  121/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8451, Loss: 0.2106
Epoch   9 Batch  122/269 - Train Accuracy: 0.8306, Validation Accuracy: 0.8389, Loss: 0.2221
Epoch   9 Batch  123/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8406, Loss: 0.2361
Epoch   9 Batch  124/269 - Train Accuracy: 0.8434, Validation Accuracy: 0.8417, Loss: 0.2129
Epoch   9 Batch  125/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8461, Loss: 0.2156
Epoch   9 Batch  126/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8456, Loss: 0.2294
Epoch   9 Batch  127/269 - Train Accuracy: 0.8405, Validation Accuracy: 0.8407, Loss: 0.2377
Epoch   9 Batch  128/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8361, Loss: 0.2280
Epoch   9 Batch  129/269 - Train Accuracy: 0.8460, Validation Accuracy: 0.8419, Loss: 0.2294
Epoch   9 Batch  130/269 - Train Accuracy: 0.8465, Validation Accuracy: 0.8383, Loss: 0.2366
Epoch   9 Batch  131/269 - Train Accuracy: 0.8364, Validation Accuracy: 0.8365, Loss: 0.2267
Epoch   9 Batch  132/269 - Train Accuracy: 0.8297, Validation Accuracy: 0.8441, Loss: 0.2385
Epoch   9 Batch  133/269 - Train Accuracy: 0.8577, Validation Accuracy: 0.8437, Loss: 0.2083
Epoch   9 Batch  134/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8456, Loss: 0.2371
Epoch   9 Batch  135/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8449, Loss: 0.2399
Epoch   9 Batch  136/269 - Train Accuracy: 0.8360, Validation Accuracy: 0.8475, Loss: 0.2455
Epoch   9 Batch  137/269 - Train Accuracy: 0.8300, Validation Accuracy: 0.8453, Loss: 0.2370
Epoch   9 Batch  138/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8349, Loss: 0.2311
Epoch   9 Batch  139/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8460, Loss: 0.2226
Epoch   9 Batch  140/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8483, Loss: 0.2364
Epoch   9 Batch  141/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8441, Loss: 0.2340
Epoch   9 Batch  142/269 - Train Accuracy: 0.8458, Validation Accuracy: 0.8387, Loss: 0.2243
Epoch   9 Batch  143/269 - Train Accuracy: 0.8463, Validation Accuracy: 0.8327, Loss: 0.2244
Epoch   9 Batch  144/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8420, Loss: 0.2183
Epoch   9 Batch  145/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8464, Loss: 0.2206
Epoch   9 Batch  146/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8420, Loss: 0.2182
Epoch   9 Batch  147/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8360, Loss: 0.2172
Epoch   9 Batch  148/269 - Train Accuracy: 0.8461, Validation Accuracy: 0.8460, Loss: 0.2372
Epoch   9 Batch  149/269 - Train Accuracy: 0.8295, Validation Accuracy: 0.8452, Loss: 0.2393
Epoch   9 Batch  150/269 - Train Accuracy: 0.8433, Validation Accuracy: 0.8393, Loss: 0.2255
Epoch   9 Batch  151/269 - Train Accuracy: 0.8437, Validation Accuracy: 0.8401, Loss: 0.2194
Epoch   9 Batch  152/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8427, Loss: 0.2308
Epoch   9 Batch  153/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8462, Loss: 0.2193
Epoch   9 Batch  154/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8444, Loss: 0.2234
Epoch   9 Batch  155/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8431, Loss: 0.2143
Epoch   9 Batch  156/269 - Train Accuracy: 0.8334, Validation Accuracy: 0.8365, Loss: 0.2273
Epoch   9 Batch  157/269 - Train Accuracy: 0.8330, Validation Accuracy: 0.8465, Loss: 0.2194
Epoch   9 Batch  158/269 - Train Accuracy: 0.8443, Validation Accuracy: 0.8466, Loss: 0.2199
Epoch   9 Batch  159/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8536, Loss: 0.2219
Epoch   9 Batch  160/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8371, Loss: 0.2222
Epoch   9 Batch  161/269 - Train Accuracy: 0.8443, Validation Accuracy: 0.8492, Loss: 0.2202
Epoch   9 Batch  162/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8523, Loss: 0.2229
Epoch   9 Batch  163/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8526, Loss: 0.2198
Epoch   9 Batch  164/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8445, Loss: 0.2208
Epoch   9 Batch  165/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8453, Loss: 0.2204
Epoch   9 Batch  166/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8485, Loss: 0.2161
Epoch   9 Batch  167/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8488, Loss: 0.2171
Epoch   9 Batch  168/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8439, Loss: 0.2294
Epoch   9 Batch  169/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8414, Loss: 0.2246
Epoch   9 Batch  170/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8435, Loss: 0.2211
Epoch   9 Batch  171/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8468, Loss: 0.2252
Epoch   9 Batch  172/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8477, Loss: 0.2368
Epoch   9 Batch  173/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8399, Loss: 0.2140
Epoch   9 Batch  174/269 - Train Accuracy: 0.8488, Validation Accuracy: 0.8482, Loss: 0.2198
Epoch   9 Batch  175/269 - Train Accuracy: 0.8450, Validation Accuracy: 0.8513, Loss: 0.2321
Epoch   9 Batch  176/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8511, Loss: 0.2289
Epoch   9 Batch  177/269 - Train Accuracy: 0.8482, Validation Accuracy: 0.8524, Loss: 0.2102
Epoch   9 Batch  178/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8464, Loss: 0.2241
Epoch   9 Batch  179/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8507, Loss: 0.2155
Epoch   9 Batch  180/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8541, Loss: 0.2083
Epoch   9 Batch  181/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8485, Loss: 0.2243
Epoch   9 Batch  182/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8412, Loss: 0.2177
Epoch   9 Batch  183/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8411, Loss: 0.1894
Epoch   9 Batch  184/269 - Train Accuracy: 0.8396, Validation Accuracy: 0.8445, Loss: 0.2217
Epoch   9 Batch  185/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8386, Loss: 0.2111
Epoch   9 Batch  186/269 - Train Accuracy: 0.8359, Validation Accuracy: 0.8369, Loss: 0.2159
Epoch   9 Batch  187/269 - Train Accuracy: 0.8425, Validation Accuracy: 0.8392, Loss: 0.2144
Epoch   9 Batch  188/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8375, Loss: 0.2076
Epoch   9 Batch  189/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8392, Loss: 0.2071
Epoch   9 Batch  190/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8404, Loss: 0.2050
Epoch   9 Batch  191/269 - Train Accuracy: 0.8453, Validation Accuracy: 0.8458, Loss: 0.2178
Epoch   9 Batch  192/269 - Train Accuracy: 0.8535, Validation Accuracy: 0.8562, Loss: 0.2244
Epoch   9 Batch  193/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8531, Loss: 0.2070
Epoch   9 Batch  194/269 - Train Accuracy: 0.8466, Validation Accuracy: 0.8556, Loss: 0.2199
Epoch   9 Batch  195/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8489, Loss: 0.2194
Epoch   9 Batch  196/269 - Train Accuracy: 0.8478, Validation Accuracy: 0.8549, Loss: 0.2085
Epoch   9 Batch  197/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8550, Loss: 0.2269
Epoch   9 Batch  198/269 - Train Accuracy: 0.8359, Validation Accuracy: 0.8517, Loss: 0.2234
Epoch   9 Batch  199/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8496, Loss: 0.2238
Epoch   9 Batch  200/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8481, Loss: 0.2220
Epoch   9 Batch  201/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8477, Loss: 0.2141
Epoch   9 Batch  202/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8430, Loss: 0.2175
Epoch   9 Batch  203/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8529, Loss: 0.2363
Epoch   9 Batch  204/269 - Train Accuracy: 0.8444, Validation Accuracy: 0.8593, Loss: 0.2333
Epoch   9 Batch  205/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8580, Loss: 0.2209
Epoch   9 Batch  206/269 - Train Accuracy: 0.8382, Validation Accuracy: 0.8503, Loss: 0.2304
Epoch   9 Batch  207/269 - Train Accuracy: 0.8437, Validation Accuracy: 0.8456, Loss: 0.2125
Epoch   9 Batch  208/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8446, Loss: 0.2221
Epoch   9 Batch  209/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8466, Loss: 0.2105
Epoch   9 Batch  210/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8494, Loss: 0.2140
Epoch   9 Batch  211/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8388, Loss: 0.2196
Epoch   9 Batch  212/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8454, Loss: 0.2194
Epoch   9 Batch  213/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8468, Loss: 0.2125
Epoch   9 Batch  214/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8519, Loss: 0.2193
Epoch   9 Batch  215/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8441, Loss: 0.2005
Epoch   9 Batch  216/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8550, Loss: 0.2426
Epoch   9 Batch  217/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8618, Loss: 0.2197
Epoch   9 Batch  218/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8565, Loss: 0.2197
Epoch   9 Batch  219/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8509, Loss: 0.2283
Epoch   9 Batch  220/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8473, Loss: 0.1987
Epoch   9 Batch  221/269 - Train Accuracy: 0.8644, Validation Accuracy: 0.8432, Loss: 0.2179
Epoch   9 Batch  222/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8538, Loss: 0.2047
Epoch   9 Batch  223/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8435, Loss: 0.2050
Epoch   9 Batch  224/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8441, Loss: 0.2258
Epoch   9 Batch  225/269 - Train Accuracy: 0.8488, Validation Accuracy: 0.8498, Loss: 0.2066
Epoch   9 Batch  226/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8471, Loss: 0.2120
Epoch   9 Batch  227/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8481, Loss: 0.2068
Epoch   9 Batch  228/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8477, Loss: 0.2124
Epoch   9 Batch  229/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8453, Loss: 0.2133
Epoch   9 Batch  230/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8548, Loss: 0.2141
Epoch   9 Batch  231/269 - Train Accuracy: 0.8466, Validation Accuracy: 0.8500, Loss: 0.2191
Epoch   9 Batch  232/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8567, Loss: 0.2223
Epoch   9 Batch  233/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8522, Loss: 0.2125
Epoch   9 Batch  234/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8523, Loss: 0.2089
Epoch   9 Batch  235/269 - Train Accuracy: 0.8606, Validation Accuracy: 0.8447, Loss: 0.1955
Epoch   9 Batch  236/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8574, Loss: 0.2078
Epoch   9 Batch  237/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8517, Loss: 0.2049
Epoch   9 Batch  238/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8517, Loss: 0.2134
Epoch   9 Batch  239/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8580, Loss: 0.2041
Epoch   9 Batch  240/269 - Train Accuracy: 0.8817, Validation Accuracy: 0.8593, Loss: 0.1907
Epoch   9 Batch  241/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8534, Loss: 0.2247
Epoch   9 Batch  242/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8495, Loss: 0.2031
Epoch   9 Batch  243/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8555, Loss: 0.1984
Epoch   9 Batch  244/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8552, Loss: 0.1989
Epoch   9 Batch  245/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8524, Loss: 0.2276
Epoch   9 Batch  246/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8518, Loss: 0.2108
Epoch   9 Batch  247/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8576, Loss: 0.2158
Epoch   9 Batch  248/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8497, Loss: 0.1976
Epoch   9 Batch  249/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8564, Loss: 0.1994
Epoch   9 Batch  250/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8595, Loss: 0.2026
Epoch   9 Batch  251/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8564, Loss: 0.1993
Epoch   9 Batch  252/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8542, Loss: 0.2051
Epoch   9 Batch  253/269 - Train Accuracy: 0.8407, Validation Accuracy: 0.8542, Loss: 0.2134
Epoch   9 Batch  254/269 - Train Accuracy: 0.8538, Validation Accuracy: 0.8494, Loss: 0.2041
Epoch   9 Batch  255/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8517, Loss: 0.2082
Epoch   9 Batch  256/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8557, Loss: 0.2089
Epoch   9 Batch  257/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8497, Loss: 0.2213
Epoch   9 Batch  258/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8487, Loss: 0.2178
Epoch   9 Batch  259/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8548, Loss: 0.2048
Epoch   9 Batch  260/269 - Train Accuracy: 0.8412, Validation Accuracy: 0.8581, Loss: 0.2230
Epoch   9 Batch  261/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8543, Loss: 0.2198
Epoch   9 Batch  262/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8597, Loss: 0.2084
Epoch   9 Batch  263/269 - Train Accuracy: 0.8503, Validation Accuracy: 0.8501, Loss: 0.2135
Epoch   9 Batch  264/269 - Train Accuracy: 0.8295, Validation Accuracy: 0.8542, Loss: 0.2213
Epoch   9 Batch  265/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8544, Loss: 0.2066
Epoch   9 Batch  266/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8575, Loss: 0.1962
Epoch   9 Batch  267/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8556, Loss: 0.2160
Epoch  10 Batch    1/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8610, Loss: 0.2053
Epoch  10 Batch    2/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8478, Loss: 0.2135
Epoch  10 Batch    3/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8449, Loss: 0.2051
Epoch  10 Batch    4/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8481, Loss: 0.2157
Epoch  10 Batch    5/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8538, Loss: 0.2063
Epoch  10 Batch    6/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8444, Loss: 0.1975
Epoch  10 Batch    7/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8433, Loss: 0.2001
Epoch  10 Batch    8/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8558, Loss: 0.2152
Epoch  10 Batch    9/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8602, Loss: 0.2145
Epoch  10 Batch   10/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8505, Loss: 0.2025
Epoch  10 Batch   11/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8526, Loss: 0.2156
Epoch  10 Batch   12/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8651, Loss: 0.2213
Epoch  10 Batch   13/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8620, Loss: 0.1874
Epoch  10 Batch   14/269 - Train Accuracy: 0.8468, Validation Accuracy: 0.8599, Loss: 0.2055
Epoch  10 Batch   15/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8674, Loss: 0.1932
Epoch  10 Batch   16/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8699, Loss: 0.2111
Epoch  10 Batch   17/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8654, Loss: 0.1938
Epoch  10 Batch   18/269 - Train Accuracy: 0.8530, Validation Accuracy: 0.8612, Loss: 0.2076
Epoch  10 Batch   19/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8548, Loss: 0.1851
Epoch  10 Batch   20/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8556, Loss: 0.2105
Epoch  10 Batch   21/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8548, Loss: 0.2291
Epoch  10 Batch   22/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8589, Loss: 0.1949
Epoch  10 Batch   23/269 - Train Accuracy: 0.8469, Validation Accuracy: 0.8567, Loss: 0.2069
Epoch  10 Batch   24/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8592, Loss: 0.2162
Epoch  10 Batch   25/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8607, Loss: 0.2220
Epoch  10 Batch   26/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8635, Loss: 0.1845
Epoch  10 Batch   27/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8662, Loss: 0.2015
Epoch  10 Batch   28/269 - Train Accuracy: 0.8266, Validation Accuracy: 0.8655, Loss: 0.2144
Epoch  10 Batch   29/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8693, Loss: 0.2117
Epoch  10 Batch   30/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8701, Loss: 0.2019
Epoch  10 Batch   31/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8659, Loss: 0.1878
Epoch  10 Batch   32/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8667, Loss: 0.1947
Epoch  10 Batch   33/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8703, Loss: 0.1951
Epoch  10 Batch   34/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8715, Loss: 0.1954
Epoch  10 Batch   35/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8667, Loss: 0.2129
Epoch  10 Batch   36/269 - Train Accuracy: 0.8365, Validation Accuracy: 0.8652, Loss: 0.2075
Epoch  10 Batch   37/269 - Train Accuracy: 0.8508, Validation Accuracy: 0.8572, Loss: 0.2061
Epoch  10 Batch   38/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8523, Loss: 0.1997
Epoch  10 Batch   39/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8608, Loss: 0.1959
Epoch  10 Batch   40/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8641, Loss: 0.2103
Epoch  10 Batch   41/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8635, Loss: 0.2111
Epoch  10 Batch   42/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8556, Loss: 0.1938
Epoch  10 Batch   43/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8651, Loss: 0.2147
Epoch  10 Batch   44/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8613, Loss: 0.2035
Epoch  10 Batch   45/269 - Train Accuracy: 0.8478, Validation Accuracy: 0.8443, Loss: 0.2104
Epoch  10 Batch   46/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8507, Loss: 0.2063
Epoch  10 Batch   47/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8583, Loss: 0.1868
Epoch  10 Batch   48/269 - Train Accuracy: 0.8785, Validation Accuracy: 0.8569, Loss: 0.1919
Epoch  10 Batch   49/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8611, Loss: 0.2059
Epoch  10 Batch   50/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8601, Loss: 0.2158
Epoch  10 Batch   51/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8453, Loss: 0.2037
Epoch  10 Batch   52/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8629, Loss: 0.1875
Epoch  10 Batch   53/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8670, Loss: 0.2176
Epoch  10 Batch   54/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8610, Loss: 0.2012
Epoch  10 Batch   55/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8439, Loss: 0.1963
Epoch  10 Batch   56/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8604, Loss: 0.2023
Epoch  10 Batch   57/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8633, Loss: 0.2111
Epoch  10 Batch   58/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8619, Loss: 0.2040
Epoch  10 Batch   59/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8596, Loss: 0.1843
Epoch  10 Batch   60/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8598, Loss: 0.1896
Epoch  10 Batch   61/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8669, Loss: 0.1833
Epoch  10 Batch   62/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8677, Loss: 0.1917
Epoch  10 Batch   63/269 - Train Accuracy: 0.8468, Validation Accuracy: 0.8648, Loss: 0.2104
Epoch  10 Batch   64/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8601, Loss: 0.1887
Epoch  10 Batch   65/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8730, Loss: 0.1976
Epoch  10 Batch   66/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8709, Loss: 0.1960
Epoch  10 Batch   67/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8660, Loss: 0.2032
Epoch  10 Batch   68/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8689, Loss: 0.2131
Epoch  10 Batch   69/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8667, Loss: 0.2255
Epoch  10 Batch   70/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8689, Loss: 0.2068
Epoch  10 Batch   71/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8695, Loss: 0.2098
Epoch  10 Batch   72/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8748, Loss: 0.2058
Epoch  10 Batch   73/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8643, Loss: 0.2071
Epoch  10 Batch   74/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8669, Loss: 0.1922
Epoch  10 Batch   75/269 - Train Accuracy: 0.8641, Validation Accuracy: 0.8617, Loss: 0.1999
Epoch  10 Batch   76/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8602, Loss: 0.2029
Epoch  10 Batch   77/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8597, Loss: 0.1969
Epoch  10 Batch   78/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8716, Loss: 0.1938
Epoch  10 Batch   79/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8659, Loss: 0.1996
Epoch  10 Batch   80/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8694, Loss: 0.1946
Epoch  10 Batch   81/269 - Train Accuracy: 0.8460, Validation Accuracy: 0.8694, Loss: 0.2130
Epoch  10 Batch   82/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.8675, Loss: 0.1815
Epoch  10 Batch   83/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8667, Loss: 0.2019
Epoch  10 Batch   84/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8665, Loss: 0.1896
Epoch  10 Batch   85/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8687, Loss: 0.1932
Epoch  10 Batch   86/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8661, Loss: 0.1934
Epoch  10 Batch   87/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8743, Loss: 0.2150
Epoch  10 Batch   88/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8682, Loss: 0.1978
Epoch  10 Batch   89/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8707, Loss: 0.1953
Epoch  10 Batch   90/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8590, Loss: 0.2070
Epoch  10 Batch   91/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8596, Loss: 0.1876
Epoch  10 Batch   92/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8734, Loss: 0.1858
Epoch  10 Batch   93/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8660, Loss: 0.1931
Epoch  10 Batch   94/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8605, Loss: 0.2093
Epoch  10 Batch   95/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8643, Loss: 0.1931
Epoch  10 Batch   96/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8630, Loss: 0.2022
Epoch  10 Batch   97/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8649, Loss: 0.1963
Epoch  10 Batch   98/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8676, Loss: 0.2006
Epoch  10 Batch   99/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8667, Loss: 0.1927
Epoch  10 Batch  100/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8666, Loss: 0.1911
Epoch  10 Batch  101/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8571, Loss: 0.2144
Epoch  10 Batch  102/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8663, Loss: 0.1981
Epoch  10 Batch  103/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.8674, Loss: 0.2074
Epoch  10 Batch  104/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8641, Loss: 0.1985
Epoch  10 Batch  105/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8574, Loss: 0.1925
Epoch  10 Batch  106/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8586, Loss: 0.1925
Epoch  10 Batch  107/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8633, Loss: 0.2002
Epoch  10 Batch  108/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8680, Loss: 0.1950
Epoch  10 Batch  109/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8755, Loss: 0.2097
Epoch  10 Batch  110/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8678, Loss: 0.1874
Epoch  10 Batch  111/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8682, Loss: 0.2123
Epoch  10 Batch  112/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8666, Loss: 0.1890
Epoch  10 Batch  113/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8657, Loss: 0.1937
Epoch  10 Batch  114/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8661, Loss: 0.1944
Epoch  10 Batch  115/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8644, Loss: 0.2027
Epoch  10 Batch  116/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8587, Loss: 0.2027
Epoch  10 Batch  117/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8627, Loss: 0.1972
Epoch  10 Batch  118/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8657, Loss: 0.1816
Epoch  10 Batch  119/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8620, Loss: 0.2118
Epoch  10 Batch  120/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8663, Loss: 0.1963
Epoch  10 Batch  121/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8667, Loss: 0.1893
Epoch  10 Batch  122/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8636, Loss: 0.1887
Epoch  10 Batch  123/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8684, Loss: 0.1995
Epoch  10 Batch  124/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8697, Loss: 0.1816
Epoch  10 Batch  125/269 - Train Accuracy: 0.8945, Validation Accuracy: 0.8700, Loss: 0.1822
Epoch  10 Batch  126/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8669, Loss: 0.1894
Epoch  10 Batch  127/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8666, Loss: 0.2013
Epoch  10 Batch  128/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8678, Loss: 0.1926
Epoch  10 Batch  129/269 - Train Accuracy: 0.8628, Validation Accuracy: 0.8586, Loss: 0.1884
Epoch  10 Batch  130/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8611, Loss: 0.1988
Epoch  10 Batch  131/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8612, Loss: 0.1933
Epoch  10 Batch  132/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8556, Loss: 0.2044
Epoch  10 Batch  133/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8667, Loss: 0.1888
Epoch  10 Batch  134/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8731, Loss: 0.1954
Epoch  10 Batch  135/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8630, Loss: 0.2104
Epoch  10 Batch  136/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8626, Loss: 0.2025
Epoch  10 Batch  137/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8688, Loss: 0.2106
Epoch  10 Batch  138/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8561, Loss: 0.1962
Epoch  10 Batch  139/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8618, Loss: 0.1892
Epoch  10 Batch  140/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8585, Loss: 0.1993
Epoch  10 Batch  141/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8701, Loss: 0.1964
Epoch  10 Batch  142/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8645, Loss: 0.1833
Epoch  10 Batch  143/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8650, Loss: 0.1960
Epoch  10 Batch  144/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8702, Loss: 0.1844
Epoch  10 Batch  145/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8659, Loss: 0.1915
Epoch  10 Batch  146/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8690, Loss: 0.1859
Epoch  10 Batch  147/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8706, Loss: 0.1956
Epoch  10 Batch  148/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8607, Loss: 0.1895
Epoch  10 Batch  149/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8716, Loss: 0.2058
Epoch  10 Batch  150/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8640, Loss: 0.1899
Epoch  10 Batch  151/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8708, Loss: 0.1860
Epoch  10 Batch  152/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8658, Loss: 0.1912
Epoch  10 Batch  153/269 - Train Accuracy: 0.8779, Validation Accuracy: 0.8689, Loss: 0.1826
Epoch  10 Batch  154/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8737, Loss: 0.1926
Epoch  10 Batch  155/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8752, Loss: 0.1833
Epoch  10 Batch  156/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8714, Loss: 0.1951
Epoch  10 Batch  157/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8699, Loss: 0.1922
Epoch  10 Batch  158/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8667, Loss: 0.1878
Epoch  10 Batch  159/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8523, Loss: 0.1962
Epoch  10 Batch  160/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8608, Loss: 0.1863
Epoch  10 Batch  161/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8678, Loss: 0.1890
Epoch  10 Batch  162/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8603, Loss: 0.1874
Epoch  10 Batch  163/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8622, Loss: 0.1904
Epoch  10 Batch  164/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8667, Loss: 0.1935
Epoch  10 Batch  165/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8691, Loss: 0.1840
Epoch  10 Batch  166/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8700, Loss: 0.1842
Epoch  10 Batch  167/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8693, Loss: 0.1883
Epoch  10 Batch  168/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8746, Loss: 0.1996
Epoch  10 Batch  169/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8755, Loss: 0.1873
Epoch  10 Batch  170/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8661, Loss: 0.1833
Epoch  10 Batch  171/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8719, Loss: 0.1887
Epoch  10 Batch  172/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8687, Loss: 0.2042
Epoch  10 Batch  173/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8738, Loss: 0.1777
Epoch  10 Batch  174/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8808, Loss: 0.1851
Epoch  10 Batch  175/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8787, Loss: 0.2057
Epoch  10 Batch  176/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8704, Loss: 0.1971
Epoch  10 Batch  177/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8722, Loss: 0.1854
Epoch  10 Batch  178/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8726, Loss: 0.1954
Epoch  10 Batch  179/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8735, Loss: 0.1832
Epoch  10 Batch  180/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8747, Loss: 0.1813
Epoch  10 Batch  181/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8730, Loss: 0.1922
Epoch  10 Batch  182/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8691, Loss: 0.1865
Epoch  10 Batch  183/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.8716, Loss: 0.1603
Epoch  10 Batch  184/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8698, Loss: 0.1892
Epoch  10 Batch  185/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8612, Loss: 0.1850
Epoch  10 Batch  186/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8714, Loss: 0.1839
Epoch  10 Batch  187/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8698, Loss: 0.1815
Epoch  10 Batch  188/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8592, Loss: 0.1770
Epoch  10 Batch  189/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8653, Loss: 0.1777
Epoch  10 Batch  190/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8715, Loss: 0.1761
Epoch  10 Batch  191/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8688, Loss: 0.1821
Epoch  10 Batch  192/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8707, Loss: 0.1860
Epoch  10 Batch  193/269 - Train Accuracy: 0.8940, Validation Accuracy: 0.8738, Loss: 0.1782
Epoch  10 Batch  194/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8752, Loss: 0.1923
Epoch  10 Batch  195/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8715, Loss: 0.1813
Epoch  10 Batch  196/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.8740, Loss: 0.1781
Epoch  10 Batch  197/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8665, Loss: 0.1940
Epoch  10 Batch  198/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8714, Loss: 0.1937
Epoch  10 Batch  199/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8704, Loss: 0.1963
Epoch  10 Batch  200/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8786, Loss: 0.1907
Epoch  10 Batch  201/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8784, Loss: 0.1858
Epoch  10 Batch  202/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8799, Loss: 0.1784
Epoch  10 Batch  203/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8748, Loss: 0.2047
Epoch  10 Batch  204/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8740, Loss: 0.1936
Epoch  10 Batch  205/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8762, Loss: 0.1805
Epoch  10 Batch  206/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8715, Loss: 0.1934
Epoch  10 Batch  207/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8704, Loss: 0.1877
Epoch  10 Batch  208/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8706, Loss: 0.1920
Epoch  10 Batch  209/269 - Train Accuracy: 0.8880, Validation Accuracy: 0.8678, Loss: 0.1757
Epoch  10 Batch  210/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8683, Loss: 0.1806
Epoch  10 Batch  211/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8674, Loss: 0.1898
Epoch  10 Batch  212/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8660, Loss: 0.1907
Epoch  10 Batch  213/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8669, Loss: 0.1800
Epoch  10 Batch  214/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8703, Loss: 0.1903
Epoch  10 Batch  215/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8719, Loss: 0.1704
Epoch  10 Batch  216/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8749, Loss: 0.2070
Epoch  10 Batch  217/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8734, Loss: 0.1893
Epoch  10 Batch  218/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.8774, Loss: 0.1865
Epoch  10 Batch  219/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8799, Loss: 0.1921
Epoch  10 Batch  220/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.8757, Loss: 0.1743
Epoch  10 Batch  221/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8857, Loss: 0.1876
Epoch  10 Batch  222/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.8781, Loss: 0.1766
Epoch  10 Batch  223/269 - Train Accuracy: 0.8798, Validation Accuracy: 0.8794, Loss: 0.1787
Epoch  10 Batch  224/269 - Train Accuracy: 0.8798, Validation Accuracy: 0.8765, Loss: 0.1931
Epoch  10 Batch  225/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8770, Loss: 0.1775
Epoch  10 Batch  226/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8761, Loss: 0.1833
Epoch  10 Batch  227/269 - Train Accuracy: 0.8957, Validation Accuracy: 0.8642, Loss: 0.1771
Epoch  10 Batch  228/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8735, Loss: 0.1866
Epoch  10 Batch  229/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8781, Loss: 0.1827
Epoch  10 Batch  230/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8635, Loss: 0.1797
Epoch  10 Batch  231/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8740, Loss: 0.1910
Epoch  10 Batch  232/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8795, Loss: 0.1839
Epoch  10 Batch  233/269 - Train Accuracy: 0.8859, Validation Accuracy: 0.8760, Loss: 0.1928
Epoch  10 Batch  234/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8754, Loss: 0.1783
Epoch  10 Batch  235/269 - Train Accuracy: 0.8963, Validation Accuracy: 0.8814, Loss: 0.1731
Epoch  10 Batch  236/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8794, Loss: 0.1779
Epoch  10 Batch  237/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8882, Loss: 0.1785
Epoch  10 Batch  238/269 - Train Accuracy: 0.8944, Validation Accuracy: 0.8835, Loss: 0.1815
Epoch  10 Batch  239/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8795, Loss: 0.1812
Epoch  10 Batch  240/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8762, Loss: 0.1696
Epoch  10 Batch  241/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8686, Loss: 0.1915
Epoch  10 Batch  242/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8654, Loss: 0.1789
Epoch  10 Batch  243/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8672, Loss: 0.1726
Epoch  10 Batch  244/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8714, Loss: 0.1772
Epoch  10 Batch  245/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8802, Loss: 0.1941
Epoch  10 Batch  246/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8710, Loss: 0.1786
Epoch  10 Batch  247/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8749, Loss: 0.1822
Epoch  10 Batch  248/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8748, Loss: 0.1757
Epoch  10 Batch  249/269 - Train Accuracy: 0.8866, Validation Accuracy: 0.8751, Loss: 0.1675
Epoch  10 Batch  250/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.8809, Loss: 0.1797
Epoch  10 Batch  251/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.8751, Loss: 0.1746
Epoch  10 Batch  252/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8801, Loss: 0.1721
Epoch  10 Batch  253/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8676, Loss: 0.1847
Epoch  10 Batch  254/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8620, Loss: 0.1796
Epoch  10 Batch  255/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8640, Loss: 0.1833
Epoch  10 Batch  256/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8682, Loss: 0.1832
Epoch  10 Batch  257/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8737, Loss: 0.1922
Epoch  10 Batch  258/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.8702, Loss: 0.1884
Epoch  10 Batch  259/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.8801, Loss: 0.1824
Epoch  10 Batch  260/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8740, Loss: 0.1920
Epoch  10 Batch  261/269 - Train Accuracy: 0.8798, Validation Accuracy: 0.8786, Loss: 0.1930
Epoch  10 Batch  262/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.8755, Loss: 0.1830
Epoch  10 Batch  263/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8823, Loss: 0.1859
Epoch  10 Batch  264/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8807, Loss: 0.1872
Epoch  10 Batch  265/269 - Train Accuracy: 0.8929, Validation Accuracy: 0.8754, Loss: 0.1848
Epoch  10 Batch  266/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8724, Loss: 0.1722
Epoch  10 Batch  267/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8749, Loss: 0.1840
Epoch  11 Batch    1/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8630, Loss: 0.1765
Epoch  11 Batch    2/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.8710, Loss: 0.1897
Epoch  11 Batch    3/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8749, Loss: 0.1756
Epoch  11 Batch    4/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8669, Loss: 0.1948
Epoch  11 Batch    5/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8742, Loss: 0.1912
Epoch  11 Batch    6/269 - Train Accuracy: 0.8984, Validation Accuracy: 0.8758, Loss: 0.1733
Epoch  11 Batch    7/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8645, Loss: 0.1715
Epoch  11 Batch    8/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8731, Loss: 0.1778
Epoch  11 Batch    9/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8818, Loss: 0.1849
Epoch  11 Batch   10/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8828, Loss: 0.1823
Epoch  11 Batch   11/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8760, Loss: 0.1840
Epoch  11 Batch   12/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8766, Loss: 0.1921
Epoch  11 Batch   13/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8711, Loss: 0.1617
Epoch  11 Batch   14/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8734, Loss: 0.1784
Epoch  11 Batch   15/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8798, Loss: 0.1644
Epoch  11 Batch   16/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8849, Loss: 0.1947
Epoch  11 Batch   17/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8803, Loss: 0.1687
Epoch  11 Batch   18/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8849, Loss: 0.1812
Epoch  11 Batch   19/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.8860, Loss: 0.1654
Epoch  11 Batch   20/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.8845, Loss: 0.1795
Epoch  11 Batch   21/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8737, Loss: 0.1945
Epoch  11 Batch   22/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8736, Loss: 0.1699
Epoch  11 Batch   23/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8837, Loss: 0.1835
Epoch  11 Batch   24/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8833, Loss: 0.1793
Epoch  11 Batch   25/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8764, Loss: 0.1920
Epoch  11 Batch   26/269 - Train Accuracy: 0.8886, Validation Accuracy: 0.8817, Loss: 0.1611
Epoch  11 Batch   27/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8797, Loss: 0.1724
Epoch  11 Batch   28/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8715, Loss: 0.1890
Epoch  11 Batch   29/269 - Train Accuracy: 0.8955, Validation Accuracy: 0.8762, Loss: 0.1797
Epoch  11 Batch   30/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8769, Loss: 0.1758
Epoch  11 Batch   31/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8878, Loss: 0.1698
Epoch  11 Batch   32/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8725, Loss: 0.1754
Epoch  11 Batch   33/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8676, Loss: 0.1602
Epoch  11 Batch   34/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8824, Loss: 0.1746
Epoch  11 Batch   35/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8858, Loss: 0.1850
Epoch  11 Batch   36/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8871, Loss: 0.1886
Epoch  11 Batch   37/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8848, Loss: 0.1723
Epoch  11 Batch   38/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8774, Loss: 0.1798
Epoch  11 Batch   39/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8767, Loss: 0.1730
Epoch  11 Batch   40/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8835, Loss: 0.1868
Epoch  11 Batch   41/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8850, Loss: 0.1837
Epoch  11 Batch   42/269 - Train Accuracy: 0.8874, Validation Accuracy: 0.8687, Loss: 0.1682
Epoch  11 Batch   43/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8866, Loss: 0.1889
Epoch  11 Batch   44/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8875, Loss: 0.1757
Epoch  11 Batch   45/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8787, Loss: 0.1777
Epoch  11 Batch   46/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8872, Loss: 0.1799
Epoch  11 Batch   47/269 - Train Accuracy: 0.8989, Validation Accuracy: 0.8848, Loss: 0.1568
Epoch  11 Batch   48/269 - Train Accuracy: 0.9010, Validation Accuracy: 0.8808, Loss: 0.1700
Epoch  11 Batch   49/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8839, Loss: 0.1744
Epoch  11 Batch   50/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8788, Loss: 0.1850
Epoch  11 Batch   51/269 - Train Accuracy: 0.8888, Validation Accuracy: 0.8777, Loss: 0.1762
Epoch  11 Batch   52/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8687, Loss: 0.1584
Epoch  11 Batch   53/269 - Train Accuracy: 0.8833, Validation Accuracy: 0.8782, Loss: 0.1909
Epoch  11 Batch   54/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8858, Loss: 0.1664
Epoch  11 Batch   55/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8712, Loss: 0.1731
Epoch  11 Batch   56/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8733, Loss: 0.1709
Epoch  11 Batch   57/269 - Train Accuracy: 0.8926, Validation Accuracy: 0.8743, Loss: 0.1828
Epoch  11 Batch   58/269 - Train Accuracy: 0.8881, Validation Accuracy: 0.8788, Loss: 0.1694
Epoch  11 Batch   59/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.8868, Loss: 0.1510
Epoch  11 Batch   60/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8882, Loss: 0.1647
Epoch  11 Batch   61/269 - Train Accuracy: 0.8933, Validation Accuracy: 0.8884, Loss: 0.1594
Epoch  11 Batch   62/269 - Train Accuracy: 0.8871, Validation Accuracy: 0.8827, Loss: 0.1715
Epoch  11 Batch   63/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8916, Loss: 0.1826
Epoch  11 Batch   64/269 - Train Accuracy: 0.8976, Validation Accuracy: 0.8922, Loss: 0.1681
Epoch  11 Batch   65/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8878, Loss: 0.1692
Epoch  11 Batch   66/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8841, Loss: 0.1674
Epoch  11 Batch   67/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.8882, Loss: 0.1792
Epoch  11 Batch   68/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8839, Loss: 0.1869
Epoch  11 Batch   69/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8857, Loss: 0.1911
Epoch  11 Batch   70/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8897, Loss: 0.1713
Epoch  11 Batch   71/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8839, Loss: 0.1812
Epoch  11 Batch   72/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8884, Loss: 0.1742
Epoch  11 Batch   73/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8854, Loss: 0.1845
Epoch  11 Batch   74/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.8713, Loss: 0.1622
Epoch  11 Batch   75/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.8743, Loss: 0.1694
Epoch  11 Batch   76/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8808, Loss: 0.1703
Epoch  11 Batch   77/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8802, Loss: 0.1686
Epoch  11 Batch   78/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.8813, Loss: 0.1650
Epoch  11 Batch   79/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8818, Loss: 0.1675
Epoch  11 Batch   80/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8800, Loss: 0.1705
Epoch  11 Batch   81/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8873, Loss: 0.1790
Epoch  11 Batch   82/269 - Train Accuracy: 0.9087, Validation Accuracy: 0.8843, Loss: 0.1547
Epoch  11 Batch   83/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8865, Loss: 0.1773
Epoch  11 Batch   84/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.8778, Loss: 0.1697
Epoch  11 Batch   85/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.8812, Loss: 0.1675
Epoch  11 Batch   86/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8882, Loss: 0.1613
Epoch  11 Batch   87/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8833, Loss: 0.1868
Epoch  11 Batch   88/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8805, Loss: 0.1835
Epoch  11 Batch   89/269 - Train Accuracy: 0.8987, Validation Accuracy: 0.8859, Loss: 0.1734
Epoch  11 Batch   90/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8784, Loss: 0.1809
Epoch  11 Batch   91/269 - Train Accuracy: 0.8939, Validation Accuracy: 0.8656, Loss: 0.1626
Epoch  11 Batch   92/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8738, Loss: 0.1650
Epoch  11 Batch   93/269 - Train Accuracy: 0.8884, Validation Accuracy: 0.8844, Loss: 0.1631
Epoch  11 Batch   94/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8743, Loss: 0.1875
Epoch  11 Batch   95/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.8688, Loss: 0.1649
Epoch  11 Batch   96/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8804, Loss: 0.1728
Epoch  11 Batch   97/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8809, Loss: 0.1681
Epoch  11 Batch   98/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8674, Loss: 0.1718
Epoch  11 Batch   99/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8779, Loss: 0.1743
Epoch  11 Batch  100/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.8864, Loss: 0.1698
Epoch  11 Batch  101/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8788, Loss: 0.1944
Epoch  11 Batch  102/269 - Train Accuracy: 0.8801, Validation Accuracy: 0.8782, Loss: 0.1668
Epoch  11 Batch  103/269 - Train Accuracy: 0.8978, Validation Accuracy: 0.8860, Loss: 0.1689
Epoch  11 Batch  104/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.8817, Loss: 0.1744
Epoch  11 Batch  105/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8835, Loss: 0.1715
Epoch  11 Batch  106/269 - Train Accuracy: 0.8957, Validation Accuracy: 0.8832, Loss: 0.1686
Epoch  11 Batch  107/269 - Train Accuracy: 0.8971, Validation Accuracy: 0.8883, Loss: 0.1718
Epoch  11 Batch  108/269 - Train Accuracy: 0.8963, Validation Accuracy: 0.8859, Loss: 0.1689
Epoch  11 Batch  109/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8760, Loss: 0.1739
Epoch  11 Batch  110/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8739, Loss: 0.1611
Epoch  11 Batch  111/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8760, Loss: 0.1817
Epoch  11 Batch  112/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.8798, Loss: 0.1717
Epoch  11 Batch  113/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8788, Loss: 0.1660
Epoch  11 Batch  114/269 - Train Accuracy: 0.8999, Validation Accuracy: 0.8796, Loss: 0.1676
Epoch  11 Batch  115/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8738, Loss: 0.1668
Epoch  11 Batch  116/269 - Train Accuracy: 0.8992, Validation Accuracy: 0.8759, Loss: 0.1710
Epoch  11 Batch  117/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8830, Loss: 0.1653
Epoch  11 Batch  118/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.8864, Loss: 0.1518
Epoch  11 Batch  119/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8859, Loss: 0.1841
Epoch  11 Batch  120/269 - Train Accuracy: 0.8871, Validation Accuracy: 0.8742, Loss: 0.1705
Epoch  11 Batch  121/269 - Train Accuracy: 0.8848, Validation Accuracy: 0.8847, Loss: 0.1596
Epoch  11 Batch  122/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8855, Loss: 0.1614
Epoch  11 Batch  123/269 - Train Accuracy: 0.8812, Validation Accuracy: 0.8809, Loss: 0.1776
Epoch  11 Batch  124/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8722, Loss: 0.1586
Epoch  11 Batch  125/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.8841, Loss: 0.1618
Epoch  11 Batch  126/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8833, Loss: 0.1642
Epoch  11 Batch  127/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.8817, Loss: 0.1816
Epoch  11 Batch  128/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8667, Loss: 0.1662
Epoch  11 Batch  129/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8689, Loss: 0.1659
Epoch  11 Batch  130/269 - Train Accuracy: 0.8968, Validation Accuracy: 0.8860, Loss: 0.1727
Epoch  11 Batch  131/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8893, Loss: 0.1689
Epoch  11 Batch  132/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8778, Loss: 0.1719
Epoch  11 Batch  133/269 - Train Accuracy: 0.8973, Validation Accuracy: 0.8857, Loss: 0.1586
Epoch  11 Batch  134/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8846, Loss: 0.1679
Epoch  11 Batch  135/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.8886, Loss: 0.1721
Epoch  11 Batch  136/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8837, Loss: 0.1767
Epoch  11 Batch  137/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8783, Loss: 0.1848
Epoch  11 Batch  138/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8771, Loss: 0.1616
Epoch  11 Batch  139/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8794, Loss: 0.1597
Epoch  11 Batch  140/269 - Train Accuracy: 0.8882, Validation Accuracy: 0.8741, Loss: 0.1762
Epoch  11 Batch  141/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8750, Loss: 0.1735
Epoch  11 Batch  142/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8879, Loss: 0.1582
Epoch  11 Batch  143/269 - Train Accuracy: 0.8933, Validation Accuracy: 0.8857, Loss: 0.1589
Epoch  11 Batch  144/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.8841, Loss: 0.1542
Epoch  11 Batch  145/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.8878, Loss: 0.1607
Epoch  11 Batch  146/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8865, Loss: 0.1585
Epoch  11 Batch  147/269 - Train Accuracy: 0.8905, Validation Accuracy: 0.8927, Loss: 0.1605
Epoch  11 Batch  148/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8887, Loss: 0.1707
Epoch  11 Batch  149/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8801, Loss: 0.1728
Epoch  11 Batch  150/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8862, Loss: 0.1686
Epoch  11 Batch  151/269 - Train Accuracy: 0.8881, Validation Accuracy: 0.8835, Loss: 0.1654
Epoch  11 Batch  152/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.8938, Loss: 0.1672
Epoch  11 Batch  153/269 - Train Accuracy: 0.8962, Validation Accuracy: 0.8896, Loss: 0.1605
Epoch  11 Batch  154/269 - Train Accuracy: 0.8999, Validation Accuracy: 0.8861, Loss: 0.1654
Epoch  11 Batch  155/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8848, Loss: 0.1531
Epoch  11 Batch  156/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8877, Loss: 0.1672
Epoch  11 Batch  157/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8837, Loss: 0.1560
Epoch  11 Batch  158/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8858, Loss: 0.1621
Epoch  11 Batch  159/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8926, Loss: 0.1651
Epoch  11 Batch  160/269 - Train Accuracy: 0.9010, Validation Accuracy: 0.8956, Loss: 0.1628
Epoch  11 Batch  161/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.8932, Loss: 0.1604
Epoch  11 Batch  162/269 - Train Accuracy: 0.8949, Validation Accuracy: 0.8911, Loss: 0.1565
Epoch  11 Batch  163/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8946, Loss: 0.1687
Epoch  11 Batch  164/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.8920, Loss: 0.1631
Epoch  11 Batch  165/269 - Train Accuracy: 0.8958, Validation Accuracy: 0.8863, Loss: 0.1637
Epoch  11 Batch  166/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.8850, Loss: 0.1591
Epoch  11 Batch  167/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.8909, Loss: 0.1633
Epoch  11 Batch  168/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8875, Loss: 0.1679
Epoch  11 Batch  169/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8924, Loss: 0.1674
Epoch  11 Batch  170/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8866, Loss: 0.1599
Epoch  11 Batch  171/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.8859, Loss: 0.1652
Epoch  11 Batch  172/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8811, Loss: 0.1750
Epoch  11 Batch  173/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8779, Loss: 0.1569
Epoch  11 Batch  174/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8804, Loss: 0.1619
Epoch  11 Batch  175/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8849, Loss: 0.1858
Epoch  11 Batch  176/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8896, Loss: 0.1782
Epoch  11 Batch  177/269 - Train Accuracy: 0.8958, Validation Accuracy: 0.8809, Loss: 0.1552
Epoch  11 Batch  178/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.8881, Loss: 0.1619
Epoch  11 Batch  179/269 - Train Accuracy: 0.8929, Validation Accuracy: 0.8934, Loss: 0.1609
Epoch  11 Batch  180/269 - Train Accuracy: 0.8974, Validation Accuracy: 0.8933, Loss: 0.1579
Epoch  11 Batch  181/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8847, Loss: 0.1690
Epoch  11 Batch  182/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8840, Loss: 0.1638
Epoch  11 Batch  183/269 - Train Accuracy: 0.9028, Validation Accuracy: 0.8823, Loss: 0.1424
Epoch  11 Batch  184/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8836, Loss: 0.1693
Epoch  11 Batch  185/269 - Train Accuracy: 0.8973, Validation Accuracy: 0.8718, Loss: 0.1585
Epoch  11 Batch  186/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.8785, Loss: 0.1624
Epoch  11 Batch  187/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.8923, Loss: 0.1551
Epoch  11 Batch  188/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.8849, Loss: 0.1529
Epoch  11 Batch  189/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8761, Loss: 0.1543
Epoch  11 Batch  190/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.8940, Loss: 0.1554
Epoch  11 Batch  191/269 - Train Accuracy: 0.8785, Validation Accuracy: 0.8896, Loss: 0.1599
Epoch  11 Batch  192/269 - Train Accuracy: 0.8928, Validation Accuracy: 0.8932, Loss: 0.1652
Epoch  11 Batch  193/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.8912, Loss: 0.1533
Epoch  11 Batch  194/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8898, Loss: 0.1666
Epoch  11 Batch  195/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8944, Loss: 0.1578
Epoch  11 Batch  196/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.8981, Loss: 0.1528
Epoch  11 Batch  197/269 - Train Accuracy: 0.8929, Validation Accuracy: 0.8848, Loss: 0.1636
Epoch  11 Batch  198/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8778, Loss: 0.1689
Epoch  11 Batch  199/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.8746, Loss: 0.1697
Epoch  11 Batch  200/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8909, Loss: 0.1598
Epoch  11 Batch  201/269 - Train Accuracy: 0.9007, Validation Accuracy: 0.8945, Loss: 0.1644
Epoch  11 Batch  202/269 - Train Accuracy: 0.8871, Validation Accuracy: 0.8980, Loss: 0.1631
Epoch  11 Batch  203/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8858, Loss: 0.1719
Epoch  11 Batch  204/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8872, Loss: 0.1660
Epoch  11 Batch  205/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9010, Loss: 0.1636
Epoch  11 Batch  206/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8930, Loss: 0.1685
Epoch  11 Batch  207/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.8879, Loss: 0.1545
Epoch  11 Batch  208/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8950, Loss: 0.1613
Epoch  11 Batch  209/269 - Train Accuracy: 0.9072, Validation Accuracy: 0.8960, Loss: 0.1491
Epoch  11 Batch  210/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8944, Loss: 0.1543
Epoch  11 Batch  211/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.8893, Loss: 0.1632
Epoch  11 Batch  212/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8786, Loss: 0.1632
Epoch  11 Batch  213/269 - Train Accuracy: 0.8881, Validation Accuracy: 0.8827, Loss: 0.1555
Epoch  11 Batch  214/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8910, Loss: 0.1643
Epoch  11 Batch  215/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.8914, Loss: 0.1513
Epoch  11 Batch  216/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8793, Loss: 0.1725
Epoch  11 Batch  217/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8920, Loss: 0.1699
Epoch  11 Batch  218/269 - Train Accuracy: 0.9030, Validation Accuracy: 0.9026, Loss: 0.1578
Epoch  11 Batch  219/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.8991, Loss: 0.1656
Epoch  11 Batch  220/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.8939, Loss: 0.1502
Epoch  11 Batch  221/269 - Train Accuracy: 0.8975, Validation Accuracy: 0.8913, Loss: 0.1683
Epoch  11 Batch  222/269 - Train Accuracy: 0.9124, Validation Accuracy: 0.8940, Loss: 0.1511
Epoch  11 Batch  223/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8975, Loss: 0.1551
Epoch  11 Batch  224/269 - Train Accuracy: 0.8961, Validation Accuracy: 0.8993, Loss: 0.1695
Epoch  11 Batch  225/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8966, Loss: 0.1512
Epoch  11 Batch  226/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8866, Loss: 0.1607
Epoch  11 Batch  227/269 - Train Accuracy: 0.9059, Validation Accuracy: 0.8801, Loss: 0.1550
Epoch  11 Batch  228/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8926, Loss: 0.1594
Epoch  11 Batch  229/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8958, Loss: 0.1520
Epoch  11 Batch  230/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8813, Loss: 0.1623
Epoch  11 Batch  231/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8779, Loss: 0.1634
Epoch  11 Batch  232/269 - Train Accuracy: 0.8871, Validation Accuracy: 0.8920, Loss: 0.1662
Epoch  11 Batch  233/269 - Train Accuracy: 0.9068, Validation Accuracy: 0.8917, Loss: 0.1597
Epoch  11 Batch  234/269 - Train Accuracy: 0.8898, Validation Accuracy: 0.8786, Loss: 0.1572
Epoch  11 Batch  235/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8780, Loss: 0.1417
Epoch  11 Batch  236/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8950, Loss: 0.1562
Epoch  11 Batch  237/269 - Train Accuracy: 0.8975, Validation Accuracy: 0.8886, Loss: 0.1537
Epoch  11 Batch  238/269 - Train Accuracy: 0.9066, Validation Accuracy: 0.8918, Loss: 0.1561
Epoch  11 Batch  239/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8964, Loss: 0.1564
Epoch  11 Batch  240/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.8980, Loss: 0.1421
Epoch  11 Batch  241/269 - Train Accuracy: 0.8900, Validation Accuracy: 0.9005, Loss: 0.1714
Epoch  11 Batch  242/269 - Train Accuracy: 0.9046, Validation Accuracy: 0.8887, Loss: 0.1494
Epoch  11 Batch  243/269 - Train Accuracy: 0.8973, Validation Accuracy: 0.8833, Loss: 0.1471
Epoch  11 Batch  244/269 - Train Accuracy: 0.8920, Validation Accuracy: 0.8896, Loss: 0.1534
Epoch  11 Batch  245/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8928, Loss: 0.1659
Epoch  11 Batch  246/269 - Train Accuracy: 0.8910, Validation Accuracy: 0.8967, Loss: 0.1572
Epoch  11 Batch  247/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.9038, Loss: 0.1585
Epoch  11 Batch  248/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.8991, Loss: 0.1504
Epoch  11 Batch  249/269 - Train Accuracy: 0.8942, Validation Accuracy: 0.8871, Loss: 0.1455
Epoch  11 Batch  250/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.8949, Loss: 0.1571
Epoch  11 Batch  251/269 - Train Accuracy: 0.9078, Validation Accuracy: 0.9009, Loss: 0.1568
Epoch  11 Batch  252/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.8960, Loss: 0.1499
Epoch  11 Batch  253/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8820, Loss: 0.1566
Epoch  11 Batch  254/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8863, Loss: 0.1537
Epoch  11 Batch  255/269 - Train Accuracy: 0.9013, Validation Accuracy: 0.8972, Loss: 0.1547
Epoch  11 Batch  256/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.9092, Loss: 0.1530
Epoch  11 Batch  257/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.9055, Loss: 0.1594
Epoch  11 Batch  258/269 - Train Accuracy: 0.8937, Validation Accuracy: 0.8936, Loss: 0.1603
Epoch  11 Batch  259/269 - Train Accuracy: 0.8927, Validation Accuracy: 0.8947, Loss: 0.1534
Epoch  11 Batch  260/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.9031, Loss: 0.1678
Epoch  11 Batch  261/269 - Train Accuracy: 0.8931, Validation Accuracy: 0.9084, Loss: 0.1622
Epoch  11 Batch  262/269 - Train Accuracy: 0.8980, Validation Accuracy: 0.9016, Loss: 0.1657
Epoch  11 Batch  263/269 - Train Accuracy: 0.8899, Validation Accuracy: 0.8938, Loss: 0.1576
Epoch  11 Batch  264/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.9018, Loss: 0.1693
Epoch  11 Batch  265/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.8944, Loss: 0.1534
Epoch  11 Batch  266/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.8981, Loss: 0.1523
Epoch  11 Batch  267/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8960, Loss: 0.1591
Epoch  12 Batch    1/269 - Train Accuracy: 0.8970, Validation Accuracy: 0.8957, Loss: 0.1565
Epoch  12 Batch    2/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.9007, Loss: 0.1646
Epoch  12 Batch    3/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.8936, Loss: 0.1498
Epoch  12 Batch    4/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8807, Loss: 0.1610
Epoch  12 Batch    5/269 - Train Accuracy: 0.8896, Validation Accuracy: 0.8896, Loss: 0.1629
Epoch  12 Batch    6/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.8956, Loss: 0.1461
Epoch  12 Batch    7/269 - Train Accuracy: 0.8961, Validation Accuracy: 0.8958, Loss: 0.1485
Epoch  12 Batch    8/269 - Train Accuracy: 0.9176, Validation Accuracy: 0.9032, Loss: 0.1607
Epoch  12 Batch    9/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9080, Loss: 0.1608
Epoch  12 Batch   10/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.9055, Loss: 0.1480
Epoch  12 Batch   11/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.9014, Loss: 0.1626
Epoch  12 Batch   12/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.9024, Loss: 0.1654
Epoch  12 Batch   13/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.8962, Loss: 0.1381
Epoch  12 Batch   14/269 - Train Accuracy: 0.8866, Validation Accuracy: 0.8849, Loss: 0.1545
Epoch  12 Batch   15/269 - Train Accuracy: 0.8995, Validation Accuracy: 0.9011, Loss: 0.1416
Epoch  12 Batch   16/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8960, Loss: 0.1558
Epoch  12 Batch   17/269 - Train Accuracy: 0.8958, Validation Accuracy: 0.8996, Loss: 0.1465
Epoch  12 Batch   18/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8927, Loss: 0.1605
Epoch  12 Batch   19/269 - Train Accuracy: 0.9034, Validation Accuracy: 0.8987, Loss: 0.1348
Epoch  12 Batch   20/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.8935, Loss: 0.1561
Epoch  12 Batch   21/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8983, Loss: 0.1649
Epoch  12 Batch   22/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.8995, Loss: 0.1440
Epoch  12 Batch   23/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.9039, Loss: 0.1552
Epoch  12 Batch   24/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.9001, Loss: 0.1467
Epoch  12 Batch   25/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.9003, Loss: 0.1627
Epoch  12 Batch   26/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.8967, Loss: 0.1391
Epoch  12 Batch   27/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.9050, Loss: 0.1511
Epoch  12 Batch   28/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.9034, Loss: 0.1662
Epoch  12 Batch   29/269 - Train Accuracy: 0.9042, Validation Accuracy: 0.8982, Loss: 0.1557
Epoch  12 Batch   30/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9115, Loss: 0.1423
Epoch  12 Batch   31/269 - Train Accuracy: 0.9059, Validation Accuracy: 0.9086, Loss: 0.1426
Epoch  12 Batch   32/269 - Train Accuracy: 0.8999, Validation Accuracy: 0.9063, Loss: 0.1438
Epoch  12 Batch   33/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.9051, Loss: 0.1355
Epoch  12 Batch   34/269 - Train Accuracy: 0.9051, Validation Accuracy: 0.8970, Loss: 0.1470
Epoch  12 Batch   35/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8929, Loss: 0.1579
Epoch  12 Batch   36/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.9032, Loss: 0.1507
Epoch  12 Batch   37/269 - Train Accuracy: 0.8989, Validation Accuracy: 0.9051, Loss: 0.1499
Epoch  12 Batch   38/269 - Train Accuracy: 0.8978, Validation Accuracy: 0.9011, Loss: 0.1551
Epoch  12 Batch   39/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.9002, Loss: 0.1431
Epoch  12 Batch   40/269 - Train Accuracy: 0.8866, Validation Accuracy: 0.8982, Loss: 0.1502
Epoch  12 Batch   41/269 - Train Accuracy: 0.8923, Validation Accuracy: 0.9015, Loss: 0.1548
Epoch  12 Batch   42/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.8995, Loss: 0.1393
Epoch  12 Batch   43/269 - Train Accuracy: 0.8960, Validation Accuracy: 0.8946, Loss: 0.1510
Epoch  12 Batch   44/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8955, Loss: 0.1483
Epoch  12 Batch   45/269 - Train Accuracy: 0.8942, Validation Accuracy: 0.9010, Loss: 0.1519
Epoch  12 Batch   46/269 - Train Accuracy: 0.8928, Validation Accuracy: 0.8988, Loss: 0.1416
Epoch  12 Batch   47/269 - Train Accuracy: 0.9013, Validation Accuracy: 0.8970, Loss: 0.1364
Epoch  12 Batch   48/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9047, Loss: 0.1464
Epoch  12 Batch   49/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.9059, Loss: 0.1413
Epoch  12 Batch   50/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.9062, Loss: 0.1613
Epoch  12 Batch   51/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.8967, Loss: 0.1445
Epoch  12 Batch   52/269 - Train Accuracy: 0.8980, Validation Accuracy: 0.8990, Loss: 0.1275
Epoch  12 Batch   53/269 - Train Accuracy: 0.8912, Validation Accuracy: 0.9132, Loss: 0.1571
Epoch  12 Batch   54/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.9147, Loss: 0.1423
Epoch  12 Batch   55/269 - Train Accuracy: 0.9088, Validation Accuracy: 0.9068, Loss: 0.1455
Epoch  12 Batch   56/269 - Train Accuracy: 0.9017, Validation Accuracy: 0.9002, Loss: 0.1502
Epoch  12 Batch   57/269 - Train Accuracy: 0.8948, Validation Accuracy: 0.8986, Loss: 0.1621
Epoch  12 Batch   58/269 - Train Accuracy: 0.9011, Validation Accuracy: 0.9120, Loss: 0.1412
Epoch  12 Batch   59/269 - Train Accuracy: 0.9124, Validation Accuracy: 0.9152, Loss: 0.1274
Epoch  12 Batch   60/269 - Train Accuracy: 0.8912, Validation Accuracy: 0.9003, Loss: 0.1404
Epoch  12 Batch   61/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.9081, Loss: 0.1364
Epoch  12 Batch   62/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.9090, Loss: 0.1434
Epoch  12 Batch   63/269 - Train Accuracy: 0.8908, Validation Accuracy: 0.9112, Loss: 0.1559
Epoch  12 Batch   64/269 - Train Accuracy: 0.9083, Validation Accuracy: 0.9127, Loss: 0.1399
Epoch  12 Batch   65/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.8966, Loss: 0.1565
Epoch  12 Batch   66/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8953, Loss: 0.1513
Epoch  12 Batch   67/269 - Train Accuracy: 0.8945, Validation Accuracy: 0.8936, Loss: 0.1576
Epoch  12 Batch   68/269 - Train Accuracy: 0.8859, Validation Accuracy: 0.9098, Loss: 0.1587
Epoch  12 Batch   69/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.9115, Loss: 0.1757
Epoch  12 Batch   70/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9113, Loss: 0.1511
Epoch  12 Batch   71/269 - Train Accuracy: 0.8923, Validation Accuracy: 0.9031, Loss: 0.1630
Epoch  12 Batch   72/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.9044, Loss: 0.1573
Epoch  12 Batch   73/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.9089, Loss: 0.1594
Epoch  12 Batch   74/269 - Train Accuracy: 0.9171, Validation Accuracy: 0.9077, Loss: 0.1481
Epoch  12 Batch   75/269 - Train Accuracy: 0.9072, Validation Accuracy: 0.9106, Loss: 0.1463
Epoch  12 Batch   76/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8961, Loss: 0.1474
Epoch  12 Batch   77/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.9023, Loss: 0.1406
Epoch  12 Batch   78/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9061, Loss: 0.1456
Epoch  12 Batch   79/269 - Train Accuracy: 0.8939, Validation Accuracy: 0.9066, Loss: 0.1454
Epoch  12 Batch   80/269 - Train Accuracy: 0.8907, Validation Accuracy: 0.9054, Loss: 0.1467
Epoch  12 Batch   81/269 - Train Accuracy: 0.8822, Validation Accuracy: 0.8933, Loss: 0.1622
Epoch  12 Batch   82/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.8921, Loss: 0.1324
Epoch  12 Batch   83/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.9059, Loss: 0.1553
Epoch  12 Batch   84/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9077, Loss: 0.1415
Epoch  12 Batch   85/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9047, Loss: 0.1413
Epoch  12 Batch   86/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.9110, Loss: 0.1449
Epoch  12 Batch   87/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.9069, Loss: 0.1549
Epoch  12 Batch   88/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.9003, Loss: 0.1553
Epoch  12 Batch   89/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9010, Loss: 0.1502
Epoch  12 Batch   90/269 - Train Accuracy: 0.8871, Validation Accuracy: 0.8988, Loss: 0.1517
Epoch  12 Batch   91/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.8929, Loss: 0.1421
Epoch  12 Batch   92/269 - Train Accuracy: 0.9005, Validation Accuracy: 0.8980, Loss: 0.1357
Epoch  12 Batch   93/269 - Train Accuracy: 0.9109, Validation Accuracy: 0.8992, Loss: 0.1464
Epoch  12 Batch   94/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8905, Loss: 0.1597
Epoch  12 Batch   95/269 - Train Accuracy: 0.8977, Validation Accuracy: 0.8940, Loss: 0.1445
Epoch  12 Batch   96/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.9066, Loss: 0.1513
Epoch  12 Batch   97/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.9067, Loss: 0.1564
Epoch  12 Batch   98/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.8945, Loss: 0.1499
Epoch  12 Batch   99/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8976, Loss: 0.1519
Epoch  12 Batch  100/269 - Train Accuracy: 0.9087, Validation Accuracy: 0.8906, Loss: 0.1437
Epoch  12 Batch  101/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8887, Loss: 0.1726
Epoch  12 Batch  102/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8938, Loss: 0.1473
Epoch  12 Batch  103/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9047, Loss: 0.1511
Epoch  12 Batch  104/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8960, Loss: 0.1454
Epoch  12 Batch  105/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.9095, Loss: 0.1612
Epoch  12 Batch  106/269 - Train Accuracy: 0.8952, Validation Accuracy: 0.8978, Loss: 0.1383
Epoch  12 Batch  107/269 - Train Accuracy: 0.8980, Validation Accuracy: 0.9040, Loss: 0.1696
Epoch  12 Batch  108/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9056, Loss: 0.1496
Epoch  12 Batch  109/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.9023, Loss: 0.1587
Epoch  12 Batch  110/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8844, Loss: 0.1410
Epoch  12 Batch  111/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8975, Loss: 0.1678
Epoch  12 Batch  112/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9015, Loss: 0.1490
Epoch  12 Batch  113/269 - Train Accuracy: 0.8985, Validation Accuracy: 0.9076, Loss: 0.1452
Epoch  12 Batch  114/269 - Train Accuracy: 0.9000, Validation Accuracy: 0.8911, Loss: 0.1462
Epoch  12 Batch  115/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8902, Loss: 0.1497
Epoch  12 Batch  116/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.8988, Loss: 0.1505
Epoch  12 Batch  117/269 - Train Accuracy: 0.8866, Validation Accuracy: 0.9040, Loss: 0.1504
Epoch  12 Batch  118/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.9043, Loss: 0.1358
Epoch  12 Batch  119/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.9012, Loss: 0.1557
Epoch  12 Batch  120/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9110, Loss: 0.1548
Epoch  12 Batch  121/269 - Train Accuracy: 0.9027, Validation Accuracy: 0.9080, Loss: 0.1405
Epoch  12 Batch  122/269 - Train Accuracy: 0.8845, Validation Accuracy: 0.9051, Loss: 0.1459
Epoch  12 Batch  123/269 - Train Accuracy: 0.8957, Validation Accuracy: 0.9022, Loss: 0.1579
Epoch  12 Batch  124/269 - Train Accuracy: 0.8874, Validation Accuracy: 0.8987, Loss: 0.1360
Epoch  12 Batch  125/269 - Train Accuracy: 0.9037, Validation Accuracy: 0.9086, Loss: 0.1459
Epoch  12 Batch  126/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.8859, Loss: 0.1431
Epoch  12 Batch  127/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.9046, Loss: 0.1652
Epoch  12 Batch  128/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.8987, Loss: 0.1443
Epoch  12 Batch  129/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8997, Loss: 0.1567
Epoch  12 Batch  130/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.8914, Loss: 0.1534
Epoch  12 Batch  131/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.9075, Loss: 0.1520
Epoch  12 Batch  132/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.9083, Loss: 0.1587
Epoch  12 Batch  133/269 - Train Accuracy: 0.9124, Validation Accuracy: 0.9102, Loss: 0.1369
Epoch  12 Batch  134/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.9072, Loss: 0.1463
Epoch  12 Batch  135/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.9095, Loss: 0.1574
Epoch  12 Batch  136/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.9055, Loss: 0.1638
Epoch  12 Batch  137/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8856, Loss: 0.1563
Epoch  12 Batch  138/269 - Train Accuracy: 0.8958, Validation Accuracy: 0.8874, Loss: 0.1412
Epoch  12 Batch  139/269 - Train Accuracy: 0.9013, Validation Accuracy: 0.9060, Loss: 0.1370
Epoch  12 Batch  140/269 - Train Accuracy: 0.8977, Validation Accuracy: 0.9101, Loss: 0.1519
Epoch  12 Batch  141/269 - Train Accuracy: 0.9014, Validation Accuracy: 0.8992, Loss: 0.1491
Epoch  12 Batch  142/269 - Train Accuracy: 0.8923, Validation Accuracy: 0.8971, Loss: 0.1423
Epoch  12 Batch  143/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.8915, Loss: 0.1400
Epoch  12 Batch  144/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.8992, Loss: 0.1307
Epoch  12 Batch  145/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.9070, Loss: 0.1337
Epoch  12 Batch  146/269 - Train Accuracy: 0.8925, Validation Accuracy: 0.9128, Loss: 0.1395
Epoch  12 Batch  147/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.9176, Loss: 0.1441
Epoch  12 Batch  148/269 - Train Accuracy: 0.8913, Validation Accuracy: 0.9044, Loss: 0.1478
Epoch  12 Batch  149/269 - Train Accuracy: 0.8860, Validation Accuracy: 0.9078, Loss: 0.1495
Epoch  12 Batch  150/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.9140, Loss: 0.1431
Epoch  12 Batch  151/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9068, Loss: 0.1466
Epoch  12 Batch  152/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.9084, Loss: 0.1432
Epoch  12 Batch  153/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9039, Loss: 0.1408
Epoch  12 Batch  154/269 - Train Accuracy: 0.9186, Validation Accuracy: 0.9080, Loss: 0.1380
Epoch  12 Batch  155/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.9085, Loss: 0.1339
Epoch  12 Batch  156/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.9097, Loss: 0.1541
Epoch  12 Batch  157/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.9070, Loss: 0.1382
Epoch  12 Batch  158/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.9080, Loss: 0.1407
Epoch  12 Batch  159/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.9084, Loss: 0.1427
Epoch  12 Batch  160/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9088, Loss: 0.1410
Epoch  12 Batch  161/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.9110, Loss: 0.1428
Epoch  12 Batch  162/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9210, Loss: 0.1353
Epoch  12 Batch  163/269 - Train Accuracy: 0.9010, Validation Accuracy: 0.9188, Loss: 0.1402
Epoch  12 Batch  164/269 - Train Accuracy: 0.9022, Validation Accuracy: 0.9127, Loss: 0.1454
Epoch  12 Batch  165/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9066, Loss: 0.1347
Epoch  12 Batch  166/269 - Train Accuracy: 0.9077, Validation Accuracy: 0.9113, Loss: 0.1391
Epoch  12 Batch  167/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9086, Loss: 0.1415
Epoch  12 Batch  168/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.9001, Loss: 0.1516
Epoch  12 Batch  169/269 - Train Accuracy: 0.8913, Validation Accuracy: 0.8930, Loss: 0.1412
Epoch  12 Batch  170/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.9013, Loss: 0.1410
Epoch  12 Batch  171/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9122, Loss: 0.1432
Epoch  12 Batch  172/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.9118, Loss: 0.1535
Epoch  12 Batch  173/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9086, Loss: 0.1345
Epoch  12 Batch  174/269 - Train Accuracy: 0.9045, Validation Accuracy: 0.9027, Loss: 0.1421
Epoch  12 Batch  175/269 - Train Accuracy: 0.8941, Validation Accuracy: 0.9054, Loss: 0.1569
Epoch  12 Batch  176/269 - Train Accuracy: 0.8898, Validation Accuracy: 0.9113, Loss: 0.1506
Epoch  12 Batch  177/269 - Train Accuracy: 0.9099, Validation Accuracy: 0.9145, Loss: 0.1372
Epoch  12 Batch  178/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9156, Loss: 0.1327
Epoch  12 Batch  179/269 - Train Accuracy: 0.9059, Validation Accuracy: 0.9129, Loss: 0.1359
Epoch  12 Batch  180/269 - Train Accuracy: 0.9025, Validation Accuracy: 0.9092, Loss: 0.1351
Epoch  12 Batch  181/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9082, Loss: 0.1491
Epoch  12 Batch  182/269 - Train Accuracy: 0.8985, Validation Accuracy: 0.9108, Loss: 0.1421
Epoch  12 Batch  183/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9157, Loss: 0.1231
Epoch  12 Batch  184/269 - Train Accuracy: 0.8989, Validation Accuracy: 0.9129, Loss: 0.1381
Epoch  12 Batch  185/269 - Train Accuracy: 0.9131, Validation Accuracy: 0.9090, Loss: 0.1412
Epoch  12 Batch  186/269 - Train Accuracy: 0.9068, Validation Accuracy: 0.9189, Loss: 0.1374
Epoch  12 Batch  187/269 - Train Accuracy: 0.9052, Validation Accuracy: 0.9119, Loss: 0.1393
Epoch  12 Batch  188/269 - Train Accuracy: 0.9018, Validation Accuracy: 0.9095, Loss: 0.1367
Epoch  12 Batch  189/269 - Train Accuracy: 0.8992, Validation Accuracy: 0.9002, Loss: 0.1316
Epoch  12 Batch  190/269 - Train Accuracy: 0.9052, Validation Accuracy: 0.9027, Loss: 0.1380
Epoch  12 Batch  191/269 - Train Accuracy: 0.8912, Validation Accuracy: 0.9050, Loss: 0.1314
Epoch  12 Batch  192/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.9091, Loss: 0.1382
Epoch  12 Batch  193/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9089, Loss: 0.1341
Epoch  12 Batch  194/269 - Train Accuracy: 0.8987, Validation Accuracy: 0.9118, Loss: 0.1431
Epoch  12 Batch  195/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.9108, Loss: 0.1381
Epoch  12 Batch  196/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.9096, Loss: 0.1364
Epoch  12 Batch  197/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.9068, Loss: 0.1522
Epoch  12 Batch  198/269 - Train Accuracy: 0.9008, Validation Accuracy: 0.9092, Loss: 0.1485
Epoch  12 Batch  199/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9062, Loss: 0.1509
Epoch  12 Batch  200/269 - Train Accuracy: 0.9096, Validation Accuracy: 0.9045, Loss: 0.1451
Epoch  12 Batch  201/269 - Train Accuracy: 0.9093, Validation Accuracy: 0.9107, Loss: 0.1396
Epoch  12 Batch  202/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.9090, Loss: 0.1413
Epoch  12 Batch  203/269 - Train Accuracy: 0.9003, Validation Accuracy: 0.9111, Loss: 0.1549
Epoch  12 Batch  204/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.9121, Loss: 0.1452
Epoch  12 Batch  205/269 - Train Accuracy: 0.9047, Validation Accuracy: 0.9031, Loss: 0.1391
Epoch  12 Batch  206/269 - Train Accuracy: 0.8878, Validation Accuracy: 0.9014, Loss: 0.1434
Epoch  12 Batch  207/269 - Train Accuracy: 0.8942, Validation Accuracy: 0.9078, Loss: 0.1348
Epoch  12 Batch  208/269 - Train Accuracy: 0.8957, Validation Accuracy: 0.9135, Loss: 0.1440
Epoch  12 Batch  209/269 - Train Accuracy: 0.9143, Validation Accuracy: 0.9120, Loss: 0.1336
Epoch  12 Batch  210/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.9073, Loss: 0.1368
Epoch  12 Batch  211/269 - Train Accuracy: 0.9017, Validation Accuracy: 0.9165, Loss: 0.1429
Epoch  12 Batch  212/269 - Train Accuracy: 0.8985, Validation Accuracy: 0.9143, Loss: 0.1426
Epoch  12 Batch  213/269 - Train Accuracy: 0.9005, Validation Accuracy: 0.9043, Loss: 0.1367
Epoch  12 Batch  214/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.9046, Loss: 0.1413
Epoch  12 Batch  215/269 - Train Accuracy: 0.9047, Validation Accuracy: 0.9069, Loss: 0.1284
Epoch  12 Batch  216/269 - Train Accuracy: 0.8873, Validation Accuracy: 0.9112, Loss: 0.1595
Epoch  12 Batch  217/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.9147, Loss: 0.1453
Epoch  12 Batch  218/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9111, Loss: 0.1385
Epoch  12 Batch  219/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.9085, Loss: 0.1374
Epoch  12 Batch  220/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9054, Loss: 0.1302
Epoch  12 Batch  221/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.8881, Loss: 0.1372
Epoch  12 Batch  222/269 - Train Accuracy: 0.9130, Validation Accuracy: 0.9071, Loss: 0.1300
Epoch  12 Batch  223/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.9086, Loss: 0.1315
Epoch  12 Batch  224/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9158, Loss: 0.1449
Epoch  12 Batch  225/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.8956, Loss: 0.1286
Epoch  12 Batch  226/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.9102, Loss: 0.1405
Epoch  12 Batch  227/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9108, Loss: 0.1396
Epoch  12 Batch  228/269 - Train Accuracy: 0.8888, Validation Accuracy: 0.9117, Loss: 0.1372
Epoch  12 Batch  229/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.9091, Loss: 0.1361
Epoch  12 Batch  230/269 - Train Accuracy: 0.9141, Validation Accuracy: 0.9078, Loss: 0.1359
Epoch  12 Batch  231/269 - Train Accuracy: 0.8946, Validation Accuracy: 0.9089, Loss: 0.1498
Epoch  12 Batch  232/269 - Train Accuracy: 0.8939, Validation Accuracy: 0.9132, Loss: 0.1442
Epoch  12 Batch  233/269 - Train Accuracy: 0.9135, Validation Accuracy: 0.9205, Loss: 0.1451
Epoch  12 Batch  234/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9111, Loss: 0.1327
Epoch  12 Batch  235/269 - Train Accuracy: 0.9177, Validation Accuracy: 0.9002, Loss: 0.1263
Epoch  12 Batch  236/269 - Train Accuracy: 0.8931, Validation Accuracy: 0.9056, Loss: 0.1327
Epoch  12 Batch  237/269 - Train Accuracy: 0.9073, Validation Accuracy: 0.9054, Loss: 0.1327
Epoch  12 Batch  238/269 - Train Accuracy: 0.9052, Validation Accuracy: 0.9019, Loss: 0.1454
Epoch  12 Batch  239/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.9021, Loss: 0.1344
Epoch  12 Batch  240/269 - Train Accuracy: 0.9240, Validation Accuracy: 0.9118, Loss: 0.1264
Epoch  12 Batch  241/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9101, Loss: 0.1472
Epoch  12 Batch  242/269 - Train Accuracy: 0.9210, Validation Accuracy: 0.9061, Loss: 0.1367
Epoch  12 Batch  243/269 - Train Accuracy: 0.9185, Validation Accuracy: 0.8994, Loss: 0.1270
Epoch  12 Batch  244/269 - Train Accuracy: 0.8993, Validation Accuracy: 0.8999, Loss: 0.1359
Epoch  12 Batch  245/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.9037, Loss: 0.1433
Epoch  12 Batch  246/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9062, Loss: 0.1415
Epoch  12 Batch  247/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9126, Loss: 0.1396
Epoch  12 Batch  248/269 - Train Accuracy: 0.8966, Validation Accuracy: 0.9088, Loss: 0.1302
Epoch  12 Batch  249/269 - Train Accuracy: 0.9015, Validation Accuracy: 0.9058, Loss: 0.1262
Epoch  12 Batch  250/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9004, Loss: 0.1320
Epoch  12 Batch  251/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9086, Loss: 0.1323
Epoch  12 Batch  252/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.9091, Loss: 0.1274
Epoch  12 Batch  253/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.9103, Loss: 0.1426
Epoch  12 Batch  254/269 - Train Accuracy: 0.8940, Validation Accuracy: 0.9092, Loss: 0.1292
Epoch  12 Batch  255/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.9084, Loss: 0.1335
Epoch  12 Batch  256/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9115, Loss: 0.1352
Epoch  12 Batch  257/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.9128, Loss: 0.1388
Epoch  12 Batch  258/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.9175, Loss: 0.1365
Epoch  12 Batch  259/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9241, Loss: 0.1313
Epoch  12 Batch  260/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.9244, Loss: 0.1434
Epoch  12 Batch  261/269 - Train Accuracy: 0.9028, Validation Accuracy: 0.9206, Loss: 0.1417
Epoch  12 Batch  262/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9178, Loss: 0.1379
Epoch  12 Batch  263/269 - Train Accuracy: 0.8915, Validation Accuracy: 0.8993, Loss: 0.1415
Epoch  12 Batch  264/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.9020, Loss: 0.1450
Epoch  12 Batch  265/269 - Train Accuracy: 0.9082, Validation Accuracy: 0.9013, Loss: 0.1312
Epoch  12 Batch  266/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9112, Loss: 0.1227
Epoch  12 Batch  267/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9122, Loss: 0.1389
Epoch  13 Batch    1/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.9170, Loss: 0.1372
Epoch  13 Batch    2/269 - Train Accuracy: 0.8998, Validation Accuracy: 0.9145, Loss: 0.1396
Epoch  13 Batch    3/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.9141, Loss: 0.1338
Epoch  13 Batch    4/269 - Train Accuracy: 0.8962, Validation Accuracy: 0.9161, Loss: 0.1355
Epoch  13 Batch    5/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9170, Loss: 0.1339
Epoch  13 Batch    6/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9181, Loss: 0.1262
Epoch  13 Batch    7/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9181, Loss: 0.1287
Epoch  13 Batch    8/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9164, Loss: 0.1333
Epoch  13 Batch    9/269 - Train Accuracy: 0.8974, Validation Accuracy: 0.9149, Loss: 0.1465
Epoch  13 Batch   10/269 - Train Accuracy: 0.8953, Validation Accuracy: 0.9126, Loss: 0.1271
Epoch  13 Batch   11/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9117, Loss: 0.1446
Epoch  13 Batch   12/269 - Train Accuracy: 0.8948, Validation Accuracy: 0.9094, Loss: 0.1453
Epoch  13 Batch   13/269 - Train Accuracy: 0.9033, Validation Accuracy: 0.9098, Loss: 0.1174
Epoch  13 Batch   14/269 - Train Accuracy: 0.8941, Validation Accuracy: 0.9182, Loss: 0.1383
Epoch  13 Batch   15/269 - Train Accuracy: 0.9082, Validation Accuracy: 0.9192, Loss: 0.1190
Epoch  13 Batch   16/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9218, Loss: 0.1389
Epoch  13 Batch   17/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9151, Loss: 0.1220
Epoch  13 Batch   18/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.9110, Loss: 0.1325
Epoch  13 Batch   19/269 - Train Accuracy: 0.9197, Validation Accuracy: 0.9111, Loss: 0.1233
Epoch  13 Batch   20/269 - Train Accuracy: 0.9052, Validation Accuracy: 0.9147, Loss: 0.1306
Epoch  13 Batch   21/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.9123, Loss: 0.1477
Epoch  13 Batch   22/269 - Train Accuracy: 0.9255, Validation Accuracy: 0.9118, Loss: 0.1215
Epoch  13 Batch   23/269 - Train Accuracy: 0.9018, Validation Accuracy: 0.9158, Loss: 0.1372
Epoch  13 Batch   24/269 - Train Accuracy: 0.9030, Validation Accuracy: 0.9170, Loss: 0.1358
Epoch  13 Batch   25/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9144, Loss: 0.1486
Epoch  13 Batch   26/269 - Train Accuracy: 0.9052, Validation Accuracy: 0.9077, Loss: 0.1203
Epoch  13 Batch   27/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9150, Loss: 0.1298
Epoch  13 Batch   28/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.9166, Loss: 0.1428
Epoch  13 Batch   29/269 - Train Accuracy: 0.9098, Validation Accuracy: 0.9103, Loss: 0.1386
Epoch  13 Batch   30/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9176, Loss: 0.1288
Epoch  13 Batch   31/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.9181, Loss: 0.1246
Epoch  13 Batch   32/269 - Train Accuracy: 0.9095, Validation Accuracy: 0.9190, Loss: 0.1282
Epoch  13 Batch   33/269 - Train Accuracy: 0.9078, Validation Accuracy: 0.9145, Loss: 0.1179
Epoch  13 Batch   34/269 - Train Accuracy: 0.9065, Validation Accuracy: 0.9075, Loss: 0.1320
Epoch  13 Batch   35/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.9118, Loss: 0.1442
Epoch  13 Batch   36/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.9146, Loss: 0.1352
Epoch  13 Batch   37/269 - Train Accuracy: 0.8966, Validation Accuracy: 0.9108, Loss: 0.1315
Epoch  13 Batch   38/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9110, Loss: 0.1313
Epoch  13 Batch   39/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9138, Loss: 0.1280
Epoch  13 Batch   40/269 - Train Accuracy: 0.9037, Validation Accuracy: 0.9173, Loss: 0.1382
Epoch  13 Batch   41/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9205, Loss: 0.1309
Epoch  13 Batch   42/269 - Train Accuracy: 0.9145, Validation Accuracy: 0.9165, Loss: 0.1207
Epoch  13 Batch   43/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9119, Loss: 0.1391
Epoch  13 Batch   44/269 - Train Accuracy: 0.9034, Validation Accuracy: 0.9142, Loss: 0.1335
Epoch  13 Batch   45/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9053, Loss: 0.1400
Epoch  13 Batch   46/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9038, Loss: 0.1250
Epoch  13 Batch   47/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9038, Loss: 0.1182
Epoch  13 Batch   48/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9047, Loss: 0.1310
Epoch  13 Batch   49/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.9105, Loss: 0.1270
Epoch  13 Batch   50/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.9173, Loss: 0.1451
Epoch  13 Batch   51/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9144, Loss: 0.1354
Epoch  13 Batch   52/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9092, Loss: 0.1227
Epoch  13 Batch   53/269 - Train Accuracy: 0.9031, Validation Accuracy: 0.9132, Loss: 0.1407
Epoch  13 Batch   54/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9149, Loss: 0.1252
Epoch  13 Batch   55/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9097, Loss: 0.1303
Epoch  13 Batch   56/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.9126, Loss: 0.1352
Epoch  13 Batch   57/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.9165, Loss: 0.1456
Epoch  13 Batch   58/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9123, Loss: 0.1314
Epoch  13 Batch   59/269 - Train Accuracy: 0.9264, Validation Accuracy: 0.9151, Loss: 0.1146
Epoch  13 Batch   60/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9207, Loss: 0.1232
Epoch  13 Batch   61/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.9200, Loss: 0.1174
Epoch  13 Batch   62/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.9213, Loss: 0.1319
Epoch  13 Batch   63/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.9165, Loss: 0.1381
Epoch  13 Batch   64/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9193, Loss: 0.1218
Epoch  13 Batch   65/269 - Train Accuracy: 0.9001, Validation Accuracy: 0.9212, Loss: 0.1278
Epoch  13 Batch   66/269 - Train Accuracy: 0.8978, Validation Accuracy: 0.9165, Loss: 0.1315
Epoch  13 Batch   67/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.9225, Loss: 0.1404
Epoch  13 Batch   68/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.9074, Loss: 0.1377
Epoch  13 Batch   69/269 - Train Accuracy: 0.8886, Validation Accuracy: 0.9231, Loss: 0.1559
Epoch  13 Batch   70/269 - Train Accuracy: 0.9011, Validation Accuracy: 0.9122, Loss: 0.1361
Epoch  13 Batch   71/269 - Train Accuracy: 0.8981, Validation Accuracy: 0.9193, Loss: 0.1481
Epoch  13 Batch   72/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9069, Loss: 0.1320
Epoch  13 Batch   73/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.9199, Loss: 0.1431
Epoch  13 Batch   74/269 - Train Accuracy: 0.9282, Validation Accuracy: 0.9142, Loss: 0.1251
Epoch  13 Batch   75/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9154, Loss: 0.1426
Epoch  13 Batch   76/269 - Train Accuracy: 0.8946, Validation Accuracy: 0.9082, Loss: 0.1314
Epoch  13 Batch   77/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.9113, Loss: 0.1348
Epoch  13 Batch   78/269 - Train Accuracy: 0.9215, Validation Accuracy: 0.9136, Loss: 0.1311
Epoch  13 Batch   79/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9148, Loss: 0.1377
Epoch  13 Batch   80/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.9157, Loss: 0.1291
Epoch  13 Batch   81/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.9118, Loss: 0.1407
Epoch  13 Batch   82/269 - Train Accuracy: 0.9297, Validation Accuracy: 0.9085, Loss: 0.1180
Epoch  13 Batch   83/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.9095, Loss: 0.1376
Epoch  13 Batch   84/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9102, Loss: 0.1266
Epoch  13 Batch   85/269 - Train Accuracy: 0.9108, Validation Accuracy: 0.9108, Loss: 0.1275
Epoch  13 Batch   86/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.9119, Loss: 0.1285
Epoch  13 Batch   87/269 - Train Accuracy: 0.8925, Validation Accuracy: 0.9145, Loss: 0.1343
Epoch  13 Batch   88/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.9136, Loss: 0.1398
Epoch  13 Batch   89/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9158, Loss: 0.1308
Epoch  13 Batch   90/269 - Train Accuracy: 0.8990, Validation Accuracy: 0.9153, Loss: 0.1359
Epoch  13 Batch   91/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9160, Loss: 0.1208
Epoch  13 Batch   92/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.9118, Loss: 0.1202
Epoch  13 Batch   93/269 - Train Accuracy: 0.9151, Validation Accuracy: 0.9144, Loss: 0.1212
Epoch  13 Batch   94/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9160, Loss: 0.1444
Epoch  13 Batch   95/269 - Train Accuracy: 0.9130, Validation Accuracy: 0.9142, Loss: 0.1236
Epoch  13 Batch   96/269 - Train Accuracy: 0.8928, Validation Accuracy: 0.9190, Loss: 0.1280
Epoch  13 Batch   97/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.9232, Loss: 0.1261
Epoch  13 Batch   98/269 - Train Accuracy: 0.9067, Validation Accuracy: 0.9134, Loss: 0.1298
Epoch  13 Batch   99/269 - Train Accuracy: 0.9007, Validation Accuracy: 0.9083, Loss: 0.1285
Epoch  13 Batch  100/269 - Train Accuracy: 0.9141, Validation Accuracy: 0.9070, Loss: 0.1296
Epoch  13 Batch  101/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9179, Loss: 0.1410
Epoch  13 Batch  102/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9219, Loss: 0.1239
Epoch  13 Batch  103/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9118, Loss: 0.1379
Epoch  13 Batch  104/269 - Train Accuracy: 0.8967, Validation Accuracy: 0.9047, Loss: 0.1277
Epoch  13 Batch  105/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.9129, Loss: 0.1366
Epoch  13 Batch  106/269 - Train Accuracy: 0.9082, Validation Accuracy: 0.9229, Loss: 0.1206
Epoch  13 Batch  107/269 - Train Accuracy: 0.9236, Validation Accuracy: 0.9183, Loss: 0.1336
Epoch  13 Batch  108/269 - Train Accuracy: 0.9217, Validation Accuracy: 0.9155, Loss: 0.1233
Epoch  13 Batch  109/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.9118, Loss: 0.1380
Epoch  13 Batch  110/269 - Train Accuracy: 0.9162, Validation Accuracy: 0.9197, Loss: 0.1163
Epoch  13 Batch  111/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.9239, Loss: 0.1408
Epoch  13 Batch  112/269 - Train Accuracy: 0.9166, Validation Accuracy: 0.9214, Loss: 0.1312
Epoch  13 Batch  113/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9198, Loss: 0.1287
Epoch  13 Batch  114/269 - Train Accuracy: 0.9092, Validation Accuracy: 0.9027, Loss: 0.1247
Epoch  13 Batch  115/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.9041, Loss: 0.1361
Epoch  13 Batch  116/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9157, Loss: 0.1264
Epoch  13 Batch  117/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.9157, Loss: 0.1277
Epoch  13 Batch  118/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9192, Loss: 0.1191
Epoch  13 Batch  119/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.9149, Loss: 0.1389
Epoch  13 Batch  120/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9123, Loss: 0.1315
Epoch  13 Batch  121/269 - Train Accuracy: 0.9077, Validation Accuracy: 0.9169, Loss: 0.1204
Epoch  13 Batch  122/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.9106, Loss: 0.1265
Epoch  13 Batch  123/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9074, Loss: 0.1283
Epoch  13 Batch  124/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.9066, Loss: 0.1142
Epoch  13 Batch  125/269 - Train Accuracy: 0.9240, Validation Accuracy: 0.9030, Loss: 0.1172
Epoch  13 Batch  126/269 - Train Accuracy: 0.8987, Validation Accuracy: 0.9056, Loss: 0.1308
Epoch  13 Batch  127/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9040, Loss: 0.1292
Epoch  13 Batch  128/269 - Train Accuracy: 0.9011, Validation Accuracy: 0.9071, Loss: 0.1298
Epoch  13 Batch  129/269 - Train Accuracy: 0.8922, Validation Accuracy: 0.9138, Loss: 0.1261
Epoch  13 Batch  130/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9158, Loss: 0.1322
Epoch  13 Batch  131/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.9082, Loss: 0.1313
Epoch  13 Batch  132/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.9080, Loss: 0.1308
Epoch  13 Batch  133/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9157, Loss: 0.1178
Epoch  13 Batch  134/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.9185, Loss: 0.1229
Epoch  13 Batch  135/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.9167, Loss: 0.1317
Epoch  13 Batch  136/269 - Train Accuracy: 0.8931, Validation Accuracy: 0.9136, Loss: 0.1379
Epoch  13 Batch  137/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.9118, Loss: 0.1397
Epoch  13 Batch  138/269 - Train Accuracy: 0.8990, Validation Accuracy: 0.9109, Loss: 0.1254
Epoch  13 Batch  139/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9130, Loss: 0.1190
Epoch  13 Batch  140/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9119, Loss: 0.1404
Epoch  13 Batch  141/269 - Train Accuracy: 0.9130, Validation Accuracy: 0.9095, Loss: 0.1319
Epoch  13 Batch  142/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.9101, Loss: 0.1224
Epoch  13 Batch  143/269 - Train Accuracy: 0.9092, Validation Accuracy: 0.9096, Loss: 0.1273
Epoch  13 Batch  144/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9079, Loss: 0.1176
Epoch  13 Batch  145/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9156, Loss: 0.1255
Epoch  13 Batch  146/269 - Train Accuracy: 0.9108, Validation Accuracy: 0.9207, Loss: 0.1187
Epoch  13 Batch  147/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9133, Loss: 0.1325
Epoch  13 Batch  148/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.9090, Loss: 0.1284
Epoch  13 Batch  149/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.9154, Loss: 0.1331
Epoch  13 Batch  150/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9194, Loss: 0.1277
Epoch  13 Batch  151/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9196, Loss: 0.1273
Epoch  13 Batch  152/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.9205, Loss: 0.1256
Epoch  13 Batch  153/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9136, Loss: 0.1163
Epoch  13 Batch  154/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9123, Loss: 0.1210
Epoch  13 Batch  155/269 - Train Accuracy: 0.9074, Validation Accuracy: 0.9146, Loss: 0.1206
Epoch  13 Batch  156/269 - Train Accuracy: 0.9158, Validation Accuracy: 0.9209, Loss: 0.1348
Epoch  13 Batch  157/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9185, Loss: 0.1246
Epoch  13 Batch  158/269 - Train Accuracy: 0.9059, Validation Accuracy: 0.9148, Loss: 0.1233
Epoch  13 Batch  159/269 - Train Accuracy: 0.8940, Validation Accuracy: 0.9219, Loss: 0.1273
Epoch  13 Batch  160/269 - Train Accuracy: 0.9057, Validation Accuracy: 0.9106, Loss: 0.1280
Epoch  13 Batch  161/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9189, Loss: 0.1259
Epoch  13 Batch  162/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9173, Loss: 0.1193
Epoch  13 Batch  163/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9185, Loss: 0.1293
Epoch  13 Batch  164/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9223, Loss: 0.1270
Epoch  13 Batch  165/269 - Train Accuracy: 0.9276, Validation Accuracy: 0.9173, Loss: 0.1220
Epoch  13 Batch  166/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9095, Loss: 0.1262
Epoch  13 Batch  167/269 - Train Accuracy: 0.9200, Validation Accuracy: 0.9164, Loss: 0.1220
Epoch  13 Batch  168/269 - Train Accuracy: 0.9046, Validation Accuracy: 0.9175, Loss: 0.1277
Epoch  13 Batch  169/269 - Train Accuracy: 0.9042, Validation Accuracy: 0.9173, Loss: 0.1240
Epoch  13 Batch  170/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9200, Loss: 0.1154
Epoch  13 Batch  171/269 - Train Accuracy: 0.9271, Validation Accuracy: 0.9251, Loss: 0.1230
Epoch  13 Batch  172/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9255, Loss: 0.1356
Epoch  13 Batch  173/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.9202, Loss: 0.1120
Epoch  13 Batch  174/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9163, Loss: 0.1251
Epoch  13 Batch  175/269 - Train Accuracy: 0.8995, Validation Accuracy: 0.9191, Loss: 0.1427
Epoch  13 Batch  176/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.9134, Loss: 0.1313
Epoch  13 Batch  177/269 - Train Accuracy: 0.9162, Validation Accuracy: 0.9084, Loss: 0.1177
Epoch  13 Batch  178/269 - Train Accuracy: 0.9176, Validation Accuracy: 0.9157, Loss: 0.1147
Epoch  13 Batch  179/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9168, Loss: 0.1185
Epoch  13 Batch  180/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9167, Loss: 0.1155
Epoch  13 Batch  181/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9180, Loss: 0.1310
Epoch  13 Batch  182/269 - Train Accuracy: 0.9108, Validation Accuracy: 0.9199, Loss: 0.1228
Epoch  13 Batch  183/269 - Train Accuracy: 0.9204, Validation Accuracy: 0.9229, Loss: 0.1061
Epoch  13 Batch  184/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9116, Loss: 0.1302
Epoch  13 Batch  185/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.9155, Loss: 0.1213
Epoch  13 Batch  186/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9192, Loss: 0.1199
Epoch  13 Batch  187/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9171, Loss: 0.1163
Epoch  13 Batch  188/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9154, Loss: 0.1184
Epoch  13 Batch  189/269 - Train Accuracy: 0.9044, Validation Accuracy: 0.9066, Loss: 0.1154
Epoch  13 Batch  190/269 - Train Accuracy: 0.9082, Validation Accuracy: 0.9055, Loss: 0.1187
Epoch  13 Batch  191/269 - Train Accuracy: 0.8995, Validation Accuracy: 0.9104, Loss: 0.1297
Epoch  13 Batch  192/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9115, Loss: 0.1180
Epoch  13 Batch  193/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9150, Loss: 0.1208
Epoch  13 Batch  194/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9124, Loss: 0.1281
Epoch  13 Batch  195/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9138, Loss: 0.1190
Epoch  13 Batch  196/269 - Train Accuracy: 0.9061, Validation Accuracy: 0.9180, Loss: 0.1192
Epoch  13 Batch  197/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9180, Loss: 0.1294
Epoch  13 Batch  198/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9207, Loss: 0.1265
Epoch  13 Batch  199/269 - Train Accuracy: 0.9212, Validation Accuracy: 0.9146, Loss: 0.1263
Epoch  13 Batch  200/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9110, Loss: 0.1207
Epoch  13 Batch  201/269 - Train Accuracy: 0.9050, Validation Accuracy: 0.9105, Loss: 0.1252
Epoch  13 Batch  202/269 - Train Accuracy: 0.9113, Validation Accuracy: 0.9163, Loss: 0.1177
Epoch  13 Batch  203/269 - Train Accuracy: 0.9145, Validation Accuracy: 0.9132, Loss: 0.1299
Epoch  13 Batch  204/269 - Train Accuracy: 0.9031, Validation Accuracy: 0.9099, Loss: 0.1260
Epoch  13 Batch  205/269 - Train Accuracy: 0.9095, Validation Accuracy: 0.9063, Loss: 0.1241
Epoch  13 Batch  206/269 - Train Accuracy: 0.9045, Validation Accuracy: 0.9159, Loss: 0.1274
Epoch  13 Batch  207/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.9179, Loss: 0.1244
Epoch  13 Batch  208/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9139, Loss: 0.1319
Epoch  13 Batch  209/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9149, Loss: 0.1136
Epoch  13 Batch  210/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.9210, Loss: 0.1193
Epoch  13 Batch  211/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9176, Loss: 0.1252
Epoch  13 Batch  212/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9180, Loss: 0.1309
Epoch  13 Batch  213/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9157, Loss: 0.1217
Epoch  13 Batch  214/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9220, Loss: 0.1277
Epoch  13 Batch  215/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9210, Loss: 0.1175
Epoch  13 Batch  216/269 - Train Accuracy: 0.8975, Validation Accuracy: 0.9117, Loss: 0.1439
Epoch  13 Batch  217/269 - Train Accuracy: 0.8937, Validation Accuracy: 0.9134, Loss: 0.1283
Epoch  13 Batch  218/269 - Train Accuracy: 0.9103, Validation Accuracy: 0.9185, Loss: 0.1272
Epoch  13 Batch  219/269 - Train Accuracy: 0.9114, Validation Accuracy: 0.9152, Loss: 0.1308
Epoch  13 Batch  220/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9102, Loss: 0.1118
Epoch  13 Batch  221/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9092, Loss: 0.1264
Epoch  13 Batch  222/269 - Train Accuracy: 0.9238, Validation Accuracy: 0.9200, Loss: 0.1152
Epoch  13 Batch  223/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.9239, Loss: 0.1214
Epoch  13 Batch  224/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9186, Loss: 0.1412
Epoch  13 Batch  225/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.9165, Loss: 0.1231
Epoch  13 Batch  226/269 - Train Accuracy: 0.9096, Validation Accuracy: 0.9205, Loss: 0.1230
Epoch  13 Batch  227/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9225, Loss: 0.1290
Epoch  13 Batch  228/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9180, Loss: 0.1184
Epoch  13 Batch  229/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.9218, Loss: 0.1134
Epoch  13 Batch  230/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9232, Loss: 0.1206
Epoch  13 Batch  231/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.9165, Loss: 0.1292
Epoch  13 Batch  232/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.9124, Loss: 0.1175
Epoch  13 Batch  233/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9174, Loss: 0.1286
Epoch  13 Batch  234/269 - Train Accuracy: 0.9042, Validation Accuracy: 0.9185, Loss: 0.1174
Epoch  13 Batch  235/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9203, Loss: 0.1107
Epoch  13 Batch  236/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9203, Loss: 0.1170
Epoch  13 Batch  237/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9200, Loss: 0.1143
Epoch  13 Batch  238/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.9234, Loss: 0.1189
Epoch  13 Batch  239/269 - Train Accuracy: 0.9010, Validation Accuracy: 0.9221, Loss: 0.1172
Epoch  13 Batch  240/269 - Train Accuracy: 0.9262, Validation Accuracy: 0.9154, Loss: 0.1122
Epoch  13 Batch  241/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9134, Loss: 0.1363
Epoch  13 Batch  242/269 - Train Accuracy: 0.9310, Validation Accuracy: 0.9138, Loss: 0.1149
Epoch  13 Batch  243/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9127, Loss: 0.1051
Epoch  13 Batch  244/269 - Train Accuracy: 0.9096, Validation Accuracy: 0.9123, Loss: 0.1232
Epoch  13 Batch  245/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.9142, Loss: 0.1255
Epoch  13 Batch  246/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9178, Loss: 0.1196
Epoch  13 Batch  247/269 - Train Accuracy: 0.9232, Validation Accuracy: 0.9249, Loss: 0.1209
Epoch  13 Batch  248/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.9235, Loss: 0.1091
Epoch  13 Batch  249/269 - Train Accuracy: 0.9145, Validation Accuracy: 0.9205, Loss: 0.1114
Epoch  13 Batch  250/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9238, Loss: 0.1174
Epoch  13 Batch  251/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9234, Loss: 0.1200
Epoch  13 Batch  252/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9209, Loss: 0.1120
Epoch  13 Batch  253/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9113, Loss: 0.1246
Epoch  13 Batch  254/269 - Train Accuracy: 0.9030, Validation Accuracy: 0.9152, Loss: 0.1154
Epoch  13 Batch  255/269 - Train Accuracy: 0.9191, Validation Accuracy: 0.9236, Loss: 0.1228
Epoch  13 Batch  256/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.9245, Loss: 0.1211
Epoch  13 Batch  257/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.9280, Loss: 0.1257
Epoch  13 Batch  258/269 - Train Accuracy: 0.9066, Validation Accuracy: 0.9113, Loss: 0.1320
Epoch  13 Batch  259/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9205, Loss: 0.1166
Epoch  13 Batch  260/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9250, Loss: 0.1302
Epoch  13 Batch  261/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.9219, Loss: 0.1239
Epoch  13 Batch  262/269 - Train Accuracy: 0.9152, Validation Accuracy: 0.9196, Loss: 0.1256
Epoch  13 Batch  263/269 - Train Accuracy: 0.9011, Validation Accuracy: 0.9235, Loss: 0.1241
Epoch  13 Batch  264/269 - Train Accuracy: 0.8933, Validation Accuracy: 0.9284, Loss: 0.1285
Epoch  13 Batch  265/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9193, Loss: 0.1161
Epoch  13 Batch  266/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9165, Loss: 0.1123
Epoch  13 Batch  267/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9259, Loss: 0.1260
Epoch  14 Batch    1/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9141, Loss: 0.1167
Epoch  14 Batch    2/269 - Train Accuracy: 0.9149, Validation Accuracy: 0.9131, Loss: 0.1232
Epoch  14 Batch    3/269 - Train Accuracy: 0.9271, Validation Accuracy: 0.9196, Loss: 0.1206
Epoch  14 Batch    4/269 - Train Accuracy: 0.8981, Validation Accuracy: 0.9189, Loss: 0.1208
Epoch  14 Batch    5/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9173, Loss: 0.1238
Epoch  14 Batch    6/269 - Train Accuracy: 0.9285, Validation Accuracy: 0.9189, Loss: 0.1128
Epoch  14 Batch    7/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9240, Loss: 0.1113
Epoch  14 Batch    8/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9194, Loss: 0.1227
Epoch  14 Batch    9/269 - Train Accuracy: 0.9066, Validation Accuracy: 0.9143, Loss: 0.1265
Epoch  14 Batch   10/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9184, Loss: 0.1124
Epoch  14 Batch   11/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.9259, Loss: 0.1287
Epoch  14 Batch   12/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.9215, Loss: 0.1219
Epoch  14 Batch   13/269 - Train Accuracy: 0.9073, Validation Accuracy: 0.9191, Loss: 0.1040
Epoch  14 Batch   14/269 - Train Accuracy: 0.9013, Validation Accuracy: 0.9118, Loss: 0.1195
Epoch  14 Batch   15/269 - Train Accuracy: 0.9099, Validation Accuracy: 0.9162, Loss: 0.1080
Epoch  14 Batch   16/269 - Train Accuracy: 0.9096, Validation Accuracy: 0.9248, Loss: 0.1204
Epoch  14 Batch   17/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9222, Loss: 0.1074
Epoch  14 Batch   18/269 - Train Accuracy: 0.9148, Validation Accuracy: 0.9173, Loss: 0.1223
Epoch  14 Batch   19/269 - Train Accuracy: 0.9245, Validation Accuracy: 0.9140, Loss: 0.1086
Epoch  14 Batch   20/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9178, Loss: 0.1135
Epoch  14 Batch   21/269 - Train Accuracy: 0.8920, Validation Accuracy: 0.9179, Loss: 0.1261
Epoch  14 Batch   22/269 - Train Accuracy: 0.9333, Validation Accuracy: 0.9194, Loss: 0.1087
Epoch  14 Batch   23/269 - Train Accuracy: 0.9045, Validation Accuracy: 0.9157, Loss: 0.1252
Epoch  14 Batch   24/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9200, Loss: 0.1174
Epoch  14 Batch   25/269 - Train Accuracy: 0.9048, Validation Accuracy: 0.9197, Loss: 0.1276
Epoch  14 Batch   26/269 - Train Accuracy: 0.9155, Validation Accuracy: 0.9256, Loss: 0.1095
Epoch  14 Batch   27/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.9218, Loss: 0.1143
Epoch  14 Batch   28/269 - Train Accuracy: 0.8856, Validation Accuracy: 0.9120, Loss: 0.1274
Epoch  14 Batch   29/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9135, Loss: 0.1222
Epoch  14 Batch   30/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9247, Loss: 0.1141
Epoch  14 Batch   31/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9230, Loss: 0.1135
Epoch  14 Batch   32/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9269, Loss: 0.1090
Epoch  14 Batch   33/269 - Train Accuracy: 0.9108, Validation Accuracy: 0.9237, Loss: 0.1078
Epoch  14 Batch   34/269 - Train Accuracy: 0.9126, Validation Accuracy: 0.9217, Loss: 0.1121
Epoch  14 Batch   35/269 - Train Accuracy: 0.9069, Validation Accuracy: 0.9215, Loss: 0.1332
Epoch  14 Batch   36/269 - Train Accuracy: 0.8963, Validation Accuracy: 0.9213, Loss: 0.1177
Epoch  14 Batch   37/269 - Train Accuracy: 0.9174, Validation Accuracy: 0.9177, Loss: 0.1159
Epoch  14 Batch   38/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.9116, Loss: 0.1144
Epoch  14 Batch   39/269 - Train Accuracy: 0.9143, Validation Accuracy: 0.9110, Loss: 0.1159
Epoch  14 Batch   40/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9148, Loss: 0.1235
Epoch  14 Batch   41/269 - Train Accuracy: 0.9030, Validation Accuracy: 0.9258, Loss: 0.1215
Epoch  14 Batch   42/269 - Train Accuracy: 0.9210, Validation Accuracy: 0.9209, Loss: 0.1110
Epoch  14 Batch   43/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9182, Loss: 0.1164
Epoch  14 Batch   44/269 - Train Accuracy: 0.9098, Validation Accuracy: 0.9178, Loss: 0.1205
Epoch  14 Batch   45/269 - Train Accuracy: 0.9097, Validation Accuracy: 0.9182, Loss: 0.1237
Epoch  14 Batch   46/269 - Train Accuracy: 0.9199, Validation Accuracy: 0.9215, Loss: 0.1102
Epoch  14 Batch   47/269 - Train Accuracy: 0.9317, Validation Accuracy: 0.9230, Loss: 0.1037
Epoch  14 Batch   48/269 - Train Accuracy: 0.9295, Validation Accuracy: 0.9219, Loss: 0.1090
Epoch  14 Batch   49/269 - Train Accuracy: 0.9157, Validation Accuracy: 0.9163, Loss: 0.1086
Epoch  14 Batch   50/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.9136, Loss: 0.1252
Epoch  14 Batch   51/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9157, Loss: 0.1217
Epoch  14 Batch   52/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9178, Loss: 0.1023
Epoch  14 Batch   53/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9179, Loss: 0.1243
Epoch  14 Batch   54/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9253, Loss: 0.1142
Epoch  14 Batch   55/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9218, Loss: 0.1138
Epoch  14 Batch   56/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.9160, Loss: 0.1179
Epoch  14 Batch   57/269 - Train Accuracy: 0.9162, Validation Accuracy: 0.9150, Loss: 0.1203
Epoch  14 Batch   58/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9110, Loss: 0.1128
Epoch  14 Batch   59/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9244, Loss: 0.1026
Epoch  14 Batch   60/269 - Train Accuracy: 0.9112, Validation Accuracy: 0.9218, Loss: 0.1103
Epoch  14 Batch   61/269 - Train Accuracy: 0.9236, Validation Accuracy: 0.9259, Loss: 0.1084
Epoch  14 Batch   62/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.9191, Loss: 0.1121
Epoch  14 Batch   63/269 - Train Accuracy: 0.8970, Validation Accuracy: 0.9196, Loss: 0.1282
Epoch  14 Batch   64/269 - Train Accuracy: 0.9239, Validation Accuracy: 0.9188, Loss: 0.1061
Epoch  14 Batch   65/269 - Train Accuracy: 0.9085, Validation Accuracy: 0.9290, Loss: 0.1173
Epoch  14 Batch   66/269 - Train Accuracy: 0.9057, Validation Accuracy: 0.9244, Loss: 0.1179
Epoch  14 Batch   67/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9233, Loss: 0.1276
Epoch  14 Batch   68/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9118, Loss: 0.1251
Epoch  14 Batch   69/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.9153, Loss: 0.1355
Epoch  14 Batch   70/269 - Train Accuracy: 0.9168, Validation Accuracy: 0.9212, Loss: 0.1206
Epoch  14 Batch   71/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9238, Loss: 0.1229
Epoch  14 Batch   72/269 - Train Accuracy: 0.9085, Validation Accuracy: 0.9205, Loss: 0.1241
Epoch  14 Batch   73/269 - Train Accuracy: 0.8931, Validation Accuracy: 0.9237, Loss: 0.1323
Epoch  14 Batch   74/269 - Train Accuracy: 0.9337, Validation Accuracy: 0.9186, Loss: 0.1149
Epoch  14 Batch   75/269 - Train Accuracy: 0.9158, Validation Accuracy: 0.9153, Loss: 0.1189
Epoch  14 Batch   76/269 - Train Accuracy: 0.9056, Validation Accuracy: 0.9192, Loss: 0.1153
Epoch  14 Batch   77/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9219, Loss: 0.1099
Epoch  14 Batch   78/269 - Train Accuracy: 0.9285, Validation Accuracy: 0.9224, Loss: 0.1099
Epoch  14 Batch   79/269 - Train Accuracy: 0.9033, Validation Accuracy: 0.9132, Loss: 0.1089
Epoch  14 Batch   80/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.9141, Loss: 0.1108
Epoch  14 Batch   81/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.9254, Loss: 0.1304
Epoch  14 Batch   82/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9230, Loss: 0.1073
Epoch  14 Batch   83/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.9150, Loss: 0.1238
Epoch  14 Batch   84/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9071, Loss: 0.1084
Epoch  14 Batch   85/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9110, Loss: 0.1150
Epoch  14 Batch   86/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9177, Loss: 0.1135
Epoch  14 Batch   87/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9179, Loss: 0.1179
Epoch  14 Batch   88/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.9153, Loss: 0.1181
Epoch  14 Batch   89/269 - Train Accuracy: 0.9242, Validation Accuracy: 0.9219, Loss: 0.1178
Epoch  14 Batch   90/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.9122, Loss: 0.1199
Epoch  14 Batch   91/269 - Train Accuracy: 0.9286, Validation Accuracy: 0.9094, Loss: 0.1140
Epoch  14 Batch   92/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9140, Loss: 0.1147
Epoch  14 Batch   93/269 - Train Accuracy: 0.9208, Validation Accuracy: 0.9220, Loss: 0.1116
Epoch  14 Batch   94/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9182, Loss: 0.1284
Epoch  14 Batch   95/269 - Train Accuracy: 0.9126, Validation Accuracy: 0.9177, Loss: 0.1096
Epoch  14 Batch   96/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9123, Loss: 0.1193
Epoch  14 Batch   97/269 - Train Accuracy: 0.9127, Validation Accuracy: 0.9230, Loss: 0.1178
Epoch  14 Batch   98/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9151, Loss: 0.1165
Epoch  14 Batch   99/269 - Train Accuracy: 0.9060, Validation Accuracy: 0.9225, Loss: 0.1173
Epoch  14 Batch  100/269 - Train Accuracy: 0.9212, Validation Accuracy: 0.9178, Loss: 0.1145
Epoch  14 Batch  101/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9156, Loss: 0.1276
Epoch  14 Batch  102/269 - Train Accuracy: 0.9124, Validation Accuracy: 0.9214, Loss: 0.1119
Epoch  14 Batch  103/269 - Train Accuracy: 0.9190, Validation Accuracy: 0.9267, Loss: 0.1235
Epoch  14 Batch  104/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.9264, Loss: 0.1171
Epoch  14 Batch  105/269 - Train Accuracy: 0.9027, Validation Accuracy: 0.9269, Loss: 0.1157
Epoch  14 Batch  106/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9216, Loss: 0.1078
Epoch  14 Batch  107/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9201, Loss: 0.1169
Epoch  14 Batch  108/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9273, Loss: 0.1154
Epoch  14 Batch  109/269 - Train Accuracy: 0.8985, Validation Accuracy: 0.9295, Loss: 0.1181
Epoch  14 Batch  110/269 - Train Accuracy: 0.9226, Validation Accuracy: 0.9256, Loss: 0.1074
Epoch  14 Batch  111/269 - Train Accuracy: 0.9028, Validation Accuracy: 0.9239, Loss: 0.1232
Epoch  14 Batch  112/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.9231, Loss: 0.1205
Epoch  14 Batch  113/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9258, Loss: 0.1133
Epoch  14 Batch  114/269 - Train Accuracy: 0.9202, Validation Accuracy: 0.9200, Loss: 0.1150
Epoch  14 Batch  115/269 - Train Accuracy: 0.9033, Validation Accuracy: 0.9192, Loss: 0.1247
Epoch  14 Batch  116/269 - Train Accuracy: 0.9213, Validation Accuracy: 0.9198, Loss: 0.1169
Epoch  14 Batch  117/269 - Train Accuracy: 0.9113, Validation Accuracy: 0.9223, Loss: 0.1116
Epoch  14 Batch  118/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9239, Loss: 0.1085
Epoch  14 Batch  119/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9165, Loss: 0.1235
Epoch  14 Batch  120/269 - Train Accuracy: 0.9202, Validation Accuracy: 0.9249, Loss: 0.1102
Epoch  14 Batch  121/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9279, Loss: 0.1046
Epoch  14 Batch  122/269 - Train Accuracy: 0.9185, Validation Accuracy: 0.9310, Loss: 0.1113
Epoch  14 Batch  123/269 - Train Accuracy: 0.9091, Validation Accuracy: 0.9279, Loss: 0.1151
Epoch  14 Batch  124/269 - Train Accuracy: 0.9168, Validation Accuracy: 0.9189, Loss: 0.1040
Epoch  14 Batch  125/269 - Train Accuracy: 0.9221, Validation Accuracy: 0.9165, Loss: 0.1088
Epoch  14 Batch  126/269 - Train Accuracy: 0.9057, Validation Accuracy: 0.9157, Loss: 0.1155
Epoch  14 Batch  127/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9169, Loss: 0.1191
Epoch  14 Batch  128/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9278, Loss: 0.1156
Epoch  14 Batch  129/269 - Train Accuracy: 0.9073, Validation Accuracy: 0.9248, Loss: 0.1119
Epoch  14 Batch  130/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.9193, Loss: 0.1145
Epoch  14 Batch  131/269 - Train Accuracy: 0.9060, Validation Accuracy: 0.9205, Loss: 0.1139
Epoch  14 Batch  132/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.9227, Loss: 0.1157
Epoch  14 Batch  133/269 - Train Accuracy: 0.9220, Validation Accuracy: 0.9216, Loss: 0.1011
Epoch  14 Batch  134/269 - Train Accuracy: 0.9124, Validation Accuracy: 0.9142, Loss: 0.1161
Epoch  14 Batch  135/269 - Train Accuracy: 0.9251, Validation Accuracy: 0.9166, Loss: 0.1159
Epoch  14 Batch  136/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.9197, Loss: 0.1267
Epoch  14 Batch  137/269 - Train Accuracy: 0.9078, Validation Accuracy: 0.9260, Loss: 0.1234
Epoch  14 Batch  138/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9221, Loss: 0.1096
Epoch  14 Batch  139/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9148, Loss: 0.1009
Epoch  14 Batch  140/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.9156, Loss: 0.1215
Epoch  14 Batch  141/269 - Train Accuracy: 0.9108, Validation Accuracy: 0.9139, Loss: 0.1211
Epoch  14 Batch  142/269 - Train Accuracy: 0.9048, Validation Accuracy: 0.9134, Loss: 0.1050
Epoch  14 Batch  143/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9150, Loss: 0.1098
Epoch  14 Batch  144/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9171, Loss: 0.0977
Epoch  14 Batch  145/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9158, Loss: 0.1050
Epoch  14 Batch  146/269 - Train Accuracy: 0.9245, Validation Accuracy: 0.9195, Loss: 0.1042
Epoch  14 Batch  147/269 - Train Accuracy: 0.9226, Validation Accuracy: 0.9229, Loss: 0.1184
Epoch  14 Batch  148/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.9198, Loss: 0.1144
Epoch  14 Batch  149/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9195, Loss: 0.1202
Epoch  14 Batch  150/269 - Train Accuracy: 0.9179, Validation Accuracy: 0.9212, Loss: 0.1174
Epoch  14 Batch  151/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9236, Loss: 0.1098
Epoch  14 Batch  152/269 - Train Accuracy: 0.9189, Validation Accuracy: 0.9215, Loss: 0.1094
Epoch  14 Batch  153/269 - Train Accuracy: 0.9297, Validation Accuracy: 0.9213, Loss: 0.1044
Epoch  14 Batch  154/269 - Train Accuracy: 0.9236, Validation Accuracy: 0.9189, Loss: 0.1097
Epoch  14 Batch  155/269 - Train Accuracy: 0.9083, Validation Accuracy: 0.9240, Loss: 0.1064
Epoch  14 Batch  156/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9202, Loss: 0.1163
Epoch  14 Batch  157/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.9157, Loss: 0.1053
Epoch  14 Batch  158/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9222, Loss: 0.1130
Epoch  14 Batch  159/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9195, Loss: 0.1083
Epoch  14 Batch  160/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9190, Loss: 0.1071
Epoch  14 Batch  161/269 - Train Accuracy: 0.9162, Validation Accuracy: 0.9177, Loss: 0.1072
Epoch  14 Batch  162/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9172, Loss: 0.1120
Epoch  14 Batch  163/269 - Train Accuracy: 0.9301, Validation Accuracy: 0.9216, Loss: 0.1156
Epoch  14 Batch  164/269 - Train Accuracy: 0.9274, Validation Accuracy: 0.9283, Loss: 0.1117
Epoch  14 Batch  165/269 - Train Accuracy: 0.9245, Validation Accuracy: 0.9227, Loss: 0.1065
Epoch  14 Batch  166/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9223, Loss: 0.1094
Epoch  14 Batch  167/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9237, Loss: 0.1161
Epoch  14 Batch  168/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9249, Loss: 0.1132
Epoch  14 Batch  169/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9162, Loss: 0.1162
Epoch  14 Batch  170/269 - Train Accuracy: 0.9035, Validation Accuracy: 0.9184, Loss: 0.1044
Epoch  14 Batch  171/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9197, Loss: 0.1079
Epoch  14 Batch  172/269 - Train Accuracy: 0.9030, Validation Accuracy: 0.9161, Loss: 0.1245
Epoch  14 Batch  173/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9237, Loss: 0.1039
Epoch  14 Batch  174/269 - Train Accuracy: 0.9287, Validation Accuracy: 0.9229, Loss: 0.1120
Epoch  14 Batch  175/269 - Train Accuracy: 0.9035, Validation Accuracy: 0.9235, Loss: 0.1357
Epoch  14 Batch  176/269 - Train Accuracy: 0.8959, Validation Accuracy: 0.9147, Loss: 0.1231
Epoch  14 Batch  177/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9132, Loss: 0.1087
Epoch  14 Batch  178/269 - Train Accuracy: 0.9155, Validation Accuracy: 0.9195, Loss: 0.1105
Epoch  14 Batch  179/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9185, Loss: 0.1066
Epoch  14 Batch  180/269 - Train Accuracy: 0.9238, Validation Accuracy: 0.9280, Loss: 0.1036
Epoch  14 Batch  181/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.9251, Loss: 0.1155
Epoch  14 Batch  182/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9200, Loss: 0.1078
Epoch  14 Batch  183/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9176, Loss: 0.0941
Epoch  14 Batch  184/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.9189, Loss: 0.1150
Epoch  14 Batch  185/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9187, Loss: 0.1177
Epoch  14 Batch  186/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9270, Loss: 0.1019
Epoch  14 Batch  187/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9226, Loss: 0.1131
Epoch  14 Batch  188/269 - Train Accuracy: 0.9226, Validation Accuracy: 0.9233, Loss: 0.1026
Epoch  14 Batch  189/269 - Train Accuracy: 0.9191, Validation Accuracy: 0.9209, Loss: 0.1014
Epoch  14 Batch  190/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9111, Loss: 0.1033
Epoch  14 Batch  191/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.9217, Loss: 0.1065
Epoch  14 Batch  192/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9245, Loss: 0.1075
Epoch  14 Batch  193/269 - Train Accuracy: 0.9245, Validation Accuracy: 0.9256, Loss: 0.1094
Epoch  14 Batch  194/269 - Train Accuracy: 0.9078, Validation Accuracy: 0.9281, Loss: 0.1111
Epoch  14 Batch  195/269 - Train Accuracy: 0.9126, Validation Accuracy: 0.9248, Loss: 0.1097
Epoch  14 Batch  196/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9229, Loss: 0.1061
Epoch  14 Batch  197/269 - Train Accuracy: 0.9085, Validation Accuracy: 0.9213, Loss: 0.1109
Epoch  14 Batch  198/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9269, Loss: 0.1160
Epoch  14 Batch  199/269 - Train Accuracy: 0.9301, Validation Accuracy: 0.9223, Loss: 0.1101
Epoch  14 Batch  200/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9131, Loss: 0.1165
Epoch  14 Batch  201/269 - Train Accuracy: 0.9167, Validation Accuracy: 0.9199, Loss: 0.1194
Epoch  14 Batch  202/269 - Train Accuracy: 0.9112, Validation Accuracy: 0.9224, Loss: 0.1062
Epoch  14 Batch  203/269 - Train Accuracy: 0.9167, Validation Accuracy: 0.9244, Loss: 0.1184
Epoch  14 Batch  204/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9226, Loss: 0.1116
Epoch  14 Batch  205/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9205, Loss: 0.1060
Epoch  14 Batch  206/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.9238, Loss: 0.1205
Epoch  14 Batch  207/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9221, Loss: 0.1085
Epoch  14 Batch  208/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.9203, Loss: 0.1138
Epoch  14 Batch  209/269 - Train Accuracy: 0.9252, Validation Accuracy: 0.9138, Loss: 0.1003
Epoch  14 Batch  210/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9261, Loss: 0.1082
Epoch  14 Batch  211/269 - Train Accuracy: 0.9162, Validation Accuracy: 0.9330, Loss: 0.1163
Epoch  14 Batch  212/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9329, Loss: 0.1117
Epoch  14 Batch  213/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9208, Loss: 0.1075
Epoch  14 Batch  214/269 - Train Accuracy: 0.9045, Validation Accuracy: 0.9229, Loss: 0.1053
Epoch  14 Batch  215/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9352, Loss: 0.1071
Epoch  14 Batch  216/269 - Train Accuracy: 0.9132, Validation Accuracy: 0.9384, Loss: 0.1230
Epoch  14 Batch  217/269 - Train Accuracy: 0.9051, Validation Accuracy: 0.9313, Loss: 0.1148
Epoch  14 Batch  218/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9285, Loss: 0.1077
Epoch  14 Batch  219/269 - Train Accuracy: 0.9266, Validation Accuracy: 0.9334, Loss: 0.1137
Epoch  14 Batch  220/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9353, Loss: 0.1037
Epoch  14 Batch  221/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9265, Loss: 0.1084
Epoch  14 Batch  222/269 - Train Accuracy: 0.9298, Validation Accuracy: 0.9277, Loss: 0.1020
Epoch  14 Batch  223/269 - Train Accuracy: 0.9001, Validation Accuracy: 0.9293, Loss: 0.1017
Epoch  14 Batch  224/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9260, Loss: 0.1300
Epoch  14 Batch  225/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9302, Loss: 0.1046
Epoch  14 Batch  226/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9329, Loss: 0.1156
Epoch  14 Batch  227/269 - Train Accuracy: 0.9284, Validation Accuracy: 0.9223, Loss: 0.1186
Epoch  14 Batch  228/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9173, Loss: 0.1141
Epoch  14 Batch  229/269 - Train Accuracy: 0.9096, Validation Accuracy: 0.9258, Loss: 0.1183
Epoch  14 Batch  230/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9254, Loss: 0.1114
Epoch  14 Batch  231/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9250, Loss: 0.1266
Epoch  14 Batch  232/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9123, Loss: 0.1065
Epoch  14 Batch  233/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.9236, Loss: 0.1192
Epoch  14 Batch  234/269 - Train Accuracy: 0.9168, Validation Accuracy: 0.9220, Loss: 0.1030
Epoch  14 Batch  235/269 - Train Accuracy: 0.9388, Validation Accuracy: 0.9179, Loss: 0.1032
Epoch  14 Batch  236/269 - Train Accuracy: 0.9048, Validation Accuracy: 0.9144, Loss: 0.1005
Epoch  14 Batch  237/269 - Train Accuracy: 0.9179, Validation Accuracy: 0.9223, Loss: 0.1117
Epoch  14 Batch  238/269 - Train Accuracy: 0.9138, Validation Accuracy: 0.9227, Loss: 0.1055
Epoch  14 Batch  239/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.9228, Loss: 0.1108
Epoch  14 Batch  240/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9149, Loss: 0.0983
Epoch  14 Batch  241/269 - Train Accuracy: 0.9131, Validation Accuracy: 0.9181, Loss: 0.1194
Epoch  14 Batch  242/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9229, Loss: 0.1060
Epoch  14 Batch  243/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9181, Loss: 0.0991
Epoch  14 Batch  244/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9229, Loss: 0.1120
Epoch  14 Batch  245/269 - Train Accuracy: 0.8933, Validation Accuracy: 0.9263, Loss: 0.1092
Epoch  14 Batch  246/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9301, Loss: 0.1102
Epoch  14 Batch  247/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9300, Loss: 0.1116
Epoch  14 Batch  248/269 - Train Accuracy: 0.9225, Validation Accuracy: 0.9193, Loss: 0.1008
Epoch  14 Batch  249/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9214, Loss: 0.0970
Epoch  14 Batch  250/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9187, Loss: 0.1064
Epoch  14 Batch  251/269 - Train Accuracy: 0.9428, Validation Accuracy: 0.9266, Loss: 0.1002
Epoch  14 Batch  252/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9276, Loss: 0.0970
Epoch  14 Batch  253/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.9207, Loss: 0.1122
Epoch  14 Batch  254/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9171, Loss: 0.1023
Epoch  14 Batch  255/269 - Train Accuracy: 0.9185, Validation Accuracy: 0.9207, Loss: 0.1114
Epoch  14 Batch  256/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9243, Loss: 0.1076
Epoch  14 Batch  257/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.9271, Loss: 0.1179
Epoch  14 Batch  258/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9238, Loss: 0.1203
Epoch  14 Batch  259/269 - Train Accuracy: 0.9200, Validation Accuracy: 0.9197, Loss: 0.1071
Epoch  14 Batch  260/269 - Train Accuracy: 0.9130, Validation Accuracy: 0.9258, Loss: 0.1086
Epoch  14 Batch  261/269 - Train Accuracy: 0.9057, Validation Accuracy: 0.9308, Loss: 0.1095
Epoch  14 Batch  262/269 - Train Accuracy: 0.9271, Validation Accuracy: 0.9324, Loss: 0.1068
Epoch  14 Batch  263/269 - Train Accuracy: 0.9080, Validation Accuracy: 0.9237, Loss: 0.1069
Epoch  14 Batch  264/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9179, Loss: 0.1147
Epoch  14 Batch  265/269 - Train Accuracy: 0.9161, Validation Accuracy: 0.9213, Loss: 0.1075
Epoch  14 Batch  266/269 - Train Accuracy: 0.9204, Validation Accuracy: 0.9315, Loss: 0.1051
Epoch  14 Batch  267/269 - Train Accuracy: 0.9264, Validation Accuracy: 0.9257, Loss: 0.1133
Epoch  15 Batch    1/269 - Train Accuracy: 0.9180, Validation Accuracy: 0.9244, Loss: 0.0990
Epoch  15 Batch    2/269 - Train Accuracy: 0.9200, Validation Accuracy: 0.9225, Loss: 0.1079
Epoch  15 Batch    3/269 - Train Accuracy: 0.9311, Validation Accuracy: 0.9274, Loss: 0.1088
Epoch  15 Batch    4/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.9274, Loss: 0.1123
Epoch  15 Batch    5/269 - Train Accuracy: 0.9188, Validation Accuracy: 0.9244, Loss: 0.1065
Epoch  15 Batch    6/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9274, Loss: 0.0975
Epoch  15 Batch    7/269 - Train Accuracy: 0.9269, Validation Accuracy: 0.9292, Loss: 0.0990
Epoch  15 Batch    8/269 - Train Accuracy: 0.9350, Validation Accuracy: 0.9298, Loss: 0.1064
Epoch  15 Batch    9/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9282, Loss: 0.1112
Epoch  15 Batch   10/269 - Train Accuracy: 0.9178, Validation Accuracy: 0.9237, Loss: 0.1053
Epoch  15 Batch   11/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9231, Loss: 0.1122
Epoch  15 Batch   12/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9250, Loss: 0.1147
Epoch  15 Batch   13/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9222, Loss: 0.0963
Epoch  15 Batch   14/269 - Train Accuracy: 0.9120, Validation Accuracy: 0.9195, Loss: 0.1007
Epoch  15 Batch   15/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9206, Loss: 0.0946
Epoch  15 Batch   16/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9296, Loss: 0.1073
Epoch  15 Batch   17/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9266, Loss: 0.0885
Epoch  15 Batch   18/269 - Train Accuracy: 0.9200, Validation Accuracy: 0.9208, Loss: 0.1078
Epoch  15 Batch   19/269 - Train Accuracy: 0.9266, Validation Accuracy: 0.9159, Loss: 0.0954
Epoch  15 Batch   20/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9192, Loss: 0.1017
Epoch  15 Batch   21/269 - Train Accuracy: 0.8915, Validation Accuracy: 0.9219, Loss: 0.1156
Epoch  15 Batch   22/269 - Train Accuracy: 0.9379, Validation Accuracy: 0.9268, Loss: 0.0922
Epoch  15 Batch   23/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9297, Loss: 0.1087
Epoch  15 Batch   24/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9276, Loss: 0.1019
Epoch  15 Batch   25/269 - Train Accuracy: 0.9067, Validation Accuracy: 0.9170, Loss: 0.1104
Epoch  15 Batch   26/269 - Train Accuracy: 0.9243, Validation Accuracy: 0.9243, Loss: 0.0945
Epoch  15 Batch   27/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9280, Loss: 0.0966
Epoch  15 Batch   28/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.9261, Loss: 0.1180
Epoch  15 Batch   29/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9238, Loss: 0.1067
Epoch  15 Batch   30/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9278, Loss: 0.1047
Epoch  15 Batch   31/269 - Train Accuracy: 0.9234, Validation Accuracy: 0.9285, Loss: 0.1033
Epoch  15 Batch   32/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.9252, Loss: 0.0981
Epoch  15 Batch   33/269 - Train Accuracy: 0.9158, Validation Accuracy: 0.9275, Loss: 0.0930
Epoch  15 Batch   34/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9308, Loss: 0.1036
Epoch  15 Batch   35/269 - Train Accuracy: 0.9157, Validation Accuracy: 0.9285, Loss: 0.1103
Epoch  15 Batch   36/269 - Train Accuracy: 0.9000, Validation Accuracy: 0.9264, Loss: 0.1074
Epoch  15 Batch   37/269 - Train Accuracy: 0.9186, Validation Accuracy: 0.9185, Loss: 0.1048
Epoch  15 Batch   38/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9163, Loss: 0.1009
Epoch  15 Batch   39/269 - Train Accuracy: 0.9176, Validation Accuracy: 0.9242, Loss: 0.1019
Epoch  15 Batch   40/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9233, Loss: 0.1068
Epoch  15 Batch   41/269 - Train Accuracy: 0.9073, Validation Accuracy: 0.9247, Loss: 0.1119
Epoch  15 Batch   42/269 - Train Accuracy: 0.9310, Validation Accuracy: 0.9231, Loss: 0.0955
Epoch  15 Batch   43/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9258, Loss: 0.1105
Epoch  15 Batch   44/269 - Train Accuracy: 0.9201, Validation Accuracy: 0.9275, Loss: 0.1122
Epoch  15 Batch   45/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9232, Loss: 0.1102
Epoch  15 Batch   46/269 - Train Accuracy: 0.9114, Validation Accuracy: 0.9286, Loss: 0.0995
Epoch  15 Batch   47/269 - Train Accuracy: 0.9389, Validation Accuracy: 0.9309, Loss: 0.0900
Epoch  15 Batch   48/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9234, Loss: 0.0944
Epoch  15 Batch   49/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9263, Loss: 0.1032
Epoch  15 Batch   50/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9278, Loss: 0.1108
Epoch  15 Batch   51/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9297, Loss: 0.1014
Epoch  15 Batch   52/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9303, Loss: 0.0944
Epoch  15 Batch   53/269 - Train Accuracy: 0.9151, Validation Accuracy: 0.9274, Loss: 0.1128
Epoch  15 Batch   54/269 - Train Accuracy: 0.9173, Validation Accuracy: 0.9251, Loss: 0.1027
Epoch  15 Batch   55/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9284, Loss: 0.1014
Epoch  15 Batch   56/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9282, Loss: 0.1052
Epoch  15 Batch   57/269 - Train Accuracy: 0.9176, Validation Accuracy: 0.9316, Loss: 0.1167
Epoch  15 Batch   58/269 - Train Accuracy: 0.9174, Validation Accuracy: 0.9309, Loss: 0.1008
Epoch  15 Batch   59/269 - Train Accuracy: 0.9435, Validation Accuracy: 0.9313, Loss: 0.0883
Epoch  15 Batch   60/269 - Train Accuracy: 0.9185, Validation Accuracy: 0.9243, Loss: 0.0972
Epoch  15 Batch   61/269 - Train Accuracy: 0.9290, Validation Accuracy: 0.9263, Loss: 0.0921
Epoch  15 Batch   62/269 - Train Accuracy: 0.9200, Validation Accuracy: 0.9330, Loss: 0.1049
Epoch  15 Batch   63/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9272, Loss: 0.1134
Epoch  15 Batch   64/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9254, Loss: 0.0945
Epoch  15 Batch   65/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9213, Loss: 0.0988
Epoch  15 Batch   66/269 - Train Accuracy: 0.9056, Validation Accuracy: 0.9165, Loss: 0.1033
Epoch  15 Batch   67/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9189, Loss: 0.1093
Epoch  15 Batch   68/269 - Train Accuracy: 0.9096, Validation Accuracy: 0.9218, Loss: 0.1077
Epoch  15 Batch   69/269 - Train Accuracy: 0.9039, Validation Accuracy: 0.9202, Loss: 0.1210
Epoch  15 Batch   70/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9230, Loss: 0.1017
Epoch  15 Batch   71/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9197, Loss: 0.1118
Epoch  15 Batch   72/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9189, Loss: 0.1110
Epoch  15 Batch   73/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9236, Loss: 0.1127
Epoch  15 Batch   74/269 - Train Accuracy: 0.9445, Validation Accuracy: 0.9225, Loss: 0.0977
Epoch  15 Batch   75/269 - Train Accuracy: 0.9264, Validation Accuracy: 0.9205, Loss: 0.1061
Epoch  15 Batch   76/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.9229, Loss: 0.1012
Epoch  15 Batch   77/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9225, Loss: 0.0957
Epoch  15 Batch   78/269 - Train Accuracy: 0.9244, Validation Accuracy: 0.9216, Loss: 0.0982
Epoch  15 Batch   79/269 - Train Accuracy: 0.9167, Validation Accuracy: 0.9272, Loss: 0.1029
Epoch  15 Batch   80/269 - Train Accuracy: 0.9174, Validation Accuracy: 0.9238, Loss: 0.1029
Epoch  15 Batch   81/269 - Train Accuracy: 0.9091, Validation Accuracy: 0.9259, Loss: 0.1159
Epoch  15 Batch   82/269 - Train Accuracy: 0.9349, Validation Accuracy: 0.9284, Loss: 0.0937
Epoch  15 Batch   83/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.9276, Loss: 0.1115
Epoch  15 Batch   84/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9290, Loss: 0.0969
Epoch  15 Batch   85/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9275, Loss: 0.1015
Epoch  15 Batch   86/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9274, Loss: 0.0991
Epoch  15 Batch   87/269 - Train Accuracy: 0.9073, Validation Accuracy: 0.9333, Loss: 0.1079
Epoch  15 Batch   88/269 - Train Accuracy: 0.8973, Validation Accuracy: 0.9291, Loss: 0.1087
Epoch  15 Batch   89/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9302, Loss: 0.1008
Epoch  15 Batch   90/269 - Train Accuracy: 0.9181, Validation Accuracy: 0.9277, Loss: 0.1065
Epoch  15 Batch   91/269 - Train Accuracy: 0.9423, Validation Accuracy: 0.9236, Loss: 0.0925
Epoch  15 Batch   92/269 - Train Accuracy: 0.9361, Validation Accuracy: 0.9143, Loss: 0.0984
Epoch  15 Batch   93/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9186, Loss: 0.0947
Epoch  15 Batch   94/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.9281, Loss: 0.1149
Epoch  15 Batch   95/269 - Train Accuracy: 0.9257, Validation Accuracy: 0.9276, Loss: 0.0984
Epoch  15 Batch   96/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.9223, Loss: 0.1015
Epoch  15 Batch   97/269 - Train Accuracy: 0.9181, Validation Accuracy: 0.9214, Loss: 0.1030
Epoch  15 Batch   98/269 - Train Accuracy: 0.9302, Validation Accuracy: 0.9252, Loss: 0.1055
Epoch  15 Batch   99/269 - Train Accuracy: 0.9172, Validation Accuracy: 0.9306, Loss: 0.0980
Epoch  15 Batch  100/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9260, Loss: 0.1015
Epoch  15 Batch  101/269 - Train Accuracy: 0.9108, Validation Accuracy: 0.9260, Loss: 0.1162
Epoch  15 Batch  102/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9288, Loss: 0.0956
Epoch  15 Batch  103/269 - Train Accuracy: 0.9218, Validation Accuracy: 0.9303, Loss: 0.1084
Epoch  15 Batch  104/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9315, Loss: 0.0987
Epoch  15 Batch  105/269 - Train Accuracy: 0.9138, Validation Accuracy: 0.9316, Loss: 0.1004
Epoch  15 Batch  106/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9355, Loss: 0.0911
Epoch  15 Batch  107/269 - Train Accuracy: 0.9304, Validation Accuracy: 0.9304, Loss: 0.0998
Epoch  15 Batch  108/269 - Train Accuracy: 0.9276, Validation Accuracy: 0.9255, Loss: 0.1057
Epoch  15 Batch  109/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9235, Loss: 0.1068
Epoch  15 Batch  110/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9315, Loss: 0.0895
Epoch  15 Batch  111/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9328, Loss: 0.1115
Epoch  15 Batch  112/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9339, Loss: 0.1055
Epoch  15 Batch  113/269 - Train Accuracy: 0.9197, Validation Accuracy: 0.9340, Loss: 0.0987
Epoch  15 Batch  114/269 - Train Accuracy: 0.9218, Validation Accuracy: 0.9347, Loss: 0.1005
Epoch  15 Batch  115/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9304, Loss: 0.1053
Epoch  15 Batch  116/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9245, Loss: 0.1004
Epoch  15 Batch  117/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9246, Loss: 0.0983
Epoch  15 Batch  118/269 - Train Accuracy: 0.9326, Validation Accuracy: 0.9284, Loss: 0.0916
Epoch  15 Batch  119/269 - Train Accuracy: 0.9077, Validation Accuracy: 0.9308, Loss: 0.1063
Epoch  15 Batch  120/269 - Train Accuracy: 0.9231, Validation Accuracy: 0.9244, Loss: 0.1029
Epoch  15 Batch  121/269 - Train Accuracy: 0.9131, Validation Accuracy: 0.9272, Loss: 0.0923
Epoch  15 Batch  122/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9318, Loss: 0.0988
Epoch  15 Batch  123/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9243, Loss: 0.0986
Epoch  15 Batch  124/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9187, Loss: 0.0866
Epoch  15 Batch  125/269 - Train Accuracy: 0.9286, Validation Accuracy: 0.9174, Loss: 0.0953
Epoch  15 Batch  126/269 - Train Accuracy: 0.9130, Validation Accuracy: 0.9247, Loss: 0.1017
Epoch  15 Batch  127/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.9316, Loss: 0.1003
Epoch  15 Batch  128/269 - Train Accuracy: 0.9165, Validation Accuracy: 0.9254, Loss: 0.1057
Epoch  15 Batch  129/269 - Train Accuracy: 0.9082, Validation Accuracy: 0.9173, Loss: 0.0959
Epoch  15 Batch  130/269 - Train Accuracy: 0.9233, Validation Accuracy: 0.9227, Loss: 0.1100
Epoch  15 Batch  131/269 - Train Accuracy: 0.9063, Validation Accuracy: 0.9316, Loss: 0.0967
Epoch  15 Batch  132/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9279, Loss: 0.1067
Epoch  15 Batch  133/269 - Train Accuracy: 0.9315, Validation Accuracy: 0.9286, Loss: 0.0907
Epoch  15 Batch  134/269 - Train Accuracy: 0.9119, Validation Accuracy: 0.9234, Loss: 0.0979
Epoch  15 Batch  135/269 - Train Accuracy: 0.9248, Validation Accuracy: 0.9174, Loss: 0.1049
Epoch  15 Batch  136/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.9206, Loss: 0.1116
Epoch  15 Batch  137/269 - Train Accuracy: 0.9133, Validation Accuracy: 0.9276, Loss: 0.1053
Epoch  15 Batch  138/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9259, Loss: 0.0973
Epoch  15 Batch  139/269 - Train Accuracy: 0.9331, Validation Accuracy: 0.9213, Loss: 0.0945
Epoch  15 Batch  140/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9229, Loss: 0.1064
Epoch  15 Batch  141/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9249, Loss: 0.1076
Epoch  15 Batch  142/269 - Train Accuracy: 0.9149, Validation Accuracy: 0.9221, Loss: 0.0944
Epoch  15 Batch  143/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9259, Loss: 0.0957
Epoch  15 Batch  144/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9290, Loss: 0.0887
Epoch  15 Batch  145/269 - Train Accuracy: 0.9143, Validation Accuracy: 0.9258, Loss: 0.0956
Epoch  15 Batch  146/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9220, Loss: 0.0923
Epoch  15 Batch  147/269 - Train Accuracy: 0.9301, Validation Accuracy: 0.9242, Loss: 0.1006
Epoch  15 Batch  148/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.9281, Loss: 0.1012
Epoch  15 Batch  149/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.9278, Loss: 0.1069
Epoch  15 Batch  150/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9290, Loss: 0.1014
Epoch  15 Batch  151/269 - Train Accuracy: 0.9109, Validation Accuracy: 0.9261, Loss: 0.1030
Epoch  15 Batch  152/269 - Train Accuracy: 0.9251, Validation Accuracy: 0.9259, Loss: 0.1043
Epoch  15 Batch  153/269 - Train Accuracy: 0.9282, Validation Accuracy: 0.9233, Loss: 0.0949
Epoch  15 Batch  154/269 - Train Accuracy: 0.9263, Validation Accuracy: 0.9263, Loss: 0.0945
Epoch  15 Batch  155/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.9244, Loss: 0.0905
Epoch  15 Batch  156/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9233, Loss: 0.1085
Epoch  15 Batch  157/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.9209, Loss: 0.0944
Epoch  15 Batch  158/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9252, Loss: 0.0990
Epoch  15 Batch  159/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9273, Loss: 0.1068
Epoch  15 Batch  160/269 - Train Accuracy: 0.9264, Validation Accuracy: 0.9256, Loss: 0.0967
Epoch  15 Batch  161/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9267, Loss: 0.1006
Epoch  15 Batch  162/269 - Train Accuracy: 0.9262, Validation Accuracy: 0.9260, Loss: 0.0982
Epoch  15 Batch  163/269 - Train Accuracy: 0.9245, Validation Accuracy: 0.9312, Loss: 0.1011
Epoch  15 Batch  164/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9327, Loss: 0.0995
Epoch  15 Batch  165/269 - Train Accuracy: 0.9242, Validation Accuracy: 0.9254, Loss: 0.0981
Epoch  15 Batch  166/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9238, Loss: 0.0978
Epoch  15 Batch  167/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9272, Loss: 0.0953
Epoch  15 Batch  168/269 - Train Accuracy: 0.9212, Validation Accuracy: 0.9373, Loss: 0.1031
Epoch  15 Batch  169/269 - Train Accuracy: 0.9065, Validation Accuracy: 0.9350, Loss: 0.0993
Epoch  15 Batch  170/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9244, Loss: 0.0909
Epoch  15 Batch  171/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9280, Loss: 0.1015
Epoch  15 Batch  172/269 - Train Accuracy: 0.9158, Validation Accuracy: 0.9315, Loss: 0.1105
Epoch  15 Batch  173/269 - Train Accuracy: 0.9229, Validation Accuracy: 0.9300, Loss: 0.0904
Epoch  15 Batch  174/269 - Train Accuracy: 0.9373, Validation Accuracy: 0.9269, Loss: 0.1032
Epoch  15 Batch  175/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9282, Loss: 0.1201
Epoch  15 Batch  176/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.9268, Loss: 0.1061
Epoch  15 Batch  177/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9268, Loss: 0.0950
Epoch  15 Batch  178/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9219, Loss: 0.0976
Epoch  15 Batch  179/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9173, Loss: 0.0963
Epoch  15 Batch  180/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9205, Loss: 0.0952
Epoch  15 Batch  181/269 - Train Accuracy: 0.9194, Validation Accuracy: 0.9264, Loss: 0.1061
Epoch  15 Batch  182/269 - Train Accuracy: 0.9218, Validation Accuracy: 0.9273, Loss: 0.1003
Epoch  15 Batch  183/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9254, Loss: 0.0850
Epoch  15 Batch  184/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9261, Loss: 0.0952
Epoch  15 Batch  185/269 - Train Accuracy: 0.9276, Validation Accuracy: 0.9226, Loss: 0.1016
Epoch  15 Batch  186/269 - Train Accuracy: 0.9241, Validation Accuracy: 0.9205, Loss: 0.0942
Epoch  15 Batch  187/269 - Train Accuracy: 0.9201, Validation Accuracy: 0.9196, Loss: 0.0998
Epoch  15 Batch  188/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9252, Loss: 0.0903
Epoch  15 Batch  189/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9244, Loss: 0.0924
Epoch  15 Batch  190/269 - Train Accuracy: 0.9304, Validation Accuracy: 0.9276, Loss: 0.0906
Epoch  15 Batch  191/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9259, Loss: 0.0954
Epoch  15 Batch  192/269 - Train Accuracy: 0.9175, Validation Accuracy: 0.9229, Loss: 0.1006
Epoch  15 Batch  193/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9254, Loss: 0.0927
Epoch  15 Batch  194/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9243, Loss: 0.0998
Epoch  15 Batch  195/269 - Train Accuracy: 0.9138, Validation Accuracy: 0.9307, Loss: 0.1032
Epoch  15 Batch  196/269 - Train Accuracy: 0.9122, Validation Accuracy: 0.9282, Loss: 0.0946
Epoch  15 Batch  197/269 - Train Accuracy: 0.9123, Validation Accuracy: 0.9266, Loss: 0.1070
Epoch  15 Batch  198/269 - Train Accuracy: 0.9204, Validation Accuracy: 0.9316, Loss: 0.1052
Epoch  15 Batch  199/269 - Train Accuracy: 0.9320, Validation Accuracy: 0.9350, Loss: 0.1040
Epoch  15 Batch  200/269 - Train Accuracy: 0.9201, Validation Accuracy: 0.9236, Loss: 0.1007
Epoch  15 Batch  201/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9194, Loss: 0.1075
Epoch  15 Batch  202/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9284, Loss: 0.1048
Epoch  15 Batch  203/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9253, Loss: 0.1093
Epoch  15 Batch  204/269 - Train Accuracy: 0.9218, Validation Accuracy: 0.9193, Loss: 0.1220
Epoch  15 Batch  205/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9168, Loss: 0.0973
Epoch  15 Batch  206/269 - Train Accuracy: 0.9109, Validation Accuracy: 0.9184, Loss: 0.1179
Epoch  15 Batch  207/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.9014, Loss: 0.1013
Epoch  15 Batch  208/269 - Train Accuracy: 0.9236, Validation Accuracy: 0.9192, Loss: 0.1253
Epoch  15 Batch  209/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9166, Loss: 0.0947
Epoch  15 Batch  210/269 - Train Accuracy: 0.9233, Validation Accuracy: 0.9305, Loss: 0.1191
Epoch  15 Batch  211/269 - Train Accuracy: 0.8963, Validation Accuracy: 0.9106, Loss: 0.1022
Epoch  15 Batch  212/269 - Train Accuracy: 0.9212, Validation Accuracy: 0.9238, Loss: 0.1417
Epoch  15 Batch  213/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8975, Loss: 0.1031
Epoch  15 Batch  214/269 - Train Accuracy: 0.8999, Validation Accuracy: 0.9242, Loss: 0.1653
Epoch  15 Batch  215/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9047, Loss: 0.1182
Epoch  15 Batch  216/269 - Train Accuracy: 0.8926, Validation Accuracy: 0.8974, Loss: 0.1715
Epoch  15 Batch  217/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8905, Loss: 0.1492
Epoch  15 Batch  218/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9232, Loss: 0.1660
Epoch  15 Batch  219/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.9024, Loss: 0.1363
Epoch  15 Batch  220/269 - Train Accuracy: 0.9074, Validation Accuracy: 0.9046, Loss: 0.1386
Epoch  15 Batch  221/269 - Train Accuracy: 0.9048, Validation Accuracy: 0.8966, Loss: 0.1510
Epoch  15 Batch  222/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8791, Loss: 0.1169
Epoch  15 Batch  223/269 - Train Accuracy: 0.9030, Validation Accuracy: 0.9196, Loss: 0.1642
Epoch  15 Batch  224/269 - Train Accuracy: 0.8899, Validation Accuracy: 0.8981, Loss: 0.1281
Epoch  15 Batch  225/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8820, Loss: 0.1494
Epoch  15 Batch  226/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9221, Loss: 0.1432
Epoch  15 Batch  227/269 - Train Accuracy: 0.9066, Validation Accuracy: 0.8999, Loss: 0.1340
Epoch  15 Batch  228/269 - Train Accuracy: 0.9042, Validation Accuracy: 0.9069, Loss: 0.1421
Epoch  15 Batch  229/269 - Train Accuracy: 0.9141, Validation Accuracy: 0.9240, Loss: 0.1284
Epoch  15 Batch  230/269 - Train Accuracy: 0.9152, Validation Accuracy: 0.9105, Loss: 0.1110
Epoch  15 Batch  231/269 - Train Accuracy: 0.9051, Validation Accuracy: 0.9125, Loss: 0.1349
Epoch  15 Batch  232/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9183, Loss: 0.1311
Epoch  15 Batch  233/269 - Train Accuracy: 0.9213, Validation Accuracy: 0.9173, Loss: 0.1176
Epoch  15 Batch  234/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9237, Loss: 0.1185
Epoch  15 Batch  235/269 - Train Accuracy: 0.9346, Validation Accuracy: 0.9163, Loss: 0.0999
Epoch  15 Batch  236/269 - Train Accuracy: 0.8941, Validation Accuracy: 0.9182, Loss: 0.1146
Epoch  15 Batch  237/269 - Train Accuracy: 0.9201, Validation Accuracy: 0.9174, Loss: 0.1098
Epoch  15 Batch  238/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9171, Loss: 0.1079
Epoch  15 Batch  239/269 - Train Accuracy: 0.9120, Validation Accuracy: 0.9215, Loss: 0.1184
Epoch  15 Batch  240/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9189, Loss: 0.1081
Epoch  15 Batch  241/269 - Train Accuracy: 0.9120, Validation Accuracy: 0.9157, Loss: 0.1198
Epoch  15 Batch  242/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9164, Loss: 0.1089
Epoch  15 Batch  243/269 - Train Accuracy: 0.9177, Validation Accuracy: 0.9153, Loss: 0.1056
Epoch  15 Batch  244/269 - Train Accuracy: 0.9143, Validation Accuracy: 0.9213, Loss: 0.1086
Epoch  15 Batch  245/269 - Train Accuracy: 0.9145, Validation Accuracy: 0.9252, Loss: 0.1140
Epoch  15 Batch  246/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9232, Loss: 0.1127
Epoch  15 Batch  247/269 - Train Accuracy: 0.9167, Validation Accuracy: 0.9240, Loss: 0.1094
Epoch  15 Batch  248/269 - Train Accuracy: 0.9119, Validation Accuracy: 0.9252, Loss: 0.0980
Epoch  15 Batch  249/269 - Train Accuracy: 0.9207, Validation Accuracy: 0.9213, Loss: 0.0979
Epoch  15 Batch  250/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9222, Loss: 0.1017
Epoch  15 Batch  251/269 - Train Accuracy: 0.9467, Validation Accuracy: 0.9226, Loss: 0.0953
Epoch  15 Batch  252/269 - Train Accuracy: 0.9286, Validation Accuracy: 0.9262, Loss: 0.0948
Epoch  15 Batch  253/269 - Train Accuracy: 0.9095, Validation Accuracy: 0.9290, Loss: 0.1060
Epoch  15 Batch  254/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9286, Loss: 0.0982
Epoch  15 Batch  255/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9318, Loss: 0.1057
Epoch  15 Batch  256/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9260, Loss: 0.1036
Epoch  15 Batch  257/269 - Train Accuracy: 0.9035, Validation Accuracy: 0.9271, Loss: 0.1015
Epoch  15 Batch  258/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9291, Loss: 0.1035
Epoch  15 Batch  259/269 - Train Accuracy: 0.9277, Validation Accuracy: 0.9284, Loss: 0.1016
Epoch  15 Batch  260/269 - Train Accuracy: 0.9141, Validation Accuracy: 0.9296, Loss: 0.1055
Epoch  15 Batch  261/269 - Train Accuracy: 0.9092, Validation Accuracy: 0.9307, Loss: 0.0999
Epoch  15 Batch  262/269 - Train Accuracy: 0.9325, Validation Accuracy: 0.9310, Loss: 0.1013
Epoch  15 Batch  263/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9293, Loss: 0.1069
Epoch  15 Batch  264/269 - Train Accuracy: 0.9007, Validation Accuracy: 0.9301, Loss: 0.1083
Epoch  15 Batch  265/269 - Train Accuracy: 0.9180, Validation Accuracy: 0.9232, Loss: 0.0931
Epoch  15 Batch  266/269 - Train Accuracy: 0.9274, Validation Accuracy: 0.9278, Loss: 0.0904
Epoch  15 Batch  267/269 - Train Accuracy: 0.9262, Validation Accuracy: 0.9243, Loss: 0.1098
Epoch  16 Batch    1/269 - Train Accuracy: 0.9196, Validation Accuracy: 0.9316, Loss: 0.0981
Epoch  16 Batch    2/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9316, Loss: 0.0998
Epoch  16 Batch    3/269 - Train Accuracy: 0.9267, Validation Accuracy: 0.9285, Loss: 0.1013
Epoch  16 Batch    4/269 - Train Accuracy: 0.9037, Validation Accuracy: 0.9251, Loss: 0.1073
Epoch  16 Batch    5/269 - Train Accuracy: 0.9256, Validation Accuracy: 0.9277, Loss: 0.0975
Epoch  16 Batch    6/269 - Train Accuracy: 0.9331, Validation Accuracy: 0.9253, Loss: 0.0966
Epoch  16 Batch    7/269 - Train Accuracy: 0.9321, Validation Accuracy: 0.9293, Loss: 0.0922
Epoch  16 Batch    8/269 - Train Accuracy: 0.9366, Validation Accuracy: 0.9282, Loss: 0.1024
Epoch  16 Batch    9/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.9262, Loss: 0.1045
Epoch  16 Batch   10/269 - Train Accuracy: 0.9239, Validation Accuracy: 0.9293, Loss: 0.0934
Epoch  16 Batch   11/269 - Train Accuracy: 0.9215, Validation Accuracy: 0.9270, Loss: 0.1053
Epoch  16 Batch   12/269 - Train Accuracy: 0.9178, Validation Accuracy: 0.9259, Loss: 0.1027
Epoch  16 Batch   13/269 - Train Accuracy: 0.9288, Validation Accuracy: 0.9301, Loss: 0.0865
Epoch  16 Batch   14/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9298, Loss: 0.0988
Epoch  16 Batch   15/269 - Train Accuracy: 0.9273, Validation Accuracy: 0.9302, Loss: 0.0818
Epoch  16 Batch   16/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9336, Loss: 0.0971
Epoch  16 Batch   17/269 - Train Accuracy: 0.9204, Validation Accuracy: 0.9324, Loss: 0.0829
Epoch  16 Batch   18/269 - Train Accuracy: 0.9167, Validation Accuracy: 0.9316, Loss: 0.0994
Epoch  16 Batch   19/269 - Train Accuracy: 0.9337, Validation Accuracy: 0.9280, Loss: 0.0870
Epoch  16 Batch   20/269 - Train Accuracy: 0.9265, Validation Accuracy: 0.9273, Loss: 0.0940
Epoch  16 Batch   21/269 - Train Accuracy: 0.9005, Validation Accuracy: 0.9282, Loss: 0.1062
Epoch  16 Batch   22/269 - Train Accuracy: 0.9376, Validation Accuracy: 0.9301, Loss: 0.0887
Epoch  16 Batch   23/269 - Train Accuracy: 0.9215, Validation Accuracy: 0.9285, Loss: 0.0999
Epoch  16 Batch   24/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9306, Loss: 0.0916
Epoch  16 Batch   25/269 - Train Accuracy: 0.9050, Validation Accuracy: 0.9289, Loss: 0.1013
Epoch  16 Batch   26/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9299, Loss: 0.0899
Epoch  16 Batch   27/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9338, Loss: 0.0912
Epoch  16 Batch   28/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.9300, Loss: 0.1023
Epoch  16 Batch   29/269 - Train Accuracy: 0.9335, Validation Accuracy: 0.9308, Loss: 0.1044
Epoch  16 Batch   30/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9320, Loss: 0.0924
Epoch  16 Batch   31/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9334, Loss: 0.0963
Epoch  16 Batch   32/269 - Train Accuracy: 0.9378, Validation Accuracy: 0.9305, Loss: 0.0890
Epoch  16 Batch   33/269 - Train Accuracy: 0.9241, Validation Accuracy: 0.9289, Loss: 0.0889
Epoch  16 Batch   34/269 - Train Accuracy: 0.9252, Validation Accuracy: 0.9303, Loss: 0.0906
Epoch  16 Batch   35/269 - Train Accuracy: 0.9224, Validation Accuracy: 0.9243, Loss: 0.1035
Epoch  16 Batch   36/269 - Train Accuracy: 0.9083, Validation Accuracy: 0.9241, Loss: 0.0917
Epoch  16 Batch   37/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.9290, Loss: 0.0943
Epoch  16 Batch   38/269 - Train Accuracy: 0.9262, Validation Accuracy: 0.9374, Loss: 0.0928
Epoch  16 Batch   39/269 - Train Accuracy: 0.9305, Validation Accuracy: 0.9377, Loss: 0.0981
Epoch  16 Batch   40/269 - Train Accuracy: 0.9219, Validation Accuracy: 0.9343, Loss: 0.0984
Epoch  16 Batch   41/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9314, Loss: 0.0962
Epoch  16 Batch   42/269 - Train Accuracy: 0.9284, Validation Accuracy: 0.9292, Loss: 0.0821
Epoch  16 Batch   43/269 - Train Accuracy: 0.9224, Validation Accuracy: 0.9318, Loss: 0.0985
Epoch  16 Batch   44/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9312, Loss: 0.0935
Epoch  16 Batch   45/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9338, Loss: 0.0955
Epoch  16 Batch   46/269 - Train Accuracy: 0.9229, Validation Accuracy: 0.9362, Loss: 0.0906
Epoch  16 Batch   47/269 - Train Accuracy: 0.9362, Validation Accuracy: 0.9362, Loss: 0.0859
Epoch  16 Batch   48/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9372, Loss: 0.0837
Epoch  16 Batch   49/269 - Train Accuracy: 0.9284, Validation Accuracy: 0.9349, Loss: 0.0906
Epoch  16 Batch   50/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9406, Loss: 0.1054
Epoch  16 Batch   51/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9393, Loss: 0.0955
Epoch  16 Batch   52/269 - Train Accuracy: 0.9173, Validation Accuracy: 0.9363, Loss: 0.0810
Epoch  16 Batch   53/269 - Train Accuracy: 0.9220, Validation Accuracy: 0.9379, Loss: 0.1039
Epoch  16 Batch   54/269 - Train Accuracy: 0.9302, Validation Accuracy: 0.9351, Loss: 0.0911
Epoch  16 Batch   55/269 - Train Accuracy: 0.9376, Validation Accuracy: 0.9320, Loss: 0.0869
Epoch  16 Batch   56/269 - Train Accuracy: 0.9196, Validation Accuracy: 0.9308, Loss: 0.0957
Epoch  16 Batch   57/269 - Train Accuracy: 0.9201, Validation Accuracy: 0.9290, Loss: 0.1079
Epoch  16 Batch   58/269 - Train Accuracy: 0.9303, Validation Accuracy: 0.9315, Loss: 0.0906
Epoch  16 Batch   59/269 - Train Accuracy: 0.9509, Validation Accuracy: 0.9354, Loss: 0.0746
Epoch  16 Batch   60/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9380, Loss: 0.0884
Epoch  16 Batch   61/269 - Train Accuracy: 0.9317, Validation Accuracy: 0.9375, Loss: 0.0882
Epoch  16 Batch   62/269 - Train Accuracy: 0.9217, Validation Accuracy: 0.9335, Loss: 0.0911
Epoch  16 Batch   63/269 - Train Accuracy: 0.9234, Validation Accuracy: 0.9350, Loss: 0.1068
Epoch  16 Batch   64/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9344, Loss: 0.0831
Epoch  16 Batch   65/269 - Train Accuracy: 0.9226, Validation Accuracy: 0.9346, Loss: 0.0895
Epoch  16 Batch   66/269 - Train Accuracy: 0.9128, Validation Accuracy: 0.9361, Loss: 0.0915
Epoch  16 Batch   67/269 - Train Accuracy: 0.9213, Validation Accuracy: 0.9330, Loss: 0.0950
Epoch  16 Batch   68/269 - Train Accuracy: 0.9207, Validation Accuracy: 0.9283, Loss: 0.0989
Epoch  16 Batch   69/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9323, Loss: 0.1104
Epoch  16 Batch   70/269 - Train Accuracy: 0.9332, Validation Accuracy: 0.9352, Loss: 0.0955
Epoch  16 Batch   71/269 - Train Accuracy: 0.9255, Validation Accuracy: 0.9381, Loss: 0.1030
Epoch  16 Batch   72/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9318, Loss: 0.1009
Epoch  16 Batch   73/269 - Train Accuracy: 0.9180, Validation Accuracy: 0.9323, Loss: 0.0996
Epoch  16 Batch   74/269 - Train Accuracy: 0.9398, Validation Accuracy: 0.9278, Loss: 0.0971
Epoch  16 Batch   75/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9259, Loss: 0.0980
Epoch  16 Batch   76/269 - Train Accuracy: 0.9178, Validation Accuracy: 0.9273, Loss: 0.0911
Epoch  16 Batch   77/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9250, Loss: 0.0887
Epoch  16 Batch   78/269 - Train Accuracy: 0.9288, Validation Accuracy: 0.9288, Loss: 0.0884
Epoch  16 Batch   79/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9300, Loss: 0.0859
Epoch  16 Batch   80/269 - Train Accuracy: 0.9267, Validation Accuracy: 0.9244, Loss: 0.0930
Epoch  16 Batch   81/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9261, Loss: 0.1030
Epoch  16 Batch   82/269 - Train Accuracy: 0.9392, Validation Accuracy: 0.9276, Loss: 0.0827
Epoch  16 Batch   83/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9290, Loss: 0.1031
Epoch  16 Batch   84/269 - Train Accuracy: 0.9354, Validation Accuracy: 0.9314, Loss: 0.0875
Epoch  16 Batch   85/269 - Train Accuracy: 0.9328, Validation Accuracy: 0.9290, Loss: 0.0900
Epoch  16 Batch   86/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9288, Loss: 0.0845
Epoch  16 Batch   87/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9272, Loss: 0.0949
Epoch  16 Batch   88/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.9218, Loss: 0.0906
Epoch  16 Batch   89/269 - Train Accuracy: 0.9201, Validation Accuracy: 0.9229, Loss: 0.0962
Epoch  16 Batch   90/269 - Train Accuracy: 0.9259, Validation Accuracy: 0.9302, Loss: 0.1013
Epoch  16 Batch   91/269 - Train Accuracy: 0.9355, Validation Accuracy: 0.9287, Loss: 0.0894
Epoch  16 Batch   92/269 - Train Accuracy: 0.9382, Validation Accuracy: 0.9247, Loss: 0.0860
Epoch  16 Batch   93/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9269, Loss: 0.0895
Epoch  16 Batch   94/269 - Train Accuracy: 0.9165, Validation Accuracy: 0.9225, Loss: 0.1054
Epoch  16 Batch   95/269 - Train Accuracy: 0.9290, Validation Accuracy: 0.9239, Loss: 0.0880
Epoch  16 Batch   96/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9263, Loss: 0.0960
Epoch  16 Batch   97/269 - Train Accuracy: 0.9242, Validation Accuracy: 0.9275, Loss: 0.0955
Epoch  16 Batch   98/269 - Train Accuracy: 0.9307, Validation Accuracy: 0.9256, Loss: 0.0950
Epoch  16 Batch   99/269 - Train Accuracy: 0.9245, Validation Accuracy: 0.9292, Loss: 0.0909
Epoch  16 Batch  100/269 - Train Accuracy: 0.9328, Validation Accuracy: 0.9358, Loss: 0.0889
Epoch  16 Batch  101/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.9311, Loss: 0.1036
Epoch  16 Batch  102/269 - Train Accuracy: 0.9285, Validation Accuracy: 0.9322, Loss: 0.0849
Epoch  16 Batch  103/269 - Train Accuracy: 0.9304, Validation Accuracy: 0.9310, Loss: 0.0978
Epoch  16 Batch  104/269 - Train Accuracy: 0.9189, Validation Accuracy: 0.9268, Loss: 0.0929
Epoch  16 Batch  105/269 - Train Accuracy: 0.9210, Validation Accuracy: 0.9326, Loss: 0.0901
Epoch  16 Batch  106/269 - Train Accuracy: 0.9374, Validation Accuracy: 0.9313, Loss: 0.0855
Epoch  16 Batch  107/269 - Train Accuracy: 0.9372, Validation Accuracy: 0.9325, Loss: 0.0915
Epoch  16 Batch  108/269 - Train Accuracy: 0.9388, Validation Accuracy: 0.9324, Loss: 0.0888
Epoch  16 Batch  109/269 - Train Accuracy: 0.9065, Validation Accuracy: 0.9243, Loss: 0.0993
Epoch  16 Batch  110/269 - Train Accuracy: 0.9189, Validation Accuracy: 0.9260, Loss: 0.0878
Epoch  16 Batch  111/269 - Train Accuracy: 0.9229, Validation Accuracy: 0.9322, Loss: 0.1009
Epoch  16 Batch  112/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9363, Loss: 0.0916
Epoch  16 Batch  113/269 - Train Accuracy: 0.9276, Validation Accuracy: 0.9372, Loss: 0.0914
Epoch  16 Batch  114/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9361, Loss: 0.0893
Epoch  16 Batch  115/269 - Train Accuracy: 0.9213, Validation Accuracy: 0.9318, Loss: 0.0926
Epoch  16 Batch  116/269 - Train Accuracy: 0.9294, Validation Accuracy: 0.9204, Loss: 0.0906
Epoch  16 Batch  117/269 - Train Accuracy: 0.9272, Validation Accuracy: 0.9190, Loss: 0.0928
Epoch  16 Batch  118/269 - Train Accuracy: 0.9273, Validation Accuracy: 0.9236, Loss: 0.0845
Epoch  16 Batch  119/269 - Train Accuracy: 0.9117, Validation Accuracy: 0.9261, Loss: 0.0981
Epoch  16 Batch  120/269 - Train Accuracy: 0.9256, Validation Accuracy: 0.9304, Loss: 0.0983
Epoch  16 Batch  121/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9337, Loss: 0.0876
Epoch  16 Batch  122/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9353, Loss: 0.0910
Epoch  16 Batch  123/269 - Train Accuracy: 0.9240, Validation Accuracy: 0.9290, Loss: 0.0861
Epoch  16 Batch  124/269 - Train Accuracy: 0.9233, Validation Accuracy: 0.9278, Loss: 0.0840
Epoch  16 Batch  125/269 - Train Accuracy: 0.9402, Validation Accuracy: 0.9305, Loss: 0.0848
Epoch  16 Batch  126/269 - Train Accuracy: 0.9165, Validation Accuracy: 0.9283, Loss: 0.0853
Epoch  16 Batch  127/269 - Train Accuracy: 0.9175, Validation Accuracy: 0.9312, Loss: 0.0927
Epoch  16 Batch  128/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9345, Loss: 0.0944
Epoch  16 Batch  129/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.9296, Loss: 0.0891
Epoch  16 Batch  130/269 - Train Accuracy: 0.9356, Validation Accuracy: 0.9292, Loss: 0.0994
Epoch  16 Batch  131/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.9329, Loss: 0.0918
Epoch  16 Batch  132/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9314, Loss: 0.0911
Epoch  16 Batch  133/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9334, Loss: 0.0873
Epoch  16 Batch  134/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9349, Loss: 0.0914
Epoch  16 Batch  135/269 - Train Accuracy: 0.9354, Validation Accuracy: 0.9336, Loss: 0.0927
Epoch  16 Batch  136/269 - Train Accuracy: 0.9041, Validation Accuracy: 0.9302, Loss: 0.0968
Epoch  16 Batch  137/269 - Train Accuracy: 0.9085, Validation Accuracy: 0.9295, Loss: 0.1030
Epoch  16 Batch  138/269 - Train Accuracy: 0.9242, Validation Accuracy: 0.9240, Loss: 0.0909
Epoch  16 Batch  139/269 - Train Accuracy: 0.9273, Validation Accuracy: 0.9269, Loss: 0.0895
Epoch  16 Batch  140/269 - Train Accuracy: 0.9219, Validation Accuracy: 0.9268, Loss: 0.0973
Epoch  16 Batch  141/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9307, Loss: 0.0929
Epoch  16 Batch  142/269 - Train Accuracy: 0.9263, Validation Accuracy: 0.9324, Loss: 0.0866
Epoch  16 Batch  143/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9286, Loss: 0.0808
Epoch  16 Batch  144/269 - Train Accuracy: 0.9356, Validation Accuracy: 0.9285, Loss: 0.0795
Epoch  16 Batch  145/269 - Train Accuracy: 0.9271, Validation Accuracy: 0.9271, Loss: 0.0896
Epoch  16 Batch  146/269 - Train Accuracy: 0.9322, Validation Accuracy: 0.9276, Loss: 0.0903
Epoch  16 Batch  147/269 - Train Accuracy: 0.9302, Validation Accuracy: 0.9280, Loss: 0.0950
Epoch  16 Batch  148/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9258, Loss: 0.0961
Epoch  16 Batch  149/269 - Train Accuracy: 0.9132, Validation Accuracy: 0.9211, Loss: 0.1016
Epoch  16 Batch  150/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9185, Loss: 0.0941
Epoch  16 Batch  151/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9194, Loss: 0.0969
Epoch  16 Batch  152/269 - Train Accuracy: 0.9321, Validation Accuracy: 0.9234, Loss: 0.0884
Epoch  16 Batch  153/269 - Train Accuracy: 0.9297, Validation Accuracy: 0.9308, Loss: 0.0893
Epoch  16 Batch  154/269 - Train Accuracy: 0.9347, Validation Accuracy: 0.9283, Loss: 0.0850
Epoch  16 Batch  155/269 - Train Accuracy: 0.9127, Validation Accuracy: 0.9244, Loss: 0.0859
Epoch  16 Batch  156/269 - Train Accuracy: 0.9219, Validation Accuracy: 0.9323, Loss: 0.0938
Epoch  16 Batch  157/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9315, Loss: 0.0852
Epoch  16 Batch  158/269 - Train Accuracy: 0.9201, Validation Accuracy: 0.9322, Loss: 0.0921
Epoch  16 Batch  159/269 - Train Accuracy: 0.9190, Validation Accuracy: 0.9296, Loss: 0.0944
Epoch  16 Batch  160/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9308, Loss: 0.0918
Epoch  16 Batch  161/269 - Train Accuracy: 0.9321, Validation Accuracy: 0.9330, Loss: 0.0860
Epoch  16 Batch  162/269 - Train Accuracy: 0.9339, Validation Accuracy: 0.9302, Loss: 0.0831
Epoch  16 Batch  163/269 - Train Accuracy: 0.9485, Validation Accuracy: 0.9279, Loss: 0.0910
Epoch  16 Batch  164/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9277, Loss: 0.0909
Epoch  16 Batch  165/269 - Train Accuracy: 0.9288, Validation Accuracy: 0.9280, Loss: 0.0896
Epoch  16 Batch  166/269 - Train Accuracy: 0.9267, Validation Accuracy: 0.9312, Loss: 0.0876
Epoch  16 Batch  167/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9335, Loss: 0.0859
Epoch  16 Batch  168/269 - Train Accuracy: 0.9212, Validation Accuracy: 0.9339, Loss: 0.0918
Epoch  16 Batch  169/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9387, Loss: 0.0891
Epoch  16 Batch  170/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9371, Loss: 0.0824
Epoch  16 Batch  171/269 - Train Accuracy: 0.9414, Validation Accuracy: 0.9331, Loss: 0.0890
Epoch  16 Batch  172/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9288, Loss: 0.0984
Epoch  16 Batch  173/269 - Train Accuracy: 0.9267, Validation Accuracy: 0.9284, Loss: 0.0835
Epoch  16 Batch  174/269 - Train Accuracy: 0.9351, Validation Accuracy: 0.9237, Loss: 0.0915
Epoch  16 Batch  175/269 - Train Accuracy: 0.9132, Validation Accuracy: 0.9240, Loss: 0.1034
Epoch  16 Batch  176/269 - Train Accuracy: 0.9072, Validation Accuracy: 0.9233, Loss: 0.1003
Epoch  16 Batch  177/269 - Train Accuracy: 0.9355, Validation Accuracy: 0.9287, Loss: 0.0865
Epoch  16 Batch  178/269 - Train Accuracy: 0.9336, Validation Accuracy: 0.9314, Loss: 0.0867
Epoch  16 Batch  179/269 - Train Accuracy: 0.9224, Validation Accuracy: 0.9323, Loss: 0.0875
Epoch  16 Batch  180/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9308, Loss: 0.0834
Epoch  16 Batch  181/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9276, Loss: 0.0908
Epoch  16 Batch  182/269 - Train Accuracy: 0.9255, Validation Accuracy: 0.9342, Loss: 0.0891
Epoch  16 Batch  183/269 - Train Accuracy: 0.9257, Validation Accuracy: 0.9382, Loss: 0.0748
Epoch  16 Batch  184/269 - Train Accuracy: 0.9234, Validation Accuracy: 0.9418, Loss: 0.0868
Epoch  16 Batch  185/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9405, Loss: 0.0848
Epoch  16 Batch  186/269 - Train Accuracy: 0.9308, Validation Accuracy: 0.9362, Loss: 0.0827
Epoch  16 Batch  187/269 - Train Accuracy: 0.9224, Validation Accuracy: 0.9325, Loss: 0.0863
Epoch  16 Batch  188/269 - Train Accuracy: 0.9207, Validation Accuracy: 0.9334, Loss: 0.0841
Epoch  16 Batch  189/269 - Train Accuracy: 0.9254, Validation Accuracy: 0.9321, Loss: 0.0856
Epoch  16 Batch  190/269 - Train Accuracy: 0.9263, Validation Accuracy: 0.9330, Loss: 0.0865
Epoch  16 Batch  191/269 - Train Accuracy: 0.9213, Validation Accuracy: 0.9341, Loss: 0.0902
Epoch  16 Batch  192/269 - Train Accuracy: 0.9293, Validation Accuracy: 0.9355, Loss: 0.0923
Epoch  16 Batch  193/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9356, Loss: 0.0867
Epoch  16 Batch  194/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9363, Loss: 0.0907
Epoch  16 Batch  195/269 - Train Accuracy: 0.9229, Validation Accuracy: 0.9331, Loss: 0.0852
Epoch  16 Batch  196/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9307, Loss: 0.0802
Epoch  16 Batch  197/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9289, Loss: 0.0882
Epoch  16 Batch  198/269 - Train Accuracy: 0.9276, Validation Accuracy: 0.9288, Loss: 0.0940
Epoch  16 Batch  199/269 - Train Accuracy: 0.9345, Validation Accuracy: 0.9232, Loss: 0.0908
Epoch  16 Batch  200/269 - Train Accuracy: 0.9224, Validation Accuracy: 0.9272, Loss: 0.0897
Epoch  16 Batch  201/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9277, Loss: 0.0950
Epoch  16 Batch  202/269 - Train Accuracy: 0.9286, Validation Accuracy: 0.9287, Loss: 0.0880
Epoch  16 Batch  203/269 - Train Accuracy: 0.9229, Validation Accuracy: 0.9317, Loss: 0.0963
Epoch  16 Batch  204/269 - Train Accuracy: 0.9273, Validation Accuracy: 0.9378, Loss: 0.0951
Epoch  16 Batch  205/269 - Train Accuracy: 0.9349, Validation Accuracy: 0.9397, Loss: 0.0853
Epoch  16 Batch  206/269 - Train Accuracy: 0.9219, Validation Accuracy: 0.9412, Loss: 0.0957
Epoch  16 Batch  207/269 - Train Accuracy: 0.9168, Validation Accuracy: 0.9419, Loss: 0.0851
Epoch  16 Batch  208/269 - Train Accuracy: 0.9197, Validation Accuracy: 0.9404, Loss: 0.0930
Epoch  16 Batch  209/269 - Train Accuracy: 0.9343, Validation Accuracy: 0.9387, Loss: 0.0825
Epoch  16 Batch  210/269 - Train Accuracy: 0.9327, Validation Accuracy: 0.9313, Loss: 0.0814
Epoch  16 Batch  211/269 - Train Accuracy: 0.9277, Validation Accuracy: 0.9346, Loss: 0.0945
Epoch  16 Batch  212/269 - Train Accuracy: 0.9190, Validation Accuracy: 0.9368, Loss: 0.0961
Epoch  16 Batch  213/269 - Train Accuracy: 0.9191, Validation Accuracy: 0.9362, Loss: 0.0835
Epoch  16 Batch  214/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9291, Loss: 0.0890
Epoch  16 Batch  215/269 - Train Accuracy: 0.9315, Validation Accuracy: 0.9328, Loss: 0.0854
Epoch  16 Batch  216/269 - Train Accuracy: 0.9203, Validation Accuracy: 0.9375, Loss: 0.1029
Epoch  16 Batch  217/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9366, Loss: 0.0903
Epoch  16 Batch  218/269 - Train Accuracy: 0.9330, Validation Accuracy: 0.9347, Loss: 0.0847
Epoch  16 Batch  219/269 - Train Accuracy: 0.9284, Validation Accuracy: 0.9392, Loss: 0.0931
Epoch  16 Batch  220/269 - Train Accuracy: 0.9331, Validation Accuracy: 0.9400, Loss: 0.0838
Epoch  16 Batch  221/269 - Train Accuracy: 0.9338, Validation Accuracy: 0.9411, Loss: 0.0881
Epoch  16 Batch  222/269 - Train Accuracy: 0.9391, Validation Accuracy: 0.9387, Loss: 0.0778
Epoch  16 Batch  223/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9363, Loss: 0.0913
Epoch  16 Batch  224/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9340, Loss: 0.1006
Epoch  16 Batch  225/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9291, Loss: 0.0848
Epoch  16 Batch  226/269 - Train Accuracy: 0.9191, Validation Accuracy: 0.9281, Loss: 0.0905
Epoch  16 Batch  227/269 - Train Accuracy: 0.9361, Validation Accuracy: 0.9311, Loss: 0.0971
Epoch  16 Batch  228/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9417, Loss: 0.0896
Epoch  16 Batch  229/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9405, Loss: 0.0855
Epoch  16 Batch  230/269 - Train Accuracy: 0.9352, Validation Accuracy: 0.9363, Loss: 0.0880
Epoch  16 Batch  231/269 - Train Accuracy: 0.9297, Validation Accuracy: 0.9285, Loss: 0.0918
Epoch  16 Batch  232/269 - Train Accuracy: 0.9168, Validation Accuracy: 0.9280, Loss: 0.0857
Epoch  16 Batch  233/269 - Train Accuracy: 0.9323, Validation Accuracy: 0.9299, Loss: 0.0934
Epoch  16 Batch  234/269 - Train Accuracy: 0.9290, Validation Accuracy: 0.9376, Loss: 0.0870
Epoch  16 Batch  235/269 - Train Accuracy: 0.9475, Validation Accuracy: 0.9356, Loss: 0.0803
Epoch  16 Batch  236/269 - Train Accuracy: 0.9174, Validation Accuracy: 0.9332, Loss: 0.0864
Epoch  16 Batch  237/269 - Train Accuracy: 0.9330, Validation Accuracy: 0.9361, Loss: 0.0821
Epoch  16 Batch  238/269 - Train Accuracy: 0.9233, Validation Accuracy: 0.9263, Loss: 0.0869
Epoch  16 Batch  239/269 - Train Accuracy: 0.9236, Validation Accuracy: 0.9247, Loss: 0.0889
Epoch  16 Batch  240/269 - Train Accuracy: 0.9333, Validation Accuracy: 0.9249, Loss: 0.0823
Epoch  16 Batch  241/269 - Train Accuracy: 0.9307, Validation Accuracy: 0.9242, Loss: 0.0968
Epoch  16 Batch  242/269 - Train Accuracy: 0.9411, Validation Accuracy: 0.9215, Loss: 0.0826
Epoch  16 Batch  243/269 - Train Accuracy: 0.9391, Validation Accuracy: 0.9268, Loss: 0.0790
Epoch  16 Batch  244/269 - Train Accuracy: 0.9217, Validation Accuracy: 0.9320, Loss: 0.0920
Epoch  16 Batch  245/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9322, Loss: 0.0859
Epoch  16 Batch  246/269 - Train Accuracy: 0.9239, Validation Accuracy: 0.9277, Loss: 0.0956
Epoch  16 Batch  247/269 - Train Accuracy: 0.9215, Validation Accuracy: 0.9263, Loss: 0.0890
Epoch  16 Batch  248/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9277, Loss: 0.0825
Epoch  16 Batch  249/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9400, Loss: 0.0803
Epoch  16 Batch  250/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9352, Loss: 0.0837
Epoch  16 Batch  251/269 - Train Accuracy: 0.9468, Validation Accuracy: 0.9368, Loss: 0.0841
Epoch  16 Batch  252/269 - Train Accuracy: 0.9340, Validation Accuracy: 0.9408, Loss: 0.0810
Epoch  16 Batch  253/269 - Train Accuracy: 0.9098, Validation Accuracy: 0.9333, Loss: 0.0951
Epoch  16 Batch  254/269 - Train Accuracy: 0.9244, Validation Accuracy: 0.9365, Loss: 0.0832
Epoch  16 Batch  255/269 - Train Accuracy: 0.9295, Validation Accuracy: 0.9332, Loss: 0.0887
Epoch  16 Batch  256/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9315, Loss: 0.0824
Epoch  16 Batch  257/269 - Train Accuracy: 0.9093, Validation Accuracy: 0.9297, Loss: 0.0906
Epoch  16 Batch  258/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9284, Loss: 0.0958
Epoch  16 Batch  259/269 - Train Accuracy: 0.9257, Validation Accuracy: 0.9277, Loss: 0.0865
Epoch  16 Batch  260/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9322, Loss: 0.0943
Epoch  16 Batch  261/269 - Train Accuracy: 0.9263, Validation Accuracy: 0.9341, Loss: 0.0910
Epoch  16 Batch  262/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9329, Loss: 0.0914
Epoch  16 Batch  263/269 - Train Accuracy: 0.9232, Validation Accuracy: 0.9378, Loss: 0.0891
Epoch  16 Batch  264/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9411, Loss: 0.0928
Epoch  16 Batch  265/269 - Train Accuracy: 0.9276, Validation Accuracy: 0.9398, Loss: 0.0865
Epoch  16 Batch  266/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9379, Loss: 0.0814
Epoch  16 Batch  267/269 - Train Accuracy: 0.9376, Validation Accuracy: 0.9331, Loss: 0.0932
Epoch  17 Batch    1/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9345, Loss: 0.0858
Epoch  17 Batch    2/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9324, Loss: 0.0891
Epoch  17 Batch    3/269 - Train Accuracy: 0.9331, Validation Accuracy: 0.9302, Loss: 0.0890
Epoch  17 Batch    4/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9299, Loss: 0.0917
Epoch  17 Batch    5/269 - Train Accuracy: 0.9317, Validation Accuracy: 0.9319, Loss: 0.0855
Epoch  17 Batch    6/269 - Train Accuracy: 0.9351, Validation Accuracy: 0.9294, Loss: 0.0825
Epoch  17 Batch    7/269 - Train Accuracy: 0.9372, Validation Accuracy: 0.9264, Loss: 0.0841
Epoch  17 Batch    8/269 - Train Accuracy: 0.9453, Validation Accuracy: 0.9265, Loss: 0.0863
Epoch  17 Batch    9/269 - Train Accuracy: 0.9224, Validation Accuracy: 0.9320, Loss: 0.0968
Epoch  17 Batch   10/269 - Train Accuracy: 0.9343, Validation Accuracy: 0.9333, Loss: 0.0846
Epoch  17 Batch   11/269 - Train Accuracy: 0.9299, Validation Accuracy: 0.9379, Loss: 0.0921
Epoch  17 Batch   12/269 - Train Accuracy: 0.9250, Validation Accuracy: 0.9375, Loss: 0.0969
Epoch  17 Batch   13/269 - Train Accuracy: 0.9302, Validation Accuracy: 0.9379, Loss: 0.0769
Epoch  17 Batch   14/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9342, Loss: 0.0790
Epoch  17 Batch   15/269 - Train Accuracy: 0.9421, Validation Accuracy: 0.9326, Loss: 0.0700
Epoch  17 Batch   16/269 - Train Accuracy: 0.9259, Validation Accuracy: 0.9305, Loss: 0.0956
Epoch  17 Batch   17/269 - Train Accuracy: 0.9318, Validation Accuracy: 0.9306, Loss: 0.0778
Epoch  17 Batch   18/269 - Train Accuracy: 0.9215, Validation Accuracy: 0.9287, Loss: 0.0857
Epoch  17 Batch   19/269 - Train Accuracy: 0.9376, Validation Accuracy: 0.9362, Loss: 0.0765
Epoch  17 Batch   20/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9322, Loss: 0.0866
Epoch  17 Batch   21/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9348, Loss: 0.0947
Epoch  17 Batch   22/269 - Train Accuracy: 0.9469, Validation Accuracy: 0.9332, Loss: 0.0781
Epoch  17 Batch   23/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9372, Loss: 0.0893
Epoch  17 Batch   24/269 - Train Accuracy: 0.9255, Validation Accuracy: 0.9355, Loss: 0.0831
Epoch  17 Batch   25/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9327, Loss: 0.0923
Epoch  17 Batch   26/269 - Train Accuracy: 0.9244, Validation Accuracy: 0.9358, Loss: 0.0846
Epoch  17 Batch   27/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9371, Loss: 0.0840
Epoch  17 Batch   28/269 - Train Accuracy: 0.9194, Validation Accuracy: 0.9395, Loss: 0.0967
Epoch  17 Batch   29/269 - Train Accuracy: 0.9382, Validation Accuracy: 0.9398, Loss: 0.0895
Epoch  17 Batch   30/269 - Train Accuracy: 0.9371, Validation Accuracy: 0.9399, Loss: 0.0815
Epoch  17 Batch   31/269 - Train Accuracy: 0.9348, Validation Accuracy: 0.9362, Loss: 0.0849
Epoch  17 Batch   32/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9351, Loss: 0.0807
Epoch  17 Batch   33/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9301, Loss: 0.0774
Epoch  17 Batch   34/269 - Train Accuracy: 0.9309, Validation Accuracy: 0.9291, Loss: 0.0817
Epoch  17 Batch   35/269 - Train Accuracy: 0.9315, Validation Accuracy: 0.9393, Loss: 0.0977
Epoch  17 Batch   36/269 - Train Accuracy: 0.9172, Validation Accuracy: 0.9395, Loss: 0.0862
Epoch  17 Batch   37/269 - Train Accuracy: 0.9411, Validation Accuracy: 0.9367, Loss: 0.0914
Epoch  17 Batch   38/269 - Train Accuracy: 0.9309, Validation Accuracy: 0.9356, Loss: 0.0863
Epoch  17 Batch   39/269 - Train Accuracy: 0.9384, Validation Accuracy: 0.9307, Loss: 0.0842
Epoch  17 Batch   40/269 - Train Accuracy: 0.9120, Validation Accuracy: 0.9285, Loss: 0.0893
Epoch  17 Batch   41/269 - Train Accuracy: 0.9143, Validation Accuracy: 0.9311, Loss: 0.0894
Epoch  17 Batch   42/269 - Train Accuracy: 0.9331, Validation Accuracy: 0.9299, Loss: 0.0766
Epoch  17 Batch   43/269 - Train Accuracy: 0.9294, Validation Accuracy: 0.9400, Loss: 0.0889
Epoch  17 Batch   44/269 - Train Accuracy: 0.9324, Validation Accuracy: 0.9426, Loss: 0.0850
Epoch  17 Batch   45/269 - Train Accuracy: 0.9332, Validation Accuracy: 0.9397, Loss: 0.0895
Epoch  17 Batch   46/269 - Train Accuracy: 0.9241, Validation Accuracy: 0.9430, Loss: 0.0828
Epoch  17 Batch   47/269 - Train Accuracy: 0.9372, Validation Accuracy: 0.9330, Loss: 0.0810
Epoch  17 Batch   48/269 - Train Accuracy: 0.9372, Validation Accuracy: 0.9272, Loss: 0.0836
Epoch  17 Batch   49/269 - Train Accuracy: 0.9413, Validation Accuracy: 0.9330, Loss: 0.0772
Epoch  17 Batch   50/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9373, Loss: 0.0910
Epoch  17 Batch   51/269 - Train Accuracy: 0.9380, Validation Accuracy: 0.9390, Loss: 0.0830
Epoch  17 Batch   52/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9386, Loss: 0.0742
Epoch  17 Batch   53/269 - Train Accuracy: 0.9252, Validation Accuracy: 0.9338, Loss: 0.0943
Epoch  17 Batch   54/269 - Train Accuracy: 0.9362, Validation Accuracy: 0.9325, Loss: 0.0844
Epoch  17 Batch   55/269 - Train Accuracy: 0.9368, Validation Accuracy: 0.9302, Loss: 0.0868
Epoch  17 Batch   56/269 - Train Accuracy: 0.9311, Validation Accuracy: 0.9355, Loss: 0.0863
Epoch  17 Batch   57/269 - Train Accuracy: 0.9208, Validation Accuracy: 0.9371, Loss: 0.0952
Epoch  17 Batch   58/269 - Train Accuracy: 0.9381, Validation Accuracy: 0.9381, Loss: 0.0829
Epoch  17 Batch   59/269 - Train Accuracy: 0.9611, Validation Accuracy: 0.9416, Loss: 0.0672
Epoch  17 Batch   60/269 - Train Accuracy: 0.9282, Validation Accuracy: 0.9444, Loss: 0.0787
Epoch  17 Batch   61/269 - Train Accuracy: 0.9370, Validation Accuracy: 0.9414, Loss: 0.0796
Epoch  17 Batch   62/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9373, Loss: 0.0829
Epoch  17 Batch   63/269 - Train Accuracy: 0.9203, Validation Accuracy: 0.9414, Loss: 0.0940
Epoch  17 Batch   64/269 - Train Accuracy: 0.9362, Validation Accuracy: 0.9415, Loss: 0.0781
Epoch  17 Batch   65/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9401, Loss: 0.0832
Epoch  17 Batch   66/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9419, Loss: 0.0880
Epoch  17 Batch   67/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9395, Loss: 0.0931
Epoch  17 Batch   68/269 - Train Accuracy: 0.9161, Validation Accuracy: 0.9357, Loss: 0.0920
Epoch  17 Batch   69/269 - Train Accuracy: 0.9199, Validation Accuracy: 0.9386, Loss: 0.1054
Epoch  17 Batch   70/269 - Train Accuracy: 0.9378, Validation Accuracy: 0.9391, Loss: 0.0877
Epoch  17 Batch   71/269 - Train Accuracy: 0.9327, Validation Accuracy: 0.9344, Loss: 0.0936
Epoch  17 Batch   72/269 - Train Accuracy: 0.9287, Validation Accuracy: 0.9354, Loss: 0.0941
Epoch  17 Batch   73/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9362, Loss: 0.0996
Epoch  17 Batch   74/269 - Train Accuracy: 0.9398, Validation Accuracy: 0.9348, Loss: 0.0772
Epoch  17 Batch   75/269 - Train Accuracy: 0.9361, Validation Accuracy: 0.9338, Loss: 0.0919
Epoch  17 Batch   76/269 - Train Accuracy: 0.9252, Validation Accuracy: 0.9361, Loss: 0.0878
Epoch  17 Batch   77/269 - Train Accuracy: 0.9318, Validation Accuracy: 0.9388, Loss: 0.0880
Epoch  17 Batch   78/269 - Train Accuracy: 0.9422, Validation Accuracy: 0.9364, Loss: 0.0903
Epoch  17 Batch   79/269 - Train Accuracy: 0.9186, Validation Accuracy: 0.9342, Loss: 0.0871
Epoch  17 Batch   80/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9350, Loss: 0.0848
Epoch  17 Batch   81/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9309, Loss: 0.0959
Epoch  17 Batch   82/269 - Train Accuracy: 0.9435, Validation Accuracy: 0.9256, Loss: 0.0737
Epoch  17 Batch   83/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9304, Loss: 0.1041
Epoch  17 Batch   84/269 - Train Accuracy: 0.9361, Validation Accuracy: 0.9352, Loss: 0.0840
Epoch  17 Batch   85/269 - Train Accuracy: 0.9281, Validation Accuracy: 0.9347, Loss: 0.0852
Epoch  17 Batch   86/269 - Train Accuracy: 0.9328, Validation Accuracy: 0.9340, Loss: 0.0847
Epoch  17 Batch   87/269 - Train Accuracy: 0.9285, Validation Accuracy: 0.9285, Loss: 0.0852
Epoch  17 Batch   88/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9324, Loss: 0.0927
Epoch  17 Batch   89/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9305, Loss: 0.0867
Epoch  17 Batch   90/269 - Train Accuracy: 0.9342, Validation Accuracy: 0.9370, Loss: 0.0865
Epoch  17 Batch   91/269 - Train Accuracy: 0.9432, Validation Accuracy: 0.9351, Loss: 0.0812
Epoch  17 Batch   92/269 - Train Accuracy: 0.9448, Validation Accuracy: 0.9353, Loss: 0.0747
Epoch  17 Batch   93/269 - Train Accuracy: 0.9394, Validation Accuracy: 0.9290, Loss: 0.0783
Epoch  17 Batch   94/269 - Train Accuracy: 0.9256, Validation Accuracy: 0.9330, Loss: 0.0974
Epoch  17 Batch   95/269 - Train Accuracy: 0.9332, Validation Accuracy: 0.9338, Loss: 0.0863
Epoch  17 Batch   96/269 - Train Accuracy: 0.9233, Validation Accuracy: 0.9355, Loss: 0.0835
Epoch  17 Batch   97/269 - Train Accuracy: 0.9257, Validation Accuracy: 0.9395, Loss: 0.0866
Epoch  17 Batch   98/269 - Train Accuracy: 0.9334, Validation Accuracy: 0.9421, Loss: 0.0838
Epoch  17 Batch   99/269 - Train Accuracy: 0.9305, Validation Accuracy: 0.9453, Loss: 0.0818
Epoch  17 Batch  100/269 - Train Accuracy: 0.9401, Validation Accuracy: 0.9416, Loss: 0.0902
Epoch  17 Batch  101/269 - Train Accuracy: 0.9210, Validation Accuracy: 0.9385, Loss: 0.0969
Epoch  17 Batch  102/269 - Train Accuracy: 0.9335, Validation Accuracy: 0.9370, Loss: 0.0812
Epoch  17 Batch  103/269 - Train Accuracy: 0.9356, Validation Accuracy: 0.9297, Loss: 0.0936
Epoch  17 Batch  104/269 - Train Accuracy: 0.9332, Validation Accuracy: 0.9371, Loss: 0.0823
Epoch  17 Batch  105/269 - Train Accuracy: 0.9233, Validation Accuracy: 0.9367, Loss: 0.0891
Epoch  17 Batch  106/269 - Train Accuracy: 0.9351, Validation Accuracy: 0.9402, Loss: 0.0780
Epoch  17 Batch  107/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9402, Loss: 0.0807
Epoch  17 Batch  108/269 - Train Accuracy: 0.9419, Validation Accuracy: 0.9388, Loss: 0.0809
Epoch  17 Batch  109/269 - Train Accuracy: 0.9152, Validation Accuracy: 0.9357, Loss: 0.0902
Epoch  17 Batch  110/269 - Train Accuracy: 0.9236, Validation Accuracy: 0.9389, Loss: 0.0793
Epoch  17 Batch  111/269 - Train Accuracy: 0.9257, Validation Accuracy: 0.9403, Loss: 0.0909
Epoch  17 Batch  112/269 - Train Accuracy: 0.9288, Validation Accuracy: 0.9392, Loss: 0.0842
Epoch  17 Batch  113/269 - Train Accuracy: 0.9250, Validation Accuracy: 0.9370, Loss: 0.0806
Epoch  17 Batch  114/269 - Train Accuracy: 0.9315, Validation Accuracy: 0.9327, Loss: 0.0833
Epoch  17 Batch  115/269 - Train Accuracy: 0.9283, Validation Accuracy: 0.9292, Loss: 0.0882
Epoch  17 Batch  116/269 - Train Accuracy: 0.9304, Validation Accuracy: 0.9265, Loss: 0.0863
Epoch  17 Batch  117/269 - Train Accuracy: 0.9328, Validation Accuracy: 0.9330, Loss: 0.0846
Epoch  17 Batch  118/269 - Train Accuracy: 0.9383, Validation Accuracy: 0.9415, Loss: 0.0770
Epoch  17 Batch  119/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9349, Loss: 0.0925
Epoch  17 Batch  120/269 - Train Accuracy: 0.9343, Validation Accuracy: 0.9373, Loss: 0.0877
Epoch  17 Batch  121/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9363, Loss: 0.0772
Epoch  17 Batch  122/269 - Train Accuracy: 0.9383, Validation Accuracy: 0.9376, Loss: 0.0777
Epoch  17 Batch  123/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9320, Loss: 0.0831
Epoch  17 Batch  124/269 - Train Accuracy: 0.9288, Validation Accuracy: 0.9328, Loss: 0.0751
Epoch  17 Batch  125/269 - Train Accuracy: 0.9451, Validation Accuracy: 0.9331, Loss: 0.0763
Epoch  17 Batch  126/269 - Train Accuracy: 0.9203, Validation Accuracy: 0.9332, Loss: 0.0836
Epoch  17 Batch  127/269 - Train Accuracy: 0.9281, Validation Accuracy: 0.9319, Loss: 0.0867
Epoch  17 Batch  128/269 - Train Accuracy: 0.9238, Validation Accuracy: 0.9332, Loss: 0.0852
Epoch  17 Batch  129/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9332, Loss: 0.0818
Epoch  17 Batch  130/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9316, Loss: 0.0916
Epoch  17 Batch  131/269 - Train Accuracy: 0.9185, Validation Accuracy: 0.9277, Loss: 0.0855
Epoch  17 Batch  132/269 - Train Accuracy: 0.9120, Validation Accuracy: 0.9273, Loss: 0.0904
Epoch  17 Batch  133/269 - Train Accuracy: 0.9343, Validation Accuracy: 0.9363, Loss: 0.0743
Epoch  17 Batch  134/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9410, Loss: 0.0825
Epoch  17 Batch  135/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9400, Loss: 0.0824
Epoch  17 Batch  136/269 - Train Accuracy: 0.9123, Validation Accuracy: 0.9393, Loss: 0.0944
Epoch  17 Batch  137/269 - Train Accuracy: 0.9099, Validation Accuracy: 0.9393, Loss: 0.0968
Epoch  17 Batch  138/269 - Train Accuracy: 0.9287, Validation Accuracy: 0.9371, Loss: 0.0814
Epoch  17 Batch  139/269 - Train Accuracy: 0.9355, Validation Accuracy: 0.9321, Loss: 0.0755
Epoch  17 Batch  140/269 - Train Accuracy: 0.9239, Validation Accuracy: 0.9297, Loss: 0.0893
Epoch  17 Batch  141/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9308, Loss: 0.0908
Epoch  17 Batch  142/269 - Train Accuracy: 0.9308, Validation Accuracy: 0.9304, Loss: 0.0776
Epoch  17 Batch  143/269 - Train Accuracy: 0.9339, Validation Accuracy: 0.9293, Loss: 0.0814
Epoch  17 Batch  144/269 - Train Accuracy: 0.9392, Validation Accuracy: 0.9279, Loss: 0.0715
Epoch  17 Batch  145/269 - Train Accuracy: 0.9287, Validation Accuracy: 0.9338, Loss: 0.0782
Epoch  17 Batch  146/269 - Train Accuracy: 0.9331, Validation Accuracy: 0.9406, Loss: 0.0811
Epoch  17 Batch  147/269 - Train Accuracy: 0.9360, Validation Accuracy: 0.9383, Loss: 0.0870
Epoch  17 Batch  148/269 - Train Accuracy: 0.9258, Validation Accuracy: 0.9285, Loss: 0.0822
Epoch  17 Batch  149/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9253, Loss: 0.0962
Epoch  17 Batch  150/269 - Train Accuracy: 0.9315, Validation Accuracy: 0.9292, Loss: 0.0879
Epoch  17 Batch  151/269 - Train Accuracy: 0.9196, Validation Accuracy: 0.9325, Loss: 0.0878
Epoch  17 Batch  152/269 - Train Accuracy: 0.9329, Validation Accuracy: 0.9311, Loss: 0.0844
Epoch  17 Batch  153/269 - Train Accuracy: 0.9335, Validation Accuracy: 0.9317, Loss: 0.0835
Epoch  17 Batch  154/269 - Train Accuracy: 0.9449, Validation Accuracy: 0.9271, Loss: 0.0847
Epoch  17 Batch  155/269 - Train Accuracy: 0.9208, Validation Accuracy: 0.9294, Loss: 0.0778
Epoch  17 Batch  156/269 - Train Accuracy: 0.9288, Validation Accuracy: 0.9352, Loss: 0.0868
Epoch  17 Batch  157/269 - Train Accuracy: 0.9098, Validation Accuracy: 0.9307, Loss: 0.0805
Epoch  17 Batch  158/269 - Train Accuracy: 0.9303, Validation Accuracy: 0.9291, Loss: 0.0846
Epoch  17 Batch  159/269 - Train Accuracy: 0.9259, Validation Accuracy: 0.9317, Loss: 0.0885
Epoch  17 Batch  160/269 - Train Accuracy: 0.9342, Validation Accuracy: 0.9339, Loss: 0.0851
Epoch  17 Batch  161/269 - Train Accuracy: 0.9387, Validation Accuracy: 0.9347, Loss: 0.0843
Epoch  17 Batch  162/269 - Train Accuracy: 0.9347, Validation Accuracy: 0.9355, Loss: 0.0831
Epoch  17 Batch  163/269 - Train Accuracy: 0.9450, Validation Accuracy: 0.9347, Loss: 0.0862
Epoch  17 Batch  164/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9266, Loss: 0.0846
Epoch  17 Batch  165/269 - Train Accuracy: 0.9342, Validation Accuracy: 0.9321, Loss: 0.0813
Epoch  17 Batch  166/269 - Train Accuracy: 0.9339, Validation Accuracy: 0.9272, Loss: 0.0847
Epoch  17 Batch  167/269 - Train Accuracy: 0.9267, Validation Accuracy: 0.9292, Loss: 0.0818
Epoch  17 Batch  168/269 - Train Accuracy: 0.9301, Validation Accuracy: 0.9284, Loss: 0.0870
Epoch  17 Batch  169/269 - Train Accuracy: 0.9202, Validation Accuracy: 0.9334, Loss: 0.0819
Epoch  17 Batch  170/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9347, Loss: 0.0743
Epoch  17 Batch  171/269 - Train Accuracy: 0.9469, Validation Accuracy: 0.9377, Loss: 0.0836
Epoch  17 Batch  172/269 - Train Accuracy: 0.9243, Validation Accuracy: 0.9384, Loss: 0.0941
Epoch  17 Batch  173/269 - Train Accuracy: 0.9313, Validation Accuracy: 0.9318, Loss: 0.0803
Epoch  17 Batch  174/269 - Train Accuracy: 0.9342, Validation Accuracy: 0.9338, Loss: 0.0847
Epoch  17 Batch  175/269 - Train Accuracy: 0.9174, Validation Accuracy: 0.9380, Loss: 0.0983
Epoch  17 Batch  176/269 - Train Accuracy: 0.9093, Validation Accuracy: 0.9366, Loss: 0.0956
Epoch  17 Batch  177/269 - Train Accuracy: 0.9411, Validation Accuracy: 0.9344, Loss: 0.0771
Epoch  17 Batch  178/269 - Train Accuracy: 0.9343, Validation Accuracy: 0.9373, Loss: 0.0830
Epoch  17 Batch  179/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9407, Loss: 0.0833
Epoch  17 Batch  180/269 - Train Accuracy: 0.9349, Validation Accuracy: 0.9419, Loss: 0.0792
Epoch  17 Batch  181/269 - Train Accuracy: 0.9308, Validation Accuracy: 0.9418, Loss: 0.0862
Epoch  17 Batch  182/269 - Train Accuracy: 0.9324, Validation Accuracy: 0.9424, Loss: 0.0836
Epoch  17 Batch  183/269 - Train Accuracy: 0.9435, Validation Accuracy: 0.9380, Loss: 0.0711
Epoch  17 Batch  184/269 - Train Accuracy: 0.9306, Validation Accuracy: 0.9382, Loss: 0.0811
Epoch  17 Batch  185/269 - Train Accuracy: 0.9389, Validation Accuracy: 0.9384, Loss: 0.0823
Epoch  17 Batch  186/269 - Train Accuracy: 0.9326, Validation Accuracy: 0.9353, Loss: 0.0768
Epoch  17 Batch  187/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9358, Loss: 0.0786
Epoch  17 Batch  188/269 - Train Accuracy: 0.9292, Validation Accuracy: 0.9350, Loss: 0.0803
Epoch  17 Batch  189/269 - Train Accuracy: 0.9363, Validation Accuracy: 0.9399, Loss: 0.0725
Epoch  17 Batch  190/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9342, Loss: 0.0731
Epoch  17 Batch  191/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9335, Loss: 0.0814
Epoch  17 Batch  192/269 - Train Accuracy: 0.9266, Validation Accuracy: 0.9359, Loss: 0.0809
Epoch  17 Batch  193/269 - Train Accuracy: 0.9262, Validation Accuracy: 0.9377, Loss: 0.0789
Epoch  17 Batch  194/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9393, Loss: 0.0854
Epoch  17 Batch  195/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9307, Loss: 0.0804
Epoch  17 Batch  196/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9316, Loss: 0.0833
Epoch  17 Batch  197/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9367, Loss: 0.0867
Epoch  17 Batch  198/269 - Train Accuracy: 0.9326, Validation Accuracy: 0.9406, Loss: 0.0888
Epoch  17 Batch  199/269 - Train Accuracy: 0.9357, Validation Accuracy: 0.9393, Loss: 0.0875
Epoch  17 Batch  200/269 - Train Accuracy: 0.9297, Validation Accuracy: 0.9359, Loss: 0.0805
Epoch  17 Batch  201/269 - Train Accuracy: 0.9264, Validation Accuracy: 0.9292, Loss: 0.0824
Epoch  17 Batch  202/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9291, Loss: 0.0825
Epoch  17 Batch  203/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9309, Loss: 0.0878
Epoch  17 Batch  204/269 - Train Accuracy: 0.9302, Validation Accuracy: 0.9489, Loss: 0.0864
Epoch  17 Batch  205/269 - Train Accuracy: 0.9384, Validation Accuracy: 0.9399, Loss: 0.0827
Epoch  17 Batch  206/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9393, Loss: 0.0869
Epoch  17 Batch  207/269 - Train Accuracy: 0.9273, Validation Accuracy: 0.9439, Loss: 0.0849
Epoch  17 Batch  208/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9347, Loss: 0.0884
Epoch  17 Batch  209/269 - Train Accuracy: 0.9414, Validation Accuracy: 0.9343, Loss: 0.0740
Epoch  17 Batch  210/269 - Train Accuracy: 0.9430, Validation Accuracy: 0.9348, Loss: 0.0759
Epoch  17 Batch  211/269 - Train Accuracy: 0.9283, Validation Accuracy: 0.9385, Loss: 0.0884
Epoch  17 Batch  212/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9382, Loss: 0.0877
Epoch  17 Batch  213/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9440, Loss: 0.0834
Epoch  17 Batch  214/269 - Train Accuracy: 0.9360, Validation Accuracy: 0.9420, Loss: 0.0813
Epoch  17 Batch  215/269 - Train Accuracy: 0.9314, Validation Accuracy: 0.9371, Loss: 0.0823
Epoch  17 Batch  216/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9348, Loss: 0.0940
Epoch  17 Batch  217/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9325, Loss: 0.0822
Epoch  17 Batch  218/269 - Train Accuracy: 0.9334, Validation Accuracy: 0.9342, Loss: 0.0797
Epoch  17 Batch  219/269 - Train Accuracy: 0.9398, Validation Accuracy: 0.9410, Loss: 0.0837
Epoch  17 Batch  220/269 - Train Accuracy: 0.9383, Validation Accuracy: 0.9372, Loss: 0.0778
Epoch  17 Batch  221/269 - Train Accuracy: 0.9371, Validation Accuracy: 0.9394, Loss: 0.0847
Epoch  17 Batch  222/269 - Train Accuracy: 0.9408, Validation Accuracy: 0.9372, Loss: 0.0748
Epoch  17 Batch  223/269 - Train Accuracy: 0.9212, Validation Accuracy: 0.9398, Loss: 0.0783
Epoch  17 Batch  224/269 - Train Accuracy: 0.9325, Validation Accuracy: 0.9402, Loss: 0.0873
Epoch  17 Batch  225/269 - Train Accuracy: 0.9250, Validation Accuracy: 0.9421, Loss: 0.0748
Epoch  17 Batch  226/269 - Train Accuracy: 0.9291, Validation Accuracy: 0.9375, Loss: 0.0839
Epoch  17 Batch  227/269 - Train Accuracy: 0.9412, Validation Accuracy: 0.9379, Loss: 0.0919
Epoch  17 Batch  228/269 - Train Accuracy: 0.9373, Validation Accuracy: 0.9311, Loss: 0.0800
Epoch  17 Batch  229/269 - Train Accuracy: 0.9246, Validation Accuracy: 0.9343, Loss: 0.0817
Epoch  17 Batch  230/269 - Train Accuracy: 0.9335, Validation Accuracy: 0.9303, Loss: 0.0823
Epoch  17 Batch  231/269 - Train Accuracy: 0.9295, Validation Accuracy: 0.9354, Loss: 0.0838
Epoch  17 Batch  232/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9364, Loss: 0.0829
Epoch  17 Batch  233/269 - Train Accuracy: 0.9376, Validation Accuracy: 0.9341, Loss: 0.0813
Epoch  17 Batch  234/269 - Train Accuracy: 0.9314, Validation Accuracy: 0.9340, Loss: 0.0817
Epoch  17 Batch  235/269 - Train Accuracy: 0.9573, Validation Accuracy: 0.9427, Loss: 0.0700
Epoch  17 Batch  236/269 - Train Accuracy: 0.9327, Validation Accuracy: 0.9390, Loss: 0.0735
Epoch  17 Batch  237/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9432, Loss: 0.0737
Epoch  17 Batch  238/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9411, Loss: 0.0798
Epoch  17 Batch  239/269 - Train Accuracy: 0.9304, Validation Accuracy: 0.9403, Loss: 0.0762
Epoch  17 Batch  240/269 - Train Accuracy: 0.9357, Validation Accuracy: 0.9391, Loss: 0.0731
Epoch  17 Batch  241/269 - Train Accuracy: 0.9272, Validation Accuracy: 0.9383, Loss: 0.0910
Epoch  17 Batch  242/269 - Train Accuracy: 0.9466, Validation Accuracy: 0.9363, Loss: 0.0760
Epoch  17 Batch  243/269 - Train Accuracy: 0.9370, Validation Accuracy: 0.9355, Loss: 0.0727
Epoch  17 Batch  244/269 - Train Accuracy: 0.9263, Validation Accuracy: 0.9351, Loss: 0.0778
Epoch  17 Batch  245/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9403, Loss: 0.0811
Epoch  17 Batch  246/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9410, Loss: 0.0840
Epoch  17 Batch  247/269 - Train Accuracy: 0.9362, Validation Accuracy: 0.9435, Loss: 0.0782
Epoch  17 Batch  248/269 - Train Accuracy: 0.9361, Validation Accuracy: 0.9457, Loss: 0.0789
Epoch  17 Batch  249/269 - Train Accuracy: 0.9340, Validation Accuracy: 0.9411, Loss: 0.0713
Epoch  17 Batch  250/269 - Train Accuracy: 0.9378, Validation Accuracy: 0.9448, Loss: 0.0793
Epoch  17 Batch  251/269 - Train Accuracy: 0.9479, Validation Accuracy: 0.9434, Loss: 0.0722
Epoch  17 Batch  252/269 - Train Accuracy: 0.9366, Validation Accuracy: 0.9474, Loss: 0.0722
Epoch  17 Batch  253/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9423, Loss: 0.0846
Epoch  17 Batch  254/269 - Train Accuracy: 0.9344, Validation Accuracy: 0.9355, Loss: 0.0778
Epoch  17 Batch  255/269 - Train Accuracy: 0.9347, Validation Accuracy: 0.9354, Loss: 0.0805
Epoch  17 Batch  256/269 - Train Accuracy: 0.9369, Validation Accuracy: 0.9393, Loss: 0.0859
Epoch  17 Batch  257/269 - Train Accuracy: 0.9120, Validation Accuracy: 0.9392, Loss: 0.0881
Epoch  17 Batch  258/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9341, Loss: 0.0845
Epoch  17 Batch  259/269 - Train Accuracy: 0.9291, Validation Accuracy: 0.9376, Loss: 0.0786
Epoch  17 Batch  260/269 - Train Accuracy: 0.9302, Validation Accuracy: 0.9395, Loss: 0.0886
Epoch  17 Batch  261/269 - Train Accuracy: 0.9305, Validation Accuracy: 0.9432, Loss: 0.0831
Epoch  17 Batch  262/269 - Train Accuracy: 0.9326, Validation Accuracy: 0.9422, Loss: 0.0848
Epoch  17 Batch  263/269 - Train Accuracy: 0.9299, Validation Accuracy: 0.9372, Loss: 0.0825
Epoch  17 Batch  264/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9386, Loss: 0.0901
Epoch  17 Batch  265/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9364, Loss: 0.0839
Epoch  17 Batch  266/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9370, Loss: 0.0772
Epoch  17 Batch  267/269 - Train Accuracy: 0.9390, Validation Accuracy: 0.9412, Loss: 0.0870
Epoch  18 Batch    1/269 - Train Accuracy: 0.9236, Validation Accuracy: 0.9393, Loss: 0.0789
Epoch  18 Batch    2/269 - Train Accuracy: 0.9389, Validation Accuracy: 0.9407, Loss: 0.0835
Epoch  18 Batch    3/269 - Train Accuracy: 0.9412, Validation Accuracy: 0.9404, Loss: 0.0833
Epoch  18 Batch    4/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9385, Loss: 0.0812
Epoch  18 Batch    5/269 - Train Accuracy: 0.9387, Validation Accuracy: 0.9381, Loss: 0.0826
Epoch  18 Batch    6/269 - Train Accuracy: 0.9484, Validation Accuracy: 0.9384, Loss: 0.0796
Epoch  18 Batch    7/269 - Train Accuracy: 0.9431, Validation Accuracy: 0.9348, Loss: 0.0765
Epoch  18 Batch    8/269 - Train Accuracy: 0.9461, Validation Accuracy: 0.9313, Loss: 0.0819
Epoch  18 Batch    9/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9376, Loss: 0.0849
Epoch  18 Batch   10/269 - Train Accuracy: 0.9426, Validation Accuracy: 0.9279, Loss: 0.0750
Epoch  18 Batch   11/269 - Train Accuracy: 0.9323, Validation Accuracy: 0.9290, Loss: 0.0846
Epoch  18 Batch   12/269 - Train Accuracy: 0.9245, Validation Accuracy: 0.9284, Loss: 0.0853
Epoch  18 Batch   13/269 - Train Accuracy: 0.9447, Validation Accuracy: 0.9420, Loss: 0.0722
Epoch  18 Batch   14/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9488, Loss: 0.0827
Epoch  18 Batch   15/269 - Train Accuracy: 0.9481, Validation Accuracy: 0.9458, Loss: 0.0658
Epoch  18 Batch   16/269 - Train Accuracy: 0.9242, Validation Accuracy: 0.9411, Loss: 0.0889
Epoch  18 Batch   17/269 - Train Accuracy: 0.9291, Validation Accuracy: 0.9317, Loss: 0.0801
Epoch  18 Batch   18/269 - Train Accuracy: 0.9276, Validation Accuracy: 0.9319, Loss: 0.0835
Epoch  18 Batch   19/269 - Train Accuracy: 0.9403, Validation Accuracy: 0.9367, Loss: 0.0696
Epoch  18 Batch   20/269 - Train Accuracy: 0.9366, Validation Accuracy: 0.9391, Loss: 0.0796
Epoch  18 Batch   21/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9406, Loss: 0.0959
Epoch  18 Batch   22/269 - Train Accuracy: 0.9450, Validation Accuracy: 0.9401, Loss: 0.0767
Epoch  18 Batch   23/269 - Train Accuracy: 0.9303, Validation Accuracy: 0.9396, Loss: 0.0833
Epoch  18 Batch   24/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9347, Loss: 0.0775
Epoch  18 Batch   25/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9341, Loss: 0.0883
Epoch  18 Batch   26/269 - Train Accuracy: 0.9302, Validation Accuracy: 0.9389, Loss: 0.0765
Epoch  18 Batch   27/269 - Train Accuracy: 0.9180, Validation Accuracy: 0.9371, Loss: 0.0759
Epoch  18 Batch   28/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9356, Loss: 0.0843
Epoch  18 Batch   29/269 - Train Accuracy: 0.9396, Validation Accuracy: 0.9387, Loss: 0.0863
Epoch  18 Batch   30/269 - Train Accuracy: 0.9266, Validation Accuracy: 0.9310, Loss: 0.0829
Epoch  18 Batch   31/269 - Train Accuracy: 0.9439, Validation Accuracy: 0.9342, Loss: 0.0840
Epoch  18 Batch   32/269 - Train Accuracy: 0.9459, Validation Accuracy: 0.9372, Loss: 0.0751
Epoch  18 Batch   33/269 - Train Accuracy: 0.9273, Validation Accuracy: 0.9397, Loss: 0.0724
Epoch  18 Batch   34/269 - Train Accuracy: 0.9331, Validation Accuracy: 0.9349, Loss: 0.0771
Epoch  18 Batch   35/269 - Train Accuracy: 0.9344, Validation Accuracy: 0.9416, Loss: 0.0929
Epoch  18 Batch   36/269 - Train Accuracy: 0.9199, Validation Accuracy: 0.9375, Loss: 0.0823
Epoch  18 Batch   37/269 - Train Accuracy: 0.9384, Validation Accuracy: 0.9355, Loss: 0.0827
Epoch  18 Batch   38/269 - Train Accuracy: 0.9361, Validation Accuracy: 0.9415, Loss: 0.0759
Epoch  18 Batch   39/269 - Train Accuracy: 0.9444, Validation Accuracy: 0.9448, Loss: 0.0759
Epoch  18 Batch   40/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9442, Loss: 0.0907
Epoch  18 Batch   41/269 - Train Accuracy: 0.9232, Validation Accuracy: 0.9412, Loss: 0.0838
Epoch  18 Batch   42/269 - Train Accuracy: 0.9442, Validation Accuracy: 0.9395, Loss: 0.0778
Epoch  18 Batch   43/269 - Train Accuracy: 0.9363, Validation Accuracy: 0.9394, Loss: 0.0836
Epoch  18 Batch   44/269 - Train Accuracy: 0.9322, Validation Accuracy: 0.9392, Loss: 0.0817
Epoch  18 Batch   45/269 - Train Accuracy: 0.9271, Validation Accuracy: 0.9402, Loss: 0.0842
Epoch  18 Batch   46/269 - Train Accuracy: 0.9418, Validation Accuracy: 0.9426, Loss: 0.0738
Epoch  18 Batch   47/269 - Train Accuracy: 0.9433, Validation Accuracy: 0.9460, Loss: 0.0692
Epoch  18 Batch   48/269 - Train Accuracy: 0.9423, Validation Accuracy: 0.9426, Loss: 0.0770
Epoch  18 Batch   49/269 - Train Accuracy: 0.9440, Validation Accuracy: 0.9392, Loss: 0.0736
Epoch  18 Batch   50/269 - Train Accuracy: 0.9213, Validation Accuracy: 0.9361, Loss: 0.0879
Epoch  18 Batch   51/269 - Train Accuracy: 0.9365, Validation Accuracy: 0.9370, Loss: 0.0781
Epoch  18 Batch   52/269 - Train Accuracy: 0.9254, Validation Accuracy: 0.9360, Loss: 0.0672
Epoch  18 Batch   53/269 - Train Accuracy: 0.9356, Validation Accuracy: 0.9371, Loss: 0.0840
Epoch  18 Batch   54/269 - Train Accuracy: 0.9386, Validation Accuracy: 0.9332, Loss: 0.0775
Epoch  18 Batch   55/269 - Train Accuracy: 0.9461, Validation Accuracy: 0.9363, Loss: 0.0762
Epoch  18 Batch   56/269 - Train Accuracy: 0.9328, Validation Accuracy: 0.9341, Loss: 0.0803
Epoch  18 Batch   57/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9367, Loss: 0.0850
Epoch  18 Batch   58/269 - Train Accuracy: 0.9465, Validation Accuracy: 0.9393, Loss: 0.0805
Epoch  18 Batch   59/269 - Train Accuracy: 0.9552, Validation Accuracy: 0.9409, Loss: 0.0633
Epoch  18 Batch   60/269 - Train Accuracy: 0.9363, Validation Accuracy: 0.9395, Loss: 0.0721
Epoch  18 Batch   61/269 - Train Accuracy: 0.9334, Validation Accuracy: 0.9440, Loss: 0.0693
Epoch  18 Batch   62/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9425, Loss: 0.0783
Epoch  18 Batch   63/269 - Train Accuracy: 0.9342, Validation Accuracy: 0.9418, Loss: 0.0895
Epoch  18 Batch   64/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9406, Loss: 0.0717
Epoch  18 Batch   65/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9363, Loss: 0.0779
Epoch  18 Batch   66/269 - Train Accuracy: 0.9255, Validation Accuracy: 0.9420, Loss: 0.0807
Epoch  18 Batch   67/269 - Train Accuracy: 0.9294, Validation Accuracy: 0.9424, Loss: 0.0857
Epoch  18 Batch   68/269 - Train Accuracy: 0.9180, Validation Accuracy: 0.9355, Loss: 0.0824
Epoch  18 Batch   69/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9321, Loss: 0.0911
Epoch  18 Batch   70/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9333, Loss: 0.0873
Epoch  18 Batch   71/269 - Train Accuracy: 0.9333, Validation Accuracy: 0.9388, Loss: 0.0920
Epoch  18 Batch   72/269 - Train Accuracy: 0.9291, Validation Accuracy: 0.9465, Loss: 0.0870
Epoch  18 Batch   73/269 - Train Accuracy: 0.9328, Validation Accuracy: 0.9458, Loss: 0.0848
Epoch  18 Batch   74/269 - Train Accuracy: 0.9422, Validation Accuracy: 0.9358, Loss: 0.0752
Epoch  18 Batch   75/269 - Train Accuracy: 0.9330, Validation Accuracy: 0.9325, Loss: 0.0827
Epoch  18 Batch   76/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9353, Loss: 0.0805
Epoch  18 Batch   77/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9371, Loss: 0.0794
Epoch  18 Batch   78/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9473, Loss: 0.0739
Epoch  18 Batch   79/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9441, Loss: 0.0755
Epoch  18 Batch   80/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9432, Loss: 0.0766
Epoch  18 Batch   81/269 - Train Accuracy: 0.9320, Validation Accuracy: 0.9415, Loss: 0.0917
Epoch  18 Batch   82/269 - Train Accuracy: 0.9489, Validation Accuracy: 0.9386, Loss: 0.0666
Epoch  18 Batch   83/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.9387, Loss: 0.0911
Epoch  18 Batch   84/269 - Train Accuracy: 0.9447, Validation Accuracy: 0.9368, Loss: 0.0772
Epoch  18 Batch   85/269 - Train Accuracy: 0.9402, Validation Accuracy: 0.9400, Loss: 0.0743
Epoch  18 Batch   86/269 - Train Accuracy: 0.9374, Validation Accuracy: 0.9370, Loss: 0.0724
Epoch  18 Batch   87/269 - Train Accuracy: 0.9241, Validation Accuracy: 0.9394, Loss: 0.0832
Epoch  18 Batch   88/269 - Train Accuracy: 0.9207, Validation Accuracy: 0.9324, Loss: 0.0835
Epoch  18 Batch   89/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9387, Loss: 0.0774
Epoch  18 Batch   90/269 - Train Accuracy: 0.9450, Validation Accuracy: 0.9413, Loss: 0.0800
Epoch  18 Batch   91/269 - Train Accuracy: 0.9462, Validation Accuracy: 0.9422, Loss: 0.0760
Epoch  18 Batch   92/269 - Train Accuracy: 0.9413, Validation Accuracy: 0.9384, Loss: 0.0712
Epoch  18 Batch   93/269 - Train Accuracy: 0.9393, Validation Accuracy: 0.9353, Loss: 0.0727
Epoch  18 Batch   94/269 - Train Accuracy: 0.9379, Validation Accuracy: 0.9356, Loss: 0.0911
Epoch  18 Batch   95/269 - Train Accuracy: 0.9409, Validation Accuracy: 0.9321, Loss: 0.0775
Epoch  18 Batch   96/269 - Train Accuracy: 0.9210, Validation Accuracy: 0.9375, Loss: 0.0802
Epoch  18 Batch   97/269 - Train Accuracy: 0.9322, Validation Accuracy: 0.9390, Loss: 0.0842
Epoch  18 Batch   98/269 - Train Accuracy: 0.9432, Validation Accuracy: 0.9361, Loss: 0.0765
Epoch  18 Batch   99/269 - Train Accuracy: 0.9367, Validation Accuracy: 0.9427, Loss: 0.0756
Epoch  18 Batch  100/269 - Train Accuracy: 0.9409, Validation Accuracy: 0.9420, Loss: 0.0779
Epoch  18 Batch  101/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9422, Loss: 0.0897
Epoch  18 Batch  102/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9392, Loss: 0.0741
Epoch  18 Batch  103/269 - Train Accuracy: 0.9404, Validation Accuracy: 0.9331, Loss: 0.0862
Epoch  18 Batch  104/269 - Train Accuracy: 0.9346, Validation Accuracy: 0.9378, Loss: 0.0794
Epoch  18 Batch  105/269 - Train Accuracy: 0.9315, Validation Accuracy: 0.9441, Loss: 0.0775
Epoch  18 Batch  106/269 - Train Accuracy: 0.9441, Validation Accuracy: 0.9497, Loss: 0.0761
Epoch  18 Batch  107/269 - Train Accuracy: 0.9425, Validation Accuracy: 0.9501, Loss: 0.0764
Epoch  18 Batch  108/269 - Train Accuracy: 0.9509, Validation Accuracy: 0.9463, Loss: 0.0777
Epoch  18 Batch  109/269 - Train Accuracy: 0.9203, Validation Accuracy: 0.9450, Loss: 0.0803
Epoch  18 Batch  110/269 - Train Accuracy: 0.9337, Validation Accuracy: 0.9477, Loss: 0.0700
Epoch  18 Batch  111/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9421, Loss: 0.0882
Epoch  18 Batch  112/269 - Train Accuracy: 0.9330, Validation Accuracy: 0.9409, Loss: 0.0778
Epoch  18 Batch  113/269 - Train Accuracy: 0.9348, Validation Accuracy: 0.9421, Loss: 0.0782
Epoch  18 Batch  114/269 - Train Accuracy: 0.9326, Validation Accuracy: 0.9412, Loss: 0.0743
Epoch  18 Batch  115/269 - Train Accuracy: 0.9343, Validation Accuracy: 0.9365, Loss: 0.0798
Epoch  18 Batch  116/269 - Train Accuracy: 0.9355, Validation Accuracy: 0.9287, Loss: 0.0776
Epoch  18 Batch  117/269 - Train Accuracy: 0.9353, Validation Accuracy: 0.9282, Loss: 0.0754
Epoch  18 Batch  118/269 - Train Accuracy: 0.9426, Validation Accuracy: 0.9357, Loss: 0.0738
Epoch  18 Batch  119/269 - Train Accuracy: 0.9215, Validation Accuracy: 0.9436, Loss: 0.0906
Epoch  18 Batch  120/269 - Train Accuracy: 0.9303, Validation Accuracy: 0.9444, Loss: 0.0765
Epoch  18 Batch  121/269 - Train Accuracy: 0.9190, Validation Accuracy: 0.9442, Loss: 0.0787
Epoch  18 Batch  122/269 - Train Accuracy: 0.9472, Validation Accuracy: 0.9331, Loss: 0.0777
Epoch  18 Batch  123/269 - Train Accuracy: 0.9326, Validation Accuracy: 0.9290, Loss: 0.0753
Epoch  18 Batch  124/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9443, Loss: 0.0736
Epoch  18 Batch  125/269 - Train Accuracy: 0.9435, Validation Accuracy: 0.9437, Loss: 0.0706
Epoch  18 Batch  126/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9466, Loss: 0.0811
Epoch  18 Batch  127/269 - Train Accuracy: 0.9400, Validation Accuracy: 0.9443, Loss: 0.0792
Epoch  18 Batch  128/269 - Train Accuracy: 0.9332, Validation Accuracy: 0.9445, Loss: 0.0808
Epoch  18 Batch  129/269 - Train Accuracy: 0.9181, Validation Accuracy: 0.9359, Loss: 0.0819
Epoch  18 Batch  130/269 - Train Accuracy: 0.9471, Validation Accuracy: 0.9339, Loss: 0.0817
Epoch  18 Batch  131/269 - Train Accuracy: 0.9284, Validation Accuracy: 0.9395, Loss: 0.0831
Epoch  18 Batch  132/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9448, Loss: 0.0804
Epoch  18 Batch  133/269 - Train Accuracy: 0.9413, Validation Accuracy: 0.9468, Loss: 0.0696
Epoch  18 Batch  134/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9454, Loss: 0.0854
Epoch  18 Batch  135/269 - Train Accuracy: 0.9444, Validation Accuracy: 0.9432, Loss: 0.0815
Epoch  18 Batch  136/269 - Train Accuracy: 0.9103, Validation Accuracy: 0.9406, Loss: 0.0823
Epoch  18 Batch  137/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9439, Loss: 0.0879
Epoch  18 Batch  138/269 - Train Accuracy: 0.9378, Validation Accuracy: 0.9461, Loss: 0.0735
Epoch  18 Batch  139/269 - Train Accuracy: 0.9488, Validation Accuracy: 0.9421, Loss: 0.0737
Epoch  18 Batch  140/269 - Train Accuracy: 0.9304, Validation Accuracy: 0.9411, Loss: 0.0880
Epoch  18 Batch  141/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9375, Loss: 0.0833
Epoch  18 Batch  142/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9324, Loss: 0.0739
Epoch  18 Batch  143/269 - Train Accuracy: 0.9359, Validation Accuracy: 0.9313, Loss: 0.0709
Epoch  18 Batch  144/269 - Train Accuracy: 0.9417, Validation Accuracy: 0.9299, Loss: 0.0637
Epoch  18 Batch  145/269 - Train Accuracy: 0.9422, Validation Accuracy: 0.9361, Loss: 0.0755
Epoch  18 Batch  146/269 - Train Accuracy: 0.9411, Validation Accuracy: 0.9390, Loss: 0.0718
Epoch  18 Batch  147/269 - Train Accuracy: 0.9353, Validation Accuracy: 0.9397, Loss: 0.0856
Epoch  18 Batch  148/269 - Train Accuracy: 0.9317, Validation Accuracy: 0.9416, Loss: 0.0816
Epoch  18 Batch  149/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9434, Loss: 0.0925
Epoch  18 Batch  150/269 - Train Accuracy: 0.9406, Validation Accuracy: 0.9445, Loss: 0.0789
Epoch  18 Batch  151/269 - Train Accuracy: 0.9345, Validation Accuracy: 0.9458, Loss: 0.0768
Epoch  18 Batch  152/269 - Train Accuracy: 0.9352, Validation Accuracy: 0.9440, Loss: 0.0764
Epoch  18 Batch  153/269 - Train Accuracy: 0.9389, Validation Accuracy: 0.9464, Loss: 0.0708
Epoch  18 Batch  154/269 - Train Accuracy: 0.9488, Validation Accuracy: 0.9401, Loss: 0.0759
Epoch  18 Batch  155/269 - Train Accuracy: 0.9382, Validation Accuracy: 0.9403, Loss: 0.0773
Epoch  18 Batch  156/269 - Train Accuracy: 0.9352, Validation Accuracy: 0.9367, Loss: 0.0851
Epoch  18 Batch  157/269 - Train Accuracy: 0.9294, Validation Accuracy: 0.9370, Loss: 0.0729
Epoch  18 Batch  158/269 - Train Accuracy: 0.9264, Validation Accuracy: 0.9347, Loss: 0.0793
Epoch  18 Batch  159/269 - Train Accuracy: 0.9314, Validation Accuracy: 0.9441, Loss: 0.0828
Epoch  18 Batch  160/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9446, Loss: 0.0706
Epoch  18 Batch  161/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9457, Loss: 0.0769
Epoch  18 Batch  162/269 - Train Accuracy: 0.9372, Validation Accuracy: 0.9454, Loss: 0.0768
Epoch  18 Batch  163/269 - Train Accuracy: 0.9412, Validation Accuracy: 0.9399, Loss: 0.0813
Epoch  18 Batch  164/269 - Train Accuracy: 0.9322, Validation Accuracy: 0.9327, Loss: 0.0774
Epoch  18 Batch  165/269 - Train Accuracy: 0.9344, Validation Accuracy: 0.9360, Loss: 0.0743
Epoch  18 Batch  166/269 - Train Accuracy: 0.9400, Validation Accuracy: 0.9433, Loss: 0.0757
Epoch  18 Batch  167/269 - Train Accuracy: 0.9359, Validation Accuracy: 0.9400, Loss: 0.0766
Epoch  18 Batch  168/269 - Train Accuracy: 0.9364, Validation Accuracy: 0.9392, Loss: 0.0765
Epoch  18 Batch  169/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9404, Loss: 0.0752
Epoch  18 Batch  170/269 - Train Accuracy: 0.9231, Validation Accuracy: 0.9408, Loss: 0.0776
Epoch  18 Batch  171/269 - Train Accuracy: 0.9490, Validation Accuracy: 0.9428, Loss: 0.0821
Epoch  18 Batch  172/269 - Train Accuracy: 0.9236, Validation Accuracy: 0.9434, Loss: 0.0859
Epoch  18 Batch  173/269 - Train Accuracy: 0.9384, Validation Accuracy: 0.9404, Loss: 0.0683
Epoch  18 Batch  174/269 - Train Accuracy: 0.9478, Validation Accuracy: 0.9390, Loss: 0.0781
Epoch  18 Batch  175/269 - Train Accuracy: 0.9199, Validation Accuracy: 0.9376, Loss: 0.0902
Epoch  18 Batch  176/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.9418, Loss: 0.0822
Epoch  18 Batch  177/269 - Train Accuracy: 0.9404, Validation Accuracy: 0.9378, Loss: 0.0790
Epoch  18 Batch  178/269 - Train Accuracy: 0.9377, Validation Accuracy: 0.9426, Loss: 0.0715
Epoch  18 Batch  179/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9430, Loss: 0.0760
Epoch  18 Batch  180/269 - Train Accuracy: 0.9467, Validation Accuracy: 0.9383, Loss: 0.0766
Epoch  18 Batch  181/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9456, Loss: 0.0776
Epoch  18 Batch  182/269 - Train Accuracy: 0.9269, Validation Accuracy: 0.9431, Loss: 0.0778
Epoch  18 Batch  183/269 - Train Accuracy: 0.9452, Validation Accuracy: 0.9368, Loss: 0.0664
Epoch  18 Batch  184/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9331, Loss: 0.0765
Epoch  18 Batch  185/269 - Train Accuracy: 0.9374, Validation Accuracy: 0.9370, Loss: 0.0794
Epoch  18 Batch  186/269 - Train Accuracy: 0.9326, Validation Accuracy: 0.9371, Loss: 0.0730
Epoch  18 Batch  187/269 - Train Accuracy: 0.9356, Validation Accuracy: 0.9326, Loss: 0.0748
Epoch  18 Batch  188/269 - Train Accuracy: 0.9344, Validation Accuracy: 0.9362, Loss: 0.0773
Epoch  18 Batch  189/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9381, Loss: 0.0736
Epoch  18 Batch  190/269 - Train Accuracy: 0.9323, Validation Accuracy: 0.9327, Loss: 0.0715
Epoch  18 Batch  191/269 - Train Accuracy: 0.9225, Validation Accuracy: 0.9332, Loss: 0.0739
Epoch  18 Batch  192/269 - Train Accuracy: 0.9356, Validation Accuracy: 0.9413, Loss: 0.0770
Epoch  18 Batch  193/269 - Train Accuracy: 0.9365, Validation Accuracy: 0.9442, Loss: 0.0742
Epoch  18 Batch  194/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9388, Loss: 0.0805
Epoch  18 Batch  195/269 - Train Accuracy: 0.9295, Validation Accuracy: 0.9351, Loss: 0.0733
Epoch  18 Batch  196/269 - Train Accuracy: 0.9324, Validation Accuracy: 0.9354, Loss: 0.0748
Epoch  18 Batch  197/269 - Train Accuracy: 0.9254, Validation Accuracy: 0.9394, Loss: 0.0817
Epoch  18 Batch  198/269 - Train Accuracy: 0.9371, Validation Accuracy: 0.9400, Loss: 0.0833
Epoch  18 Batch  199/269 - Train Accuracy: 0.9438, Validation Accuracy: 0.9355, Loss: 0.0775
Epoch  18 Batch  200/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9276, Loss: 0.0726
Epoch  18 Batch  201/269 - Train Accuracy: 0.9407, Validation Accuracy: 0.9315, Loss: 0.0781
Epoch  18 Batch  202/269 - Train Accuracy: 0.9362, Validation Accuracy: 0.9399, Loss: 0.0778
Epoch  18 Batch  203/269 - Train Accuracy: 0.9272, Validation Accuracy: 0.9412, Loss: 0.0839
Epoch  18 Batch  204/269 - Train Accuracy: 0.9388, Validation Accuracy: 0.9415, Loss: 0.0757
Epoch  18 Batch  205/269 - Train Accuracy: 0.9394, Validation Accuracy: 0.9446, Loss: 0.0743
Epoch  18 Batch  206/269 - Train Accuracy: 0.9191, Validation Accuracy: 0.9447, Loss: 0.0854
Epoch  18 Batch  207/269 - Train Accuracy: 0.9255, Validation Accuracy: 0.9421, Loss: 0.0797
Epoch  18 Batch  208/269 - Train Accuracy: 0.9313, Validation Accuracy: 0.9442, Loss: 0.0826
Epoch  18 Batch  209/269 - Train Accuracy: 0.9459, Validation Accuracy: 0.9431, Loss: 0.0710
Epoch  18 Batch  210/269 - Train Accuracy: 0.9372, Validation Accuracy: 0.9431, Loss: 0.0743
Epoch  18 Batch  211/269 - Train Accuracy: 0.9290, Validation Accuracy: 0.9418, Loss: 0.0817
Epoch  18 Batch  212/269 - Train Accuracy: 0.9324, Validation Accuracy: 0.9416, Loss: 0.0807
Epoch  18 Batch  213/269 - Train Accuracy: 0.9354, Validation Accuracy: 0.9433, Loss: 0.0745
Epoch  18 Batch  214/269 - Train Accuracy: 0.9344, Validation Accuracy: 0.9459, Loss: 0.0764
Epoch  18 Batch  215/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9438, Loss: 0.0765
Epoch  18 Batch  216/269 - Train Accuracy: 0.9358, Validation Accuracy: 0.9431, Loss: 0.0869
Epoch  18 Batch  217/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9379, Loss: 0.0856
Epoch  18 Batch  218/269 - Train Accuracy: 0.9306, Validation Accuracy: 0.9385, Loss: 0.0738
Epoch  18 Batch  219/269 - Train Accuracy: 0.9405, Validation Accuracy: 0.9374, Loss: 0.0785
Epoch  18 Batch  220/269 - Train Accuracy: 0.9377, Validation Accuracy: 0.9374, Loss: 0.0730
Epoch  18 Batch  221/269 - Train Accuracy: 0.9321, Validation Accuracy: 0.9343, Loss: 0.0790
Epoch  18 Batch  222/269 - Train Accuracy: 0.9466, Validation Accuracy: 0.9351, Loss: 0.0702
Epoch  18 Batch  223/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9401, Loss: 0.0760
Epoch  18 Batch  224/269 - Train Accuracy: 0.9337, Validation Accuracy: 0.9408, Loss: 0.0861
Epoch  18 Batch  225/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9406, Loss: 0.0745
Epoch  18 Batch  226/269 - Train Accuracy: 0.9384, Validation Accuracy: 0.9449, Loss: 0.0794
Epoch  18 Batch  227/269 - Train Accuracy: 0.9419, Validation Accuracy: 0.9387, Loss: 0.0917
Epoch  18 Batch  228/269 - Train Accuracy: 0.9357, Validation Accuracy: 0.9372, Loss: 0.0700
Epoch  18 Batch  229/269 - Train Accuracy: 0.9299, Validation Accuracy: 0.9405, Loss: 0.0736
Epoch  18 Batch  230/269 - Train Accuracy: 0.9369, Validation Accuracy: 0.9453, Loss: 0.0747
Epoch  18 Batch  231/269 - Train Accuracy: 0.9282, Validation Accuracy: 0.9453, Loss: 0.0764
Epoch  18 Batch  232/269 - Train Accuracy: 0.9368, Validation Accuracy: 0.9506, Loss: 0.0818
Epoch  18 Batch  233/269 - Train Accuracy: 0.9461, Validation Accuracy: 0.9507, Loss: 0.0777
Epoch  18 Batch  234/269 - Train Accuracy: 0.9410, Validation Accuracy: 0.9448, Loss: 0.0738
Epoch  18 Batch  235/269 - Train Accuracy: 0.9631, Validation Accuracy: 0.9464, Loss: 0.0671
Epoch  18 Batch  236/269 - Train Accuracy: 0.9294, Validation Accuracy: 0.9479, Loss: 0.0726
Epoch  18 Batch  237/269 - Train Accuracy: 0.9374, Validation Accuracy: 0.9444, Loss: 0.0730
Epoch  18 Batch  238/269 - Train Accuracy: 0.9389, Validation Accuracy: 0.9450, Loss: 0.0741
Epoch  18 Batch  239/269 - Train Accuracy: 0.9256, Validation Accuracy: 0.9371, Loss: 0.0796
Epoch  18 Batch  240/269 - Train Accuracy: 0.9333, Validation Accuracy: 0.9372, Loss: 0.0755
Epoch  18 Batch  241/269 - Train Accuracy: 0.9333, Validation Accuracy: 0.9355, Loss: 0.0877
Epoch  18 Batch  242/269 - Train Accuracy: 0.9488, Validation Accuracy: 0.9379, Loss: 0.0713
Epoch  18 Batch  243/269 - Train Accuracy: 0.9375, Validation Accuracy: 0.9425, Loss: 0.0693
Epoch  18 Batch  244/269 - Train Accuracy: 0.9281, Validation Accuracy: 0.9446, Loss: 0.0766
Epoch  18 Batch  245/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9447, Loss: 0.0784
Epoch  18 Batch  246/269 - Train Accuracy: 0.9264, Validation Accuracy: 0.9403, Loss: 0.0805
Epoch  18 Batch  247/269 - Train Accuracy: 0.9417, Validation Accuracy: 0.9421, Loss: 0.0750
Epoch  18 Batch  248/269 - Train Accuracy: 0.9379, Validation Accuracy: 0.9390, Loss: 0.0699
Epoch  18 Batch  249/269 - Train Accuracy: 0.9325, Validation Accuracy: 0.9398, Loss: 0.0670
Epoch  18 Batch  250/269 - Train Accuracy: 0.9496, Validation Accuracy: 0.9486, Loss: 0.0741
Epoch  18 Batch  251/269 - Train Accuracy: 0.9571, Validation Accuracy: 0.9439, Loss: 0.0679
Epoch  18 Batch  252/269 - Train Accuracy: 0.9439, Validation Accuracy: 0.9427, Loss: 0.0673
Epoch  18 Batch  253/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9424, Loss: 0.0796
Epoch  18 Batch  254/269 - Train Accuracy: 0.9371, Validation Accuracy: 0.9474, Loss: 0.0722
Epoch  18 Batch  255/269 - Train Accuracy: 0.9333, Validation Accuracy: 0.9403, Loss: 0.0766
Epoch  18 Batch  256/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9434, Loss: 0.0774
Epoch  18 Batch  257/269 - Train Accuracy: 0.9167, Validation Accuracy: 0.9427, Loss: 0.0826
Epoch  18 Batch  258/269 - Train Accuracy: 0.9308, Validation Accuracy: 0.9433, Loss: 0.0819
Epoch  18 Batch  259/269 - Train Accuracy: 0.9408, Validation Accuracy: 0.9429, Loss: 0.0729
Epoch  18 Batch  260/269 - Train Accuracy: 0.9291, Validation Accuracy: 0.9420, Loss: 0.0803
Epoch  18 Batch  261/269 - Train Accuracy: 0.9434, Validation Accuracy: 0.9407, Loss: 0.0808
Epoch  18 Batch  262/269 - Train Accuracy: 0.9398, Validation Accuracy: 0.9399, Loss: 0.0813
Epoch  18 Batch  263/269 - Train Accuracy: 0.9324, Validation Accuracy: 0.9391, Loss: 0.0791
Epoch  18 Batch  264/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.9451, Loss: 0.0817
Epoch  18 Batch  265/269 - Train Accuracy: 0.9323, Validation Accuracy: 0.9446, Loss: 0.0743
Epoch  18 Batch  266/269 - Train Accuracy: 0.9335, Validation Accuracy: 0.9455, Loss: 0.0677
Epoch  18 Batch  267/269 - Train Accuracy: 0.9437, Validation Accuracy: 0.9417, Loss: 0.0811
Epoch  19 Batch    1/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9441, Loss: 0.0754
Epoch  19 Batch    2/269 - Train Accuracy: 0.9422, Validation Accuracy: 0.9463, Loss: 0.0767
Epoch  19 Batch    3/269 - Train Accuracy: 0.9441, Validation Accuracy: 0.9457, Loss: 0.0761
Epoch  19 Batch    4/269 - Train Accuracy: 0.9172, Validation Accuracy: 0.9424, Loss: 0.0757
Epoch  19 Batch    5/269 - Train Accuracy: 0.9327, Validation Accuracy: 0.9462, Loss: 0.0794
Epoch  19 Batch    6/269 - Train Accuracy: 0.9489, Validation Accuracy: 0.9450, Loss: 0.0719
Epoch  19 Batch    7/269 - Train Accuracy: 0.9409, Validation Accuracy: 0.9461, Loss: 0.0739
Epoch  19 Batch    8/269 - Train Accuracy: 0.9540, Validation Accuracy: 0.9477, Loss: 0.0773
Epoch  19 Batch    9/269 - Train Accuracy: 0.9307, Validation Accuracy: 0.9436, Loss: 0.0823
Epoch  19 Batch   10/269 - Train Accuracy: 0.9374, Validation Accuracy: 0.9426, Loss: 0.0746
Epoch  19 Batch   11/269 - Train Accuracy: 0.9336, Validation Accuracy: 0.9382, Loss: 0.0855
Epoch  19 Batch   12/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9419, Loss: 0.0826
Epoch  19 Batch   13/269 - Train Accuracy: 0.9407, Validation Accuracy: 0.9405, Loss: 0.0637
Epoch  19 Batch   14/269 - Train Accuracy: 0.9262, Validation Accuracy: 0.9407, Loss: 0.0737
Epoch  19 Batch   15/269 - Train Accuracy: 0.9514, Validation Accuracy: 0.9438, Loss: 0.0648
Epoch  19 Batch   16/269 - Train Accuracy: 0.9294, Validation Accuracy: 0.9434, Loss: 0.0829
Epoch  19 Batch   17/269 - Train Accuracy: 0.9362, Validation Accuracy: 0.9415, Loss: 0.0683
Epoch  19 Batch   18/269 - Train Accuracy: 0.9318, Validation Accuracy: 0.9415, Loss: 0.0767
Epoch  19 Batch   19/269 - Train Accuracy: 0.9496, Validation Accuracy: 0.9385, Loss: 0.0707
Epoch  19 Batch   20/269 - Train Accuracy: 0.9390, Validation Accuracy: 0.9400, Loss: 0.0731
Epoch  19 Batch   21/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9436, Loss: 0.0843
Epoch  19 Batch   22/269 - Train Accuracy: 0.9436, Validation Accuracy: 0.9434, Loss: 0.0698
Epoch  19 Batch   23/269 - Train Accuracy: 0.9398, Validation Accuracy: 0.9448, Loss: 0.0800
Epoch  19 Batch   24/269 - Train Accuracy: 0.9322, Validation Accuracy: 0.9347, Loss: 0.0755
Epoch  19 Batch   25/269 - Train Accuracy: 0.9322, Validation Accuracy: 0.9282, Loss: 0.0875
Epoch  19 Batch   26/269 - Train Accuracy: 0.9301, Validation Accuracy: 0.9403, Loss: 0.0763
Epoch  19 Batch   27/269 - Train Accuracy: 0.9265, Validation Accuracy: 0.9462, Loss: 0.0664
Epoch  19 Batch   28/269 - Train Accuracy: 0.9269, Validation Accuracy: 0.9456, Loss: 0.0868
Epoch  19 Batch   29/269 - Train Accuracy: 0.9410, Validation Accuracy: 0.9404, Loss: 0.0783
Epoch  19 Batch   30/269 - Train Accuracy: 0.9364, Validation Accuracy: 0.9407, Loss: 0.0778
Epoch  19 Batch   31/269 - Train Accuracy: 0.9422, Validation Accuracy: 0.9388, Loss: 0.0693
Epoch  19 Batch   32/269 - Train Accuracy: 0.9437, Validation Accuracy: 0.9414, Loss: 0.0729
Epoch  19 Batch   33/269 - Train Accuracy: 0.9361, Validation Accuracy: 0.9456, Loss: 0.0677
Epoch  19 Batch   34/269 - Train Accuracy: 0.9406, Validation Accuracy: 0.9446, Loss: 0.0791
Epoch  19 Batch   35/269 - Train Accuracy: 0.9422, Validation Accuracy: 0.9436, Loss: 0.0839
Epoch  19 Batch   36/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9441, Loss: 0.0776
Epoch  19 Batch   37/269 - Train Accuracy: 0.9423, Validation Accuracy: 0.9395, Loss: 0.0751
Epoch  19 Batch   38/269 - Train Accuracy: 0.9368, Validation Accuracy: 0.9457, Loss: 0.0750
Epoch  19 Batch   39/269 - Train Accuracy: 0.9422, Validation Accuracy: 0.9465, Loss: 0.0773
Epoch  19 Batch   40/269 - Train Accuracy: 0.9273, Validation Accuracy: 0.9474, Loss: 0.0768
Epoch  19 Batch   41/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9461, Loss: 0.0781
Epoch  19 Batch   42/269 - Train Accuracy: 0.9474, Validation Accuracy: 0.9403, Loss: 0.0657
Epoch  19 Batch   43/269 - Train Accuracy: 0.9382, Validation Accuracy: 0.9357, Loss: 0.0753
Epoch  19 Batch   44/269 - Train Accuracy: 0.9303, Validation Accuracy: 0.9341, Loss: 0.0754
Epoch  19 Batch   45/269 - Train Accuracy: 0.9347, Validation Accuracy: 0.9363, Loss: 0.0763
Epoch  19 Batch   46/269 - Train Accuracy: 0.9390, Validation Accuracy: 0.9409, Loss: 0.0749
Epoch  19 Batch   47/269 - Train Accuracy: 0.9475, Validation Accuracy: 0.9433, Loss: 0.0664
Epoch  19 Batch   48/269 - Train Accuracy: 0.9433, Validation Accuracy: 0.9431, Loss: 0.0728
Epoch  19 Batch   49/269 - Train Accuracy: 0.9334, Validation Accuracy: 0.9385, Loss: 0.0697
Epoch  19 Batch   50/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9360, Loss: 0.0877
Epoch  19 Batch   51/269 - Train Accuracy: 0.9350, Validation Accuracy: 0.9419, Loss: 0.0775
Epoch  19 Batch   52/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9425, Loss: 0.0670
Epoch  19 Batch   53/269 - Train Accuracy: 0.9291, Validation Accuracy: 0.9422, Loss: 0.0790
Epoch  19 Batch   54/269 - Train Accuracy: 0.9462, Validation Accuracy: 0.9435, Loss: 0.0730
Epoch  19 Batch   55/269 - Train Accuracy: 0.9461, Validation Accuracy: 0.9432, Loss: 0.0728
Epoch  19 Batch   56/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9445, Loss: 0.0736
Epoch  19 Batch   57/269 - Train Accuracy: 0.9285, Validation Accuracy: 0.9426, Loss: 0.0831
Epoch  19 Batch   58/269 - Train Accuracy: 0.9345, Validation Accuracy: 0.9438, Loss: 0.0717
Epoch  19 Batch   59/269 - Train Accuracy: 0.9575, Validation Accuracy: 0.9408, Loss: 0.0629
Epoch  19 Batch   60/269 - Train Accuracy: 0.9367, Validation Accuracy: 0.9462, Loss: 0.0707
Epoch  19 Batch   61/269 - Train Accuracy: 0.9391, Validation Accuracy: 0.9434, Loss: 0.0661
Epoch  19 Batch   62/269 - Train Accuracy: 0.9311, Validation Accuracy: 0.9490, Loss: 0.0730
Epoch  19 Batch   63/269 - Train Accuracy: 0.9403, Validation Accuracy: 0.9439, Loss: 0.0830
Epoch  19 Batch   64/269 - Train Accuracy: 0.9433, Validation Accuracy: 0.9448, Loss: 0.0688
Epoch  19 Batch   65/269 - Train Accuracy: 0.9234, Validation Accuracy: 0.9406, Loss: 0.0759
Epoch  19 Batch   66/269 - Train Accuracy: 0.9239, Validation Accuracy: 0.9459, Loss: 0.0809
Epoch  19 Batch   67/269 - Train Accuracy: 0.9250, Validation Accuracy: 0.9442, Loss: 0.0843
Epoch  19 Batch   68/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9441, Loss: 0.0830
Epoch  19 Batch   69/269 - Train Accuracy: 0.9274, Validation Accuracy: 0.9387, Loss: 0.0902
Epoch  19 Batch   70/269 - Train Accuracy: 0.9448, Validation Accuracy: 0.9398, Loss: 0.0785
Epoch  19 Batch   71/269 - Train Accuracy: 0.9338, Validation Accuracy: 0.9413, Loss: 0.0809
Epoch  19 Batch   72/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9438, Loss: 0.0792
Epoch  19 Batch   73/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9399, Loss: 0.0840
Epoch  19 Batch   74/269 - Train Accuracy: 0.9381, Validation Accuracy: 0.9385, Loss: 0.0692
Epoch  19 Batch   75/269 - Train Accuracy: 0.9373, Validation Accuracy: 0.9442, Loss: 0.0769
Epoch  19 Batch   76/269 - Train Accuracy: 0.9322, Validation Accuracy: 0.9448, Loss: 0.0740
Epoch  19 Batch   77/269 - Train Accuracy: 0.9351, Validation Accuracy: 0.9479, Loss: 0.0725
Epoch  19 Batch   78/269 - Train Accuracy: 0.9468, Validation Accuracy: 0.9447, Loss: 0.0759
Epoch  19 Batch   79/269 - Train Accuracy: 0.9330, Validation Accuracy: 0.9461, Loss: 0.0712
Epoch  19 Batch   80/269 - Train Accuracy: 0.9417, Validation Accuracy: 0.9434, Loss: 0.0747
Epoch  19 Batch   81/269 - Train Accuracy: 0.9281, Validation Accuracy: 0.9466, Loss: 0.0835
Epoch  19 Batch   82/269 - Train Accuracy: 0.9474, Validation Accuracy: 0.9447, Loss: 0.0620
Epoch  19 Batch   83/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9444, Loss: 0.0831
Epoch  19 Batch   84/269 - Train Accuracy: 0.9391, Validation Accuracy: 0.9434, Loss: 0.0727
Epoch  19 Batch   85/269 - Train Accuracy: 0.9422, Validation Accuracy: 0.9410, Loss: 0.0727
Epoch  19 Batch   86/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9374, Loss: 0.0664
Epoch  19 Batch   87/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9357, Loss: 0.0765
Epoch  19 Batch   88/269 - Train Accuracy: 0.9218, Validation Accuracy: 0.9389, Loss: 0.0728
Epoch  19 Batch   89/269 - Train Accuracy: 0.9420, Validation Accuracy: 0.9442, Loss: 0.0751
Epoch  19 Batch   90/269 - Train Accuracy: 0.9456, Validation Accuracy: 0.9431, Loss: 0.0739
Epoch  19 Batch   91/269 - Train Accuracy: 0.9496, Validation Accuracy: 0.9442, Loss: 0.0698
Epoch  19 Batch   92/269 - Train Accuracy: 0.9459, Validation Accuracy: 0.9448, Loss: 0.0697
Epoch  19 Batch   93/269 - Train Accuracy: 0.9470, Validation Accuracy: 0.9422, Loss: 0.0703
Epoch  19 Batch   94/269 - Train Accuracy: 0.9273, Validation Accuracy: 0.9443, Loss: 0.0826
Epoch  19 Batch   95/269 - Train Accuracy: 0.9488, Validation Accuracy: 0.9466, Loss: 0.0663
Epoch  19 Batch   96/269 - Train Accuracy: 0.9318, Validation Accuracy: 0.9455, Loss: 0.0797
Epoch  19 Batch   97/269 - Train Accuracy: 0.9355, Validation Accuracy: 0.9468, Loss: 0.0821
Epoch  19 Batch   98/269 - Train Accuracy: 0.9430, Validation Accuracy: 0.9415, Loss: 0.0726
Epoch  19 Batch   99/269 - Train Accuracy: 0.9400, Validation Accuracy: 0.9367, Loss: 0.0698
Epoch  19 Batch  100/269 - Train Accuracy: 0.9410, Validation Accuracy: 0.9441, Loss: 0.0746
Epoch  19 Batch  101/269 - Train Accuracy: 0.9323, Validation Accuracy: 0.9447, Loss: 0.0844
Epoch  19 Batch  102/269 - Train Accuracy: 0.9406, Validation Accuracy: 0.9482, Loss: 0.0749
Epoch  19 Batch  103/269 - Train Accuracy: 0.9486, Validation Accuracy: 0.9502, Loss: 0.0789
Epoch  19 Batch  104/269 - Train Accuracy: 0.9418, Validation Accuracy: 0.9488, Loss: 0.0689
Epoch  19 Batch  105/269 - Train Accuracy: 0.9337, Validation Accuracy: 0.9466, Loss: 0.0771
Epoch  19 Batch  106/269 - Train Accuracy: 0.9504, Validation Accuracy: 0.9478, Loss: 0.0713
Epoch  19 Batch  107/269 - Train Accuracy: 0.9472, Validation Accuracy: 0.9438, Loss: 0.0744
Epoch  19 Batch  108/269 - Train Accuracy: 0.9515, Validation Accuracy: 0.9409, Loss: 0.0717
Epoch  19 Batch  109/269 - Train Accuracy: 0.9254, Validation Accuracy: 0.9460, Loss: 0.0747
Epoch  19 Batch  110/269 - Train Accuracy: 0.9359, Validation Accuracy: 0.9440, Loss: 0.0658
Epoch  19 Batch  111/269 - Train Accuracy: 0.9370, Validation Accuracy: 0.9432, Loss: 0.0794
Epoch  19 Batch  112/269 - Train Accuracy: 0.9364, Validation Accuracy: 0.9442, Loss: 0.0772
Epoch  19 Batch  113/269 - Train Accuracy: 0.9370, Validation Accuracy: 0.9433, Loss: 0.0738
Epoch  19 Batch  114/269 - Train Accuracy: 0.9379, Validation Accuracy: 0.9383, Loss: 0.0770
Epoch  19 Batch  115/269 - Train Accuracy: 0.9380, Validation Accuracy: 0.9403, Loss: 0.0732
Epoch  19 Batch  116/269 - Train Accuracy: 0.9345, Validation Accuracy: 0.9408, Loss: 0.0771
Epoch  19 Batch  117/269 - Train Accuracy: 0.9352, Validation Accuracy: 0.9447, Loss: 0.0677
Epoch  19 Batch  118/269 - Train Accuracy: 0.9458, Validation Accuracy: 0.9426, Loss: 0.0689
Epoch  19 Batch  119/269 - Train Accuracy: 0.9203, Validation Accuracy: 0.9432, Loss: 0.0797
Epoch  19 Batch  120/269 - Train Accuracy: 0.9326, Validation Accuracy: 0.9442, Loss: 0.0795
Epoch  19 Batch  121/269 - Train Accuracy: 0.9318, Validation Accuracy: 0.9417, Loss: 0.0676
Epoch  19 Batch  122/269 - Train Accuracy: 0.9462, Validation Accuracy: 0.9403, Loss: 0.0714
Epoch  19 Batch  123/269 - Train Accuracy: 0.9353, Validation Accuracy: 0.9368, Loss: 0.0754
Epoch  19 Batch  124/269 - Train Accuracy: 0.9314, Validation Accuracy: 0.9379, Loss: 0.0691
Epoch  19 Batch  125/269 - Train Accuracy: 0.9472, Validation Accuracy: 0.9403, Loss: 0.0686
Epoch  19 Batch  126/269 - Train Accuracy: 0.9213, Validation Accuracy: 0.9403, Loss: 0.0727
Epoch  19 Batch  127/269 - Train Accuracy: 0.9371, Validation Accuracy: 0.9450, Loss: 0.0821
Epoch  19 Batch  128/269 - Train Accuracy: 0.9383, Validation Accuracy: 0.9365, Loss: 0.0736
Epoch  19 Batch  129/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9367, Loss: 0.0761
Epoch  19 Batch  130/269 - Train Accuracy: 0.9500, Validation Accuracy: 0.9434, Loss: 0.0805
Epoch  19 Batch  131/269 - Train Accuracy: 0.9306, Validation Accuracy: 0.9421, Loss: 0.0769
Epoch  19 Batch  132/269 - Train Accuracy: 0.9168, Validation Accuracy: 0.9347, Loss: 0.0792
Epoch  19 Batch  133/269 - Train Accuracy: 0.9424, Validation Accuracy: 0.9324, Loss: 0.0673
Epoch  19 Batch  134/269 - Train Accuracy: 0.9269, Validation Accuracy: 0.9339, Loss: 0.0724
Epoch  19 Batch  135/269 - Train Accuracy: 0.9420, Validation Accuracy: 0.9388, Loss: 0.0814
Epoch  19 Batch  136/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9415, Loss: 0.0831
Epoch  19 Batch  137/269 - Train Accuracy: 0.9220, Validation Accuracy: 0.9397, Loss: 0.0853
Epoch  19 Batch  138/269 - Train Accuracy: 0.9352, Validation Accuracy: 0.9411, Loss: 0.0720
Epoch  19 Batch  139/269 - Train Accuracy: 0.9448, Validation Accuracy: 0.9428, Loss: 0.0677
Epoch  19 Batch  140/269 - Train Accuracy: 0.9346, Validation Accuracy: 0.9458, Loss: 0.0803
Epoch  19 Batch  141/269 - Train Accuracy: 0.9332, Validation Accuracy: 0.9420, Loss: 0.0844
Epoch  19 Batch  142/269 - Train Accuracy: 0.9324, Validation Accuracy: 0.9441, Loss: 0.0722
Epoch  19 Batch  143/269 - Train Accuracy: 0.9440, Validation Accuracy: 0.9420, Loss: 0.0678
Epoch  19 Batch  144/269 - Train Accuracy: 0.9521, Validation Accuracy: 0.9374, Loss: 0.0650
Epoch  19 Batch  145/269 - Train Accuracy: 0.9375, Validation Accuracy: 0.9418, Loss: 0.0705
Epoch  19 Batch  146/269 - Train Accuracy: 0.9365, Validation Accuracy: 0.9429, Loss: 0.0689
Epoch  19 Batch  147/269 - Train Accuracy: 0.9372, Validation Accuracy: 0.9472, Loss: 0.0800
Epoch  19 Batch  148/269 - Train Accuracy: 0.9408, Validation Accuracy: 0.9436, Loss: 0.0701
Epoch  19 Batch  149/269 - Train Accuracy: 0.9254, Validation Accuracy: 0.9458, Loss: 0.0843
Epoch  19 Batch  150/269 - Train Accuracy: 0.9426, Validation Accuracy: 0.9430, Loss: 0.0778
Epoch  19 Batch  151/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9385, Loss: 0.0702
Epoch  19 Batch  152/269 - Train Accuracy: 0.9365, Validation Accuracy: 0.9427, Loss: 0.0759
Epoch  19 Batch  153/269 - Train Accuracy: 0.9493, Validation Accuracy: 0.9476, Loss: 0.0720
Epoch  19 Batch  154/269 - Train Accuracy: 0.9458, Validation Accuracy: 0.9468, Loss: 0.0688
Epoch  19 Batch  155/269 - Train Accuracy: 0.9333, Validation Accuracy: 0.9447, Loss: 0.0698
Epoch  19 Batch  156/269 - Train Accuracy: 0.9354, Validation Accuracy: 0.9437, Loss: 0.0813
Epoch  19 Batch  157/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9427, Loss: 0.0683
Epoch  19 Batch  158/269 - Train Accuracy: 0.9305, Validation Accuracy: 0.9401, Loss: 0.0751
Epoch  19 Batch  159/269 - Train Accuracy: 0.9314, Validation Accuracy: 0.9459, Loss: 0.0760
Epoch  19 Batch  160/269 - Train Accuracy: 0.9361, Validation Accuracy: 0.9392, Loss: 0.0723
Epoch  19 Batch  161/269 - Train Accuracy: 0.9435, Validation Accuracy: 0.9396, Loss: 0.0687
Epoch  19 Batch  162/269 - Train Accuracy: 0.9408, Validation Accuracy: 0.9405, Loss: 0.0704
Epoch  19 Batch  163/269 - Train Accuracy: 0.9457, Validation Accuracy: 0.9329, Loss: 0.0715
Epoch  19 Batch  164/269 - Train Accuracy: 0.9405, Validation Accuracy: 0.9336, Loss: 0.0699
Epoch  19 Batch  165/269 - Train Accuracy: 0.9381, Validation Accuracy: 0.9398, Loss: 0.0743
Epoch  19 Batch  166/269 - Train Accuracy: 0.9453, Validation Accuracy: 0.9409, Loss: 0.0748
Epoch  19 Batch  167/269 - Train Accuracy: 0.9450, Validation Accuracy: 0.9450, Loss: 0.0674
Epoch  19 Batch  168/269 - Train Accuracy: 0.9442, Validation Accuracy: 0.9446, Loss: 0.0747
Epoch  19 Batch  169/269 - Train Accuracy: 0.9285, Validation Accuracy: 0.9437, Loss: 0.0711
Epoch  19 Batch  170/269 - Train Accuracy: 0.9318, Validation Accuracy: 0.9456, Loss: 0.0740
Epoch  19 Batch  171/269 - Train Accuracy: 0.9531, Validation Accuracy: 0.9467, Loss: 0.0736
Epoch  19 Batch  172/269 - Train Accuracy: 0.9344, Validation Accuracy: 0.9473, Loss: 0.0825
Epoch  19 Batch  173/269 - Train Accuracy: 0.9450, Validation Accuracy: 0.9422, Loss: 0.0642
Epoch  19 Batch  174/269 - Train Accuracy: 0.9515, Validation Accuracy: 0.9442, Loss: 0.0756
Epoch  19 Batch  175/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9447, Loss: 0.0840
Epoch  19 Batch  176/269 - Train Accuracy: 0.9224, Validation Accuracy: 0.9437, Loss: 0.0829
Epoch  19 Batch  177/269 - Train Accuracy: 0.9521, Validation Accuracy: 0.9450, Loss: 0.0690
Epoch  19 Batch  178/269 - Train Accuracy: 0.9390, Validation Accuracy: 0.9442, Loss: 0.0681
Epoch  19 Batch  179/269 - Train Accuracy: 0.9248, Validation Accuracy: 0.9446, Loss: 0.0728
Epoch  19 Batch  180/269 - Train Accuracy: 0.9408, Validation Accuracy: 0.9443, Loss: 0.0714
Epoch  19 Batch  181/269 - Train Accuracy: 0.9355, Validation Accuracy: 0.9474, Loss: 0.0813
Epoch  19 Batch  182/269 - Train Accuracy: 0.9338, Validation Accuracy: 0.9444, Loss: 0.0705
Epoch  19 Batch  183/269 - Train Accuracy: 0.9465, Validation Accuracy: 0.9497, Loss: 0.0616
Epoch  19 Batch  184/269 - Train Accuracy: 0.9409, Validation Accuracy: 0.9431, Loss: 0.0694
Epoch  19 Batch  185/269 - Train Accuracy: 0.9406, Validation Accuracy: 0.9437, Loss: 0.0682
Epoch  19 Batch  186/269 - Train Accuracy: 0.9393, Validation Accuracy: 0.9437, Loss: 0.0665
Epoch  19 Batch  187/269 - Train Accuracy: 0.9364, Validation Accuracy: 0.9450, Loss: 0.0715
Epoch  19 Batch  188/269 - Train Accuracy: 0.9380, Validation Accuracy: 0.9464, Loss: 0.0711
Epoch  19 Batch  189/269 - Train Accuracy: 0.9360, Validation Accuracy: 0.9466, Loss: 0.0654
Epoch  19 Batch  190/269 - Train Accuracy: 0.9331, Validation Accuracy: 0.9478, Loss: 0.0688
Epoch  19 Batch  191/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9444, Loss: 0.0684
Epoch  19 Batch  192/269 - Train Accuracy: 0.9432, Validation Accuracy: 0.9471, Loss: 0.0729
Epoch  19 Batch  193/269 - Train Accuracy: 0.9410, Validation Accuracy: 0.9468, Loss: 0.0693
Epoch  19 Batch  194/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9490, Loss: 0.0715
Epoch  19 Batch  195/269 - Train Accuracy: 0.9363, Validation Accuracy: 0.9452, Loss: 0.0700
Epoch  19 Batch  196/269 - Train Accuracy: 0.9336, Validation Accuracy: 0.9470, Loss: 0.0701
Epoch  19 Batch  197/269 - Train Accuracy: 0.9350, Validation Accuracy: 0.9458, Loss: 0.0736
Epoch  19 Batch  198/269 - Train Accuracy: 0.9441, Validation Accuracy: 0.9463, Loss: 0.0748
Epoch  19 Batch  199/269 - Train Accuracy: 0.9461, Validation Accuracy: 0.9376, Loss: 0.0711
Epoch  19 Batch  200/269 - Train Accuracy: 0.9348, Validation Accuracy: 0.9358, Loss: 0.0719
Epoch  19 Batch  201/269 - Train Accuracy: 0.9429, Validation Accuracy: 0.9436, Loss: 0.0722
Epoch  19 Batch  202/269 - Train Accuracy: 0.9314, Validation Accuracy: 0.9466, Loss: 0.0721
Epoch  19 Batch  203/269 - Train Accuracy: 0.9282, Validation Accuracy: 0.9508, Loss: 0.0812
Epoch  19 Batch  204/269 - Train Accuracy: 0.9428, Validation Accuracy: 0.9498, Loss: 0.0747
Epoch  19 Batch  205/269 - Train Accuracy: 0.9387, Validation Accuracy: 0.9513, Loss: 0.0722
Epoch  19 Batch  206/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9498, Loss: 0.0768
Epoch  19 Batch  207/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9518, Loss: 0.0697
Epoch  19 Batch  208/269 - Train Accuracy: 0.9357, Validation Accuracy: 0.9490, Loss: 0.0806
Epoch  19 Batch  209/269 - Train Accuracy: 0.9465, Validation Accuracy: 0.9457, Loss: 0.0633
Epoch  19 Batch  210/269 - Train Accuracy: 0.9427, Validation Accuracy: 0.9490, Loss: 0.0729
Epoch  19 Batch  211/269 - Train Accuracy: 0.9345, Validation Accuracy: 0.9458, Loss: 0.0783
Epoch  19 Batch  212/269 - Train Accuracy: 0.9381, Validation Accuracy: 0.9450, Loss: 0.0811
Epoch  19 Batch  213/269 - Train Accuracy: 0.9378, Validation Accuracy: 0.9431, Loss: 0.0674
Epoch  19 Batch  214/269 - Train Accuracy: 0.9400, Validation Accuracy: 0.9434, Loss: 0.0697
Epoch  19 Batch  215/269 - Train Accuracy: 0.9350, Validation Accuracy: 0.9417, Loss: 0.0699
Epoch  19 Batch  216/269 - Train Accuracy: 0.9362, Validation Accuracy: 0.9434, Loss: 0.0823
Epoch  19 Batch  217/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9479, Loss: 0.0767
Epoch  19 Batch  218/269 - Train Accuracy: 0.9487, Validation Accuracy: 0.9482, Loss: 0.0711
Epoch  19 Batch  219/269 - Train Accuracy: 0.9502, Validation Accuracy: 0.9486, Loss: 0.0750
Epoch  19 Batch  220/269 - Train Accuracy: 0.9409, Validation Accuracy: 0.9510, Loss: 0.0676
Epoch  19 Batch  221/269 - Train Accuracy: 0.9416, Validation Accuracy: 0.9455, Loss: 0.0759
Epoch  19 Batch  222/269 - Train Accuracy: 0.9483, Validation Accuracy: 0.9467, Loss: 0.0683
Epoch  19 Batch  223/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9454, Loss: 0.0715
Epoch  19 Batch  224/269 - Train Accuracy: 0.9392, Validation Accuracy: 0.9445, Loss: 0.0830
Epoch  19 Batch  225/269 - Train Accuracy: 0.9331, Validation Accuracy: 0.9462, Loss: 0.0620
Epoch  19 Batch  226/269 - Train Accuracy: 0.9430, Validation Accuracy: 0.9464, Loss: 0.0716
Epoch  19 Batch  227/269 - Train Accuracy: 0.9504, Validation Accuracy: 0.9474, Loss: 0.0840
Epoch  19 Batch  228/269 - Train Accuracy: 0.9430, Validation Accuracy: 0.9450, Loss: 0.0670
Epoch  19 Batch  229/269 - Train Accuracy: 0.9369, Validation Accuracy: 0.9441, Loss: 0.0677
Epoch  19 Batch  230/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9473, Loss: 0.0708
Epoch  19 Batch  231/269 - Train Accuracy: 0.9388, Validation Accuracy: 0.9490, Loss: 0.0735
Epoch  19 Batch  232/269 - Train Accuracy: 0.9399, Validation Accuracy: 0.9445, Loss: 0.0741
Epoch  19 Batch  233/269 - Train Accuracy: 0.9432, Validation Accuracy: 0.9440, Loss: 0.0745
Epoch  19 Batch  234/269 - Train Accuracy: 0.9432, Validation Accuracy: 0.9471, Loss: 0.0727
Epoch  19 Batch  235/269 - Train Accuracy: 0.9670, Validation Accuracy: 0.9532, Loss: 0.0581
Epoch  19 Batch  236/269 - Train Accuracy: 0.9339, Validation Accuracy: 0.9522, Loss: 0.0711
Epoch  19 Batch  237/269 - Train Accuracy: 0.9417, Validation Accuracy: 0.9497, Loss: 0.0655
Epoch  19 Batch  238/269 - Train Accuracy: 0.9497, Validation Accuracy: 0.9525, Loss: 0.0718
Epoch  19 Batch  239/269 - Train Accuracy: 0.9385, Validation Accuracy: 0.9395, Loss: 0.0690
Epoch  19 Batch  240/269 - Train Accuracy: 0.9487, Validation Accuracy: 0.9505, Loss: 0.0655
Epoch  19 Batch  241/269 - Train Accuracy: 0.9469, Validation Accuracy: 0.9512, Loss: 0.0788
Epoch  19 Batch  242/269 - Train Accuracy: 0.9564, Validation Accuracy: 0.9435, Loss: 0.0727
Epoch  19 Batch  243/269 - Train Accuracy: 0.9430, Validation Accuracy: 0.9417, Loss: 0.0685
Epoch  19 Batch  244/269 - Train Accuracy: 0.9443, Validation Accuracy: 0.9476, Loss: 0.0735
Epoch  19 Batch  245/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9462, Loss: 0.0736
Epoch  19 Batch  246/269 - Train Accuracy: 0.9396, Validation Accuracy: 0.9508, Loss: 0.0769
Epoch  19 Batch  247/269 - Train Accuracy: 0.9380, Validation Accuracy: 0.9522, Loss: 0.0683
Epoch  19 Batch  248/269 - Train Accuracy: 0.9496, Validation Accuracy: 0.9448, Loss: 0.0664
Epoch  19 Batch  249/269 - Train Accuracy: 0.9385, Validation Accuracy: 0.9440, Loss: 0.0643
Epoch  19 Batch  250/269 - Train Accuracy: 0.9446, Validation Accuracy: 0.9455, Loss: 0.0664
Epoch  19 Batch  251/269 - Train Accuracy: 0.9627, Validation Accuracy: 0.9458, Loss: 0.0707
Epoch  19 Batch  252/269 - Train Accuracy: 0.9431, Validation Accuracy: 0.9443, Loss: 0.0660
Epoch  19 Batch  253/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9422, Loss: 0.0738
Epoch  19 Batch  254/269 - Train Accuracy: 0.9387, Validation Accuracy: 0.9410, Loss: 0.0740
Epoch  19 Batch  255/269 - Train Accuracy: 0.9491, Validation Accuracy: 0.9399, Loss: 0.0733
Epoch  19 Batch  256/269 - Train Accuracy: 0.9371, Validation Accuracy: 0.9411, Loss: 0.0736
Epoch  19 Batch  257/269 - Train Accuracy: 0.9331, Validation Accuracy: 0.9371, Loss: 0.0772
Epoch  19 Batch  258/269 - Train Accuracy: 0.9386, Validation Accuracy: 0.9377, Loss: 0.0769
Epoch  19 Batch  259/269 - Train Accuracy: 0.9422, Validation Accuracy: 0.9496, Loss: 0.0689
Epoch  19 Batch  260/269 - Train Accuracy: 0.9371, Validation Accuracy: 0.9524, Loss: 0.0765
Epoch  19 Batch  261/269 - Train Accuracy: 0.9393, Validation Accuracy: 0.9502, Loss: 0.0726
Epoch  19 Batch  262/269 - Train Accuracy: 0.9382, Validation Accuracy: 0.9490, Loss: 0.0733
Epoch  19 Batch  263/269 - Train Accuracy: 0.9363, Validation Accuracy: 0.9485, Loss: 0.0752
Epoch  19 Batch  264/269 - Train Accuracy: 0.9257, Validation Accuracy: 0.9484, Loss: 0.0772
Epoch  19 Batch  265/269 - Train Accuracy: 0.9433, Validation Accuracy: 0.9465, Loss: 0.0692
Epoch  19 Batch  266/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9504, Loss: 0.0662
Epoch  19 Batch  267/269 - Train Accuracy: 0.9482, Validation Accuracy: 0.9510, Loss: 0.0777
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Save-Parameters">¶</a></h3><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Checkpoint">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Sentence-to-Sequence">¶</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    """</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab_to_int</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
            <span class="n">ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">'&lt;UNK&gt;'</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">ids</span>


<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">"""</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>3
6
5
4
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Translate">¶</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">'he saw a old yellow truck .'</span>


<span class="sd">"""</span>
<span class="sd">DON'T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">"""</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">'.meta'</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'input:0'</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'predictions:0'</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'target_sequence_length:0'</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'source_sequence_length:0'</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'keep_prob:0'</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">target_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">source_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Input'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'  Word Ids:      </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'  English Words: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Prediction'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'  Word Ids:      </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'  French Words: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>35
9
8
77
215
158
181
INFO:tensorflow:Restoring parameters from checkpoints/dev
Input
  Word Ids:      [35, 9, 8, 77, 215, 158, 181]
  English Words: ['he', 'saw', 'a', 'old', 'yellow', 'truck', '.']

Prediction
  Word Ids:      [306, 201, 109, 208, 255, 336, 51, 179, 1]
  French Words: il a vu un vieux camion jaune . &lt;EOS&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Imperfect-Translation">¶</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="http://localhost:8888/nbconvert/html/dlnd_language_translation.ipynb?download=false#Submitting-This-Project">¶</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>


 



</body></html>